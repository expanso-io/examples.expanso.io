---
title: Transform Formats
sidebar_label: Introduction
sidebar_position: 1
description: Transform data between JSON, Avro, Parquet, and Protobuf formats for optimal performance and compatibility
keywords: [format-conversion, avro, parquet, protobuf, json, serialization, schema-evolution, bandwidth-optimization]
---

# Transform Formats

Transform data between JSON, Avro, Parquet, and Protobuf formats to optimize for bandwidth, storage, and processing.

## The Problem

Data pipelines need multiple formats for different purposes:
- JSON sensor readings need compact Avro for Kafka streaming
- Avro needs efficient Parquet for cloud analytics
- Microservices require type-safe Protobuf
- Each format requires specialized serialization

## The Solution

Learn 4 format transformation techniques:

1. **JSON to Avro** - Binary serialization with schema registry integration for 60% bandwidth reduction
2. **Avro to Parquet** - Row-to-column format conversion with compression for 90% storage reduction
3. **JSON to Protobuf** - Schema-based binary serialization for type-safe microservice communication
4. **Multi-Format Auto-Detection** - Content-Type analysis with conditional processing for mixed sources

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See format transformations with live before/after examples

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [JSON to Avro](./step-1-convert-json-avro)
2. [Avro to Parquet](./step-2-convert-avro-parquet)
3. [JSON to Protobuf](./step-3-convert-json-protobuf)
4. [Multi-Format Detection](./step-4-auto-detect-formats)

### [Complete Pipeline](./complete-pipeline)
Download the production-ready solution
