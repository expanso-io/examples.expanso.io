---
title: Normalize Timestamps
sidebar_label: Introduction
sidebar_position: 1
description: Parse, convert, and standardize timestamps from different time zones to consistent UTC representation at the edge
keywords: [timestamp, timezone, UTC, ISO8601, unix-epoch, parsing, conversion, compliance, analytics, edge]
---

# Normalize Timestamps

**Learn to build a production-ready timestamp normalization pipeline** that processes data at the edge—standardizing timestamps from multiple formats and time zones into consistent UTC representation. This step-by-step guide teaches you 3 essential timestamp processing techniques through hands-on exercises.

## The Problem

Your events arrive with timestamps in inconsistent formats and time zones, making analytics impossible:

```json
{
  "event_type": "user_login",
  "timestamp": "2025-10-20T19:23:45.123+01:00",  // ❌ London timezone
  "user_id": "user_12345"
}
{
  "event_type": "user_login", 
  "timestamp": 1729450425,                        // ❌ Unix epoch (unknown TZ)
  "user_id": "user_67890"
}
{
  "event_type": "user_login",
  "timestamp": "2025-10-20 14:23:45",             // ❌ Custom format
  "timezone": "America/New_York",                 // ❌ Separate TZ field
  "user_id": "user_24680"
}
```

**The challenge:** Normalize all timestamp formats to consistent UTC representation while preserving timezone context for compliance and analytics.

## The Solution: 3 Timestamp Processing Techniques

This guide teaches you how to apply the right technique for each timestamp format:

### 1. **Parse Multiple Formats** → ISO8601, Unix Epochs, Custom Formats
Detect and parse timestamps regardless of input format.
- **Use case:** Handle diverse data sources (APIs, logs, databases)
- **Method:** Format detection with Bloblang parsing functions
- **Result:** Consistent timestamp object for further processing

### 2. **Convert Timezones** → UTC Standardization
Transform all timestamps to UTC while preserving timezone context.
- **Use case:** Global analytics, compliance audit trails
- **Method:** Timezone detection and UTC conversion
- **Result:** All events on same time basis for comparison

### 3. **Enrich Metadata** → Analytics-Friendly Components
Add time components for business intelligence queries.
- **Use case:** Business hours analysis, seasonal patterns
- **Method:** Extract year, month, hour, quarter, weekend flags
- **Result:** SQL queries without complex timestamp math

## Why Process at the Edge?

**Compliance:** Maintain timezone audit trails before data leaves source regions (GDPR Article 30)
**Performance:** Avoid timezone calculations in every analytics query (10x query speed improvement)
**Consistency:** Single source of truth for time normalization across all systems
**Cost:** Reduce compute costs in data warehouse by pre-processing timestamps

## What You'll Learn

By the end of this guide, you'll be able to:

✅ **Parse timestamps** from any format (ISO8601, Unix epochs, custom patterns)
✅ **Convert timezones** to UTC while preserving original context
✅ **Enrich metadata** with analytics-friendly time components
✅ **Handle edge cases** like DST transitions and clock skew
✅ **Deploy production** pipelines with monitoring and error handling

## Get Started

### Option 1: Step-by-Step Tutorial (Recommended)
**Build** the timestamp normalization pipeline incrementally, one concept at a time.

1. [**Setup Guide**](./setup) - Configure environment and deploy shell pipeline
2. [**Step 1: Parse Multiple Formats**](./step-1-parse-formats) - Handle ISO8601, Unix epochs, custom formats
3. [**Step 2: Convert Timezones**](./step-2-convert-timezones) - Standardize to UTC with context preservation  
4. [**Step 3: Enrich Metadata**](./step-3-enrich-metadata) - Add analytics components and business logic

### Option 2: Jump to Final Solution
**Download** the complete, production-ready timestamp normalization pipeline.

[**→ Get Complete Pipeline**](./complete-pipeline)

## Who This Guide Is For

- **Data Engineers** building ETL pipelines with timestamp normalization requirements
- **Analytics Teams** needing consistent time dimensions for reporting and BI
- **Compliance Officers** ensuring proper timezone handling for audit trails

## Prerequisites

- Expanso Edge deployed ([Installation Guide](https://docs.expanso.io/setup))
- Basic familiarity with JSON data structures
- Understanding of timezone concepts

## Time to Complete

- **Step-by-Step Tutorial:** 45-60 minutes
- **Quick Deploy:** 5 minutes

## Real-World Impact

**Before Timestamp Normalization:**
```
- Query performance: 2.3 seconds (timezone math per row)
- Analytics accuracy: 73% (timezone confusion)
- Compliance coverage: 45% (missing audit trails)
```

**After Timestamp Normalization:**
```
- Query performance: 0.21 seconds (pre-computed components)
- Analytics accuracy: 99% (consistent UTC base)
- Compliance coverage: 100% (full timezone audit trails)
```

---

## Next Steps

Ready to start? Choose your learning path:

<div style={{display: 'flex', gap: '1rem', marginTop: '2rem', marginBottom: '2rem', flexWrap: 'wrap'}}>
  <a href="./setup" className="button button--primary button--lg" style={{flex: '1', minWidth: '200px'}}>
    Start Tutorial
  </a>
  <a href="./complete-pipeline" className="button button--secondary button--lg" style={{flex: '1', minWidth: '200px'}}>
    Download Complete Pipeline
  </a>
</div>

**Questions?** Check [Troubleshooting](./troubleshooting) or see [Related Examples](#related-examples) below.

## Related Examples

- [**Parse Structured Logs**](../parse-logs) - Extract timestamps from various log formats
- [**Aggregate Time Windows**](../aggregate-time-windows) - Time-based aggregation and windowing
- [**Remove PII**](../../data-security/remove-pii) - Anonymize user data while preserving timestamps
