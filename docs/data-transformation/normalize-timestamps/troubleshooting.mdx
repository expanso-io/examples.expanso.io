---
title: Troubleshooting Timestamp Normalization
sidebar_label: Troubleshooting
sidebar_position: 7
description: Comprehensive troubleshooting guide for timestamp normalization issues, errors, and performance problems
keywords: [troubleshooting, errors, debugging, performance, timestamp-issues, DLQ]
---

# Troubleshooting Timestamp Normalization

Comprehensive solutions for common timestamp normalization issues, from format parsing errors to performance problems and timezone edge cases.

## Format Detection Issues

Problems with identifying and parsing timestamp formats.

### Issue: Format Not Detected

**Symptom:**
```json
{
  "event_id": "evt_001",
  "format_detected": "unknown", 
  "dlq_reason": "timestamp_parse_failed",
  "error": "Unsupported timestamp format: unknown for value: 2025-13-45T99:99:99"
}
```

**Diagnosis:**
```bash
# Check what format detection sees
expanso debug-mapping << 'EOF'
let ts = "2025-13-45T99:99:99".string()
root.checks = {
  "iso8601_check": ts.re_match("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}"),
  "unix_check": ts.re_match("^\\d{10}$"),
  "custom_check": ts.re_match("^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$")
}
EOF
```

**Solutions:**

**1. Add Custom Format Detection**
```yaml
# Extend format detection
- mapping: |
    let ts = this.timestamp.string()
    
    root.format_detected = if ts.re_match("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}") {
      "iso8601"
    } else if ts.re_match("^\\d{4}/\\d{2}/\\d{2}") {
      "slash_date"  # Add new format
    } else if ts.re_match("^\\d{2}\\.\\d{2}\\.\\d{4}") {
      "eu_date"     # European format
    } else {
      "unknown"
    }
```

**2. Add Format-Specific Parsing**
```yaml
# Handle new formats
- mapping: |
    root.timestamp_parsed = if this.format_detected == "slash_date" {
      this.timestamp_original.parse_timestamp("2006/01/02 15:04:05")
    } else if this.format_detected == "eu_date" {
      this.timestamp_original.parse_timestamp("02.01.2006 15:04:05")
    } else {
      # ... existing parsing logic
    }
```

**3. Debug Mode for Unknown Formats**
```yaml
# Add debugging for unknown formats
- mapping: |
    root = if this.format_detected == "unknown" {
      this.assign({
        "debug_info": {
          "original_value": this.timestamp_original,
          "string_representation": this.timestamp_original.string(),
          "value_type": this.timestamp_original.type(),
          "length": this.timestamp_original.string().length(),
          "first_10_chars": this.timestamp_original.string().slice(0, 10)
        }
      })
    } else {
      this
    }
```

### Issue: Regex Pattern Errors

**Symptom:**
```
Error: regex compilation failed: invalid escape sequence
```

**Diagnosis:**
```bash
# Test regex patterns
echo '"2025-10-20T14:23:45.123Z"' | expanso debug-mapping << 'EOF'
let ts = this.string()
root.regex_test = ts.re_match("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}")
EOF
```

**Solutions:**

**1. Escape Special Characters Properly**
```yaml
# Correct regex escaping for Bloblang
- mapping: |
    let ts = this.timestamp.string()
    
    # ✅ Correct - double backslash for literal \d
    root.is_iso = ts.re_match("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}")
    
    # ❌ Wrong - single backslash
    # root.is_iso = ts.re_match("^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}")
```

**2. Use Character Classes Instead**
```yaml
# Alternative: use character classes
- mapping: |
    let ts = this.timestamp.string()
    
    # More readable character classes
    root.is_iso = ts.re_match("^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}")
```

### Issue: Mixed Data Types

**Symptom:**
```json
{
  "error": "cannot call .string() on number value",
  "timestamp_original": 1729450425
}
```

**Solutions:**

**1. Type-Safe Conversion**
```yaml
# Handle both strings and numbers
- mapping: |
    let ts_str = if this.timestamp.type() == "string" {
      this.timestamp.string()
    } else if this.timestamp.type() == "number" {
      this.timestamp.string()  # Convert number to string
    } else {
      "invalid"
    }
    
    root.timestamp_string = ts_str
```

**2. Type-Specific Detection**
```yaml
# Detect format based on type
- mapping: |
    root.format_detected = if this.timestamp.type() == "number" {
      let num = this.timestamp.number()
      if num > 1000000000000 {  # 13+ digits
        "unix_milliseconds"
      } else if num > 1000000000 {  # 10+ digits  
        "unix_seconds"
      } else {
        "invalid_unix"
      }
    } else if this.timestamp.type() == "string" {
      # ... string format detection
    } else {
      "unsupported_type"
    }
```

---

## Timezone Conversion Issues

Problems with timezone handling and UTC conversion.

### Issue: Unknown Timezone

**Symptom:**
```json
{
  "error": "unknown timezone: America/New_Yrok",
  "timezone_original": "America/New_Yrok"
}
```

**Diagnosis:**
```bash
# Check timezone database
zdump -v America/New_York | head -1

# List available timezones
find /usr/share/zoneinfo -type f | head -20
```

**Solutions:**

**1. Timezone Validation and Fallback**
```yaml
# Validate timezone before use
- mapping: |
    let tz = this.timezone_original.string()
    
    # Known good timezones
    let valid_timezones = [
      "UTC", "America/New_York", "Europe/London", "Asia/Tokyo",
      "America/Los_Angeles", "Europe/Paris", "Australia/Sydney"
    ]
    
    root.timezone_validated = if valid_timezones.contains(tz) {
      tz
    } else if tz.re_match("^[-+]\\d{2}:?\\d{2}$") {
      tz  # Offset format is always valid
    } else {
      "UTC"  # Default fallback
    }
    
    root.timezone_warning = if this.timezone_validated != tz {
      "Unknown timezone '" + tz + "' defaulted to UTC"
    } else {
      null
    }
```

**2. Common Timezone Mappings**
```yaml
# Map common typos and variations
- mapping: |
    let tz = this.timezone_original.string()
    
    root.timezone_corrected = if tz == "EST" || tz == "EDT" {
      "America/New_York"
    } else if tz == "PST" || tz == "PDT" {
      "America/Los_Angeles"
    } else if tz == "GMT" || tz == "BST" {
      "Europe/London"
    } else if tz == "CET" || tz == "CEST" {
      "Europe/Paris"
    } else {
      tz  # Keep as-is
    }
```

**3. Update Timezone Database**
```bash
# Update timezone data (Ubuntu/Debian)
sudo apt-get update && sudo apt-get install -y tzdata

# Update timezone data (Alpine)
sudo apk add --update tzdata

# Update timezone data (RHEL/CentOS)
sudo yum update tzdata

# Verify update
zdump -v America/New_York | head -1
```

### Issue: DST Transition Ambiguity

**Symptom:**
```json
{
  "timestamp": "2025-11-02T06:30:00.000-05:00",
  "warning": "Ambiguous time during DST transition"
}
```

**Solutions:**

**1. DST Transition Detection**
```yaml
# Detect and handle DST transitions
- mapping: |
    let tz = this.timezone_original.string()
    let ts = this.timestamp_parsed
    let month = ts.format_timestamp("01", "UTC").number()
    let day = ts.format_timestamp("02", "UTC").number()
    let hour = ts.format_timestamp("15", tz).number()
    let weekday = ts.format_timestamp("Monday", tz)
    
    # US DST transitions (simplified)
    root.dst_transition = if tz.contains("America/") {
      # Spring forward: 2nd Sunday in March, 2:00 AM
      # Fall back: 1st Sunday in November, 2:00 AM
      (month == 3 && weekday == "Sunday" && day >= 8 && day <= 14 && hour == 2) ||
      (month == 11 && weekday == "Sunday" && day <= 7 && hour >= 1 && hour <= 2)
    } else {
      false
    }
    
    root.timestamp_note = if this.dst_transition {
      "Timestamp occurs during DST transition - may be ambiguous"
    } else {
      null
    }
```

**2. Prefer Standard Time During Fall Back**
```yaml
# Handle "fall back" ambiguity
- mapping: |
    root.timestamp_utc = if this.dst_transition && this.timezone_original.contains("America/") {
      # During fall back, prefer standard time interpretation
      this.timestamp_parsed.format_timestamp_iso8601("UTC")
    } else {
      this.timestamp_parsed.format_timestamp_iso8601("UTC")
    }
```

### Issue: Historical Timezone Changes

**Symptom:**
```json
{
  "timestamp": "1970-01-01T00:00:00+08:00",
  "timezone_original": "Asia/Shanghai",
  "warning": "Historical timezone rules may differ"
}
```

**Solutions:**

**1. Historical Timezone Warnings**
```yaml
# Flag historical timezone issues
- mapping: |
    let tz = this.timezone_original.string()
    let year = this.time_metadata.year
    
    root.historical_warning = if tz == "Europe/Moscow" && year < 2014 {
      "Moscow timezone changed in 2014 - historical accuracy may vary"
    } else if tz.contains("America/") && year < 2007 {
      "US DST rules changed in 2007 - pre-2007 dates may be inaccurate"
    } else if tz == "Asia/Shanghai" && year < 1949 {
      "China timezone history is complex - verify accuracy for pre-1949 dates"
    } else {
      null
    }
```

**2. Timezone Database Version Tracking**
```yaml
# Track timezone data version
- mapping: |
    root.timezone_metadata = {
      "database_version": "2023c",  # Update based on your tzdata version
      "conversion_timestamp": now().format_timestamp_iso8601(),
      "confidence": if this.historical_warning.type() == "string" {
        "medium"
      } else {
        "high"
      }
    }
```

---

## Time Metadata Issues

Problems with time component extraction and business logic.

### Issue: Wrong Business Hours

**Symptom:**
```json
{
  "timestamp": "2025-10-20T14:00:00.000Z",
  "time_metadata": {
    "hour": 14,
    "is_business_hours": false  // Should be true
  }
}
```

**Diagnosis:**
```bash
# Debug business hours logic
echo '{"timestamp": "2025-10-20T14:00:00.000Z"}' | expanso debug-mapping << 'EOF'
let ts = this.timestamp.parse_timestamp_iso8601()
let hour = ts.format_timestamp("15", "UTC").number()
let dow = ts.format_timestamp("1", "UTC").number()

root.debug = {
  "hour": hour,
  "day_of_week": dow,
  "is_weekday": dow >= 1 && dow <= 5,
  "is_work_hour": hour >= 9 && hour < 17,
  "both_true": (dow >= 1 && dow <= 5) && (hour >= 9 && hour < 17)
}
EOF
```

**Solutions:**

**1. Fix Business Hours Logic**
```yaml
# Correct business hours calculation
- mapping: |
    let ts = this.timestamp.parse_timestamp_iso8601()
    let hour = ts.format_timestamp("15", "UTC").number()
    let dow = ts.format_timestamp("1", "UTC").number()  # 1=Monday, 7=Sunday
    
    root.time_metadata.is_business_hours = (dow >= 1 && dow <= 5) && (hour >= 9 && hour < 17)
    
    # Add debug info
    root.time_metadata.debug = {
      "hour": hour,
      "day_of_week": dow,
      "is_weekday": dow >= 1 && dow <= 5,
      "in_work_hours": hour >= 9 && hour < 17
    }
```

**2. Configurable Business Hours**
```yaml
# Support different business hour configurations
- mapping: |
    # Configuration (could be from environment)
    let business_config = {
      "start_hour": 8,  # 8 AM
      "end_hour": 18,   # 6 PM
      "work_days": [1, 2, 3, 4, 5],  # Mon-Fri
      "timezone": "America/New_York"  # Business timezone
    }
    
    # Convert UTC to business timezone
    let business_ts = this.timestamp.parse_timestamp_iso8601().format_timestamp("2006-01-02 15:04:05", business_config.timezone)
    let biz_hour = business_ts.parse_timestamp("2006-01-02 15:04:05").format_timestamp("15", "UTC").number()
    let biz_dow = business_ts.parse_timestamp("2006-01-02 15:04:05").format_timestamp("1", "UTC").number()
    
    root.time_metadata.is_business_hours = business_config.work_days.contains(biz_dow) &&
                                          biz_hour >= business_config.start_hour &&
                                          biz_hour < business_config.end_hour
```

### Issue: Incorrect Holiday Detection

**Symptom:**
```json
{
  "timestamp": "2025-07-04T10:00:00.000Z",
  "time_metadata": {
    "is_holiday": false  // Should be true (July 4th)
  }
}
```

**Solutions:**

**1. Comprehensive Holiday Calendar**
```yaml
# Complete US federal holiday detection
- mapping: |
    let year = this.time_metadata.year
    let month = this.time_metadata.month
    let day = this.time_metadata.day
    let dow = this.time_metadata.day_of_week_num
    
    # Fixed holidays
    let fixed_holidays = (month == 1 && day == 1) ||   # New Year
                        (month == 7 && day == 4) ||    # Independence Day
                        (month == 12 && day == 25)     # Christmas
    
    # Floating holidays (simplified - use proper date calculation in production)
    let floating_holidays = false  # TODO: Implement proper floating date logic
    
    root.time_metadata.is_holiday = fixed_holidays || floating_holidays
    
    # Add holiday name for debugging
    root.time_metadata.holiday_name = if month == 1 && day == 1 {
      "New Year's Day"
    } else if month == 7 && day == 4 {
      "Independence Day"
    } else if month == 12 && day == 25 {
      "Christmas Day"
    } else {
      null
    }
```

**2. External Holiday Calendar Integration**
```yaml
# Use external holiday service (conceptual)
- http:
    url: "https://api.holidays.com/check"
    verb: "GET"
    headers:
      "Content-Type": "application/json"
    query:
      date: '${! json("time_metadata.date_string") }'
      country: "US"
    
- mapping: |
    root.time_metadata.is_holiday = this.http_response.is_holiday
    root.time_metadata.holiday_name = this.http_response.holiday_name
```

### Issue: Wrong Fiscal Year Calculation

**Symptom:**
```json
{
  "timestamp": "2025-10-01T10:00:00.000Z",
  "time_metadata": {
    "fiscal_year": 2025,  // Should be 2026 if FY starts Oct 1
    "fiscal_quarter": "FQ4"  // Should be FQ1
  }
}
```

**Solutions:**

**1. Configurable Fiscal Year**
```yaml
# Configurable fiscal year calculation
- mapping: |
    let year = this.time_metadata.year
    let month = this.time_metadata.month
    
    # Fiscal year configuration
    let fy_start_month = 10  # October start
    
    root.time_metadata.fiscal_year = if month >= fy_start_month {
      year + 1  # Next calendar year
    } else {
      year      # Same calendar year
    }
    
    # Fiscal quarters
    root.time_metadata.fiscal_quarter = if month >= 10 || month <= 12 {
      "FQ1"  # Oct-Dec
    } else if month >= 1 && month <= 3 {
      "FQ2"  # Jan-Mar  
    } else if month >= 4 && month <= 6 {
      "FQ3"  # Apr-Jun
    } else {
      "FQ4"  # Jul-Sep
    }
    
    # Debug info
    root.time_metadata.fy_debug = {
      "calendar_year": year,
      "month": month,
      "fy_start_month": fy_start_month,
      "calculation": if month >= fy_start_month { "year + 1" } else { "year" }
    }
```

---

## Performance Issues

Problems with pipeline speed and resource usage.

### Issue: High Processing Latency

**Symptom:**
```
timestamp_processing_duration_ms 95th percentile: 250ms (target: &lt;20ms)
```

**Diagnosis:**
```bash
# Profile processing steps
expanso profile normalize-timestamps-complete.yaml --duration 60s

# Check metrics
curl http://localhost:9090/metrics | grep timestamp_processing
```

**Solutions:**

**1. Optimize Format Detection**
```yaml
# Cache format detection results
- cache:
    resource: "format_cache"
    key: '${! json("timestamp").string().slice(0, 20) }'  # Cache by timestamp prefix
    value: '${! json("format_detected") }'
    ttl: "1h"

# Use cached result if available
- mapping: |
    root.format_detected = if this.format_cache_hit.type() == "string" {
      this.format_cache_hit
    } else {
      # ... format detection logic
    }
```

**2. Reduce Regex Complexity**
```yaml
# Simpler, faster format detection
- mapping: |
    let ts = this.timestamp.string()
    let len = ts.length()
    
    root.format_detected = if len == 10 && ts.re_match("^\\d{10}$") {
      "unix_seconds"
    } else if len == 13 && ts.re_match("^\\d{13}$") {
      "unix_milliseconds"  
    } else if ts.contains("T") && ts.contains("Z") {
      "iso8601_utc"
    } else if ts.contains("T") && ts.contains("+") {
      "iso8601_offset"
    } else {
      "unknown"
    }
```

**3. Batch Processing Optimization**
```yaml
# Process in larger batches
input:
  kafka:
    batching:
      count: 5000      # Increase batch size
      period: "10s"    # Longer batching period

# Parallel processing
pipeline:
  processors:
    - parallel:
        cap: 4  # Process 4 batches simultaneously
        processors:
          # ... timestamp processing logic
```

### Issue: High Memory Usage

**Symptom:**
```
Container memory usage: 1.8GB (limit: 2GB)
Memory growth rate: +50MB/hour
```

**Diagnosis:**
```bash
# Monitor memory usage
docker stats timestamp-normalizer

# Check for memory leaks
expanso memory-profile normalize-timestamps-complete.yaml
```

**Solutions:**

**1. Reduce Metadata Overhead**
```yaml
# Minimal metadata for high-volume processing
- mapping: |
    root = {
      "event_id": this.event_id,
      "timestamp": this.timestamp_utc,
      # Essential metadata only
      "time_metadata": {
        "year": this.time_metadata.year,
        "month": this.time_metadata.month,
        "hour": this.time_metadata.hour,
        "is_business_hours": this.time_metadata.is_business_hours
      }
    }
```

**2. Stream Processing Mode**
```yaml
# Disable caching for memory-constrained environments
pipeline:
  processors:
    # Remove cache processors
    # - cache: ...  # Comment out caching
    
    # Process and flush immediately
    - mapping: |
        # ... processing logic without intermediate storage
```

**3. Garbage Collection Tuning**
```bash
# Optimize Go GC for the workload
export GOGC=100          # Default garbage collection target
export GOMEMLIMIT=1800m  # Memory limit (leave headroom)
```

### Issue: Low Throughput

**Symptom:**
```
Processing rate: 3,000 events/sec (target: 10,000+)
CPU usage: 100% on all cores
```

**Solutions:**

**1. Horizontal Scaling**
```yaml
# Scale out with multiple instances
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timestamp-normalizer
spec:
  replicas: 6  # Increase replica count
  template:
    spec:
      containers:
      - name: timestamp-normalizer
        resources:
          requests:
            cpu: "2"
            memory: "1Gi"
          limits:
            cpu: "4"
            memory: "2Gi"
```

**2. Partitioned Processing**
```yaml
# Partition by timestamp format for parallel processing
input:
  kafka:
    topics: ["raw-events"]
    partition_consumers: 8  # More parallel consumers

pipeline:
  # Route different formats to different processors
  - switch:
    - check: 'json("timestamp").string().re_match("^\\d{10}$")'
      processors:
        - mapping: |
            # Fast path for Unix timestamps
            root = this
            root.timestamp = this.timestamp.timestamp_unix().format_timestamp_iso8601("UTC")
    
    - check: 'json("timestamp").string().contains("T")'
      processors:
        - mapping: |
            # Standard path for ISO timestamps
            # ... full processing logic
```

**3. Skip Non-Essential Processing**
```yaml
# Fast track for real-time requirements
- branch:
    request_map: 'root = this'
    result_map: 'root = this.merge({"fast_track": true})'
    processors:
      - mapping: |
          # Minimal processing for speed
          root.timestamp = this.timestamp_original.parse_timestamp_iso8601().format_timestamp_iso8601("UTC")
          root.hour = this.timestamp.parse_timestamp_iso8601().format_timestamp("15", "UTC").number()
```

---

## Data Quality Issues

Problems with output accuracy and validation.

### Issue: High DLQ Rate

**Symptom:**
```
DLQ events: 500/sec (5% of total volume)
Success rate: 95% (target: &gt;99%)
```

**Diagnosis:**
```bash
# Analyze DLQ events
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic timestamp-dlq \
  --max-messages 100 | jq '.dlq_reason' | sort | uniq -c
```

**Solutions:**

**1. DLQ Analysis and Remediation**
```yaml
# Add detailed DLQ analysis
- mapping: |
    root = if this.quality_score < 0.6 {
      this.assign({
        "dlq_analysis": {
          "reason": this.dlq_reason,
          "original_timestamp": this.timestamp_original,
          "format_detected": this.format_detected,
          "validation_results": this.validation,
          "suggested_fix": if this.dlq_reason == "timestamp_parse_failed" {
            "Check timestamp format and add to format detection"
          } else if this.dlq_reason == "timezone_conversion_failed" {
            "Verify timezone name is valid"
          } else {
            "Manual review required"
          }
        }
      })
    } else {
      this
    }
```

**2. Automatic Recovery Patterns**
```yaml
# Retry failed events with fallbacks
- switch:
  - check: 'json("dlq_reason") == "timestamp_parse_failed"'
    processors:
      - mapping: |
          # Attempt Unix timestamp interpretation as fallback
          root = this
          root.timestamp = if this.timestamp_original.type() == "number" {
            this.timestamp_original.timestamp_unix().format_timestamp_iso8601("UTC")
          } else {
            # Try stripping extra characters and re-parsing
            let clean_ts = this.timestamp_original.string().re_replace_all("[^\\d\\-T:Z\\+\\.]", "")
            clean_ts.parse_timestamp_iso8601().format_timestamp_iso8601("UTC")
          }
          root.recovery_applied = true
```

### Issue: Validation Failures

**Symptom:**
```json
{
  "validation": {
    "timestamp_reasonable": false,
    "year_valid": true,
    "offset_reasonable": false
  },
  "quality_score": 0.2
}
```

**Solutions:**

**1. Enhanced Validation Logic**
```yaml
# More comprehensive validation
- mapping: |
    let ts_unix = this.time_metadata.unix_timestamp
    let now_unix = now().timestamp_unix()
    let year = this.time_metadata.year
    let offset = this.timezone_offset_minutes
    
    root.validation = {
      "timestamp_exists": this.timestamp.type() == "string",
      "utc_format": this.timestamp.contains("Z"),
      "year_reasonable": year >= 1970 && year <= 2100,
      "not_too_far_past": ts_unix > (now_unix - 94608000),    # 3 years
      "not_too_far_future": ts_unix < (now_unix + 31536000),  # 1 year
      "offset_valid": offset.abs() <= 840,  # ±14 hours max
      "business_logic_consistent": this.time_metadata.is_weekend == (this.time_metadata.day_of_week_num >= 6)
    }
    
    # Calculate detailed quality score
    let valid_count = this.validation.values().map_each(v -> if v { 1 } else { 0 }).sum()
    root.quality_score = valid_count / this.validation.length()
```

**2. Configurable Validation Thresholds**
```yaml
# Environment-specific validation
- mapping: |
    # Validation configuration
    let validation_config = {
      "max_past_days": 1095,      # 3 years for historical data
      "max_future_days": 7,       # 1 week for future events
      "strict_mode": false        # Relaxed validation for data migration
    }
    
    let ts_unix = this.time_metadata.unix_timestamp
    let now_unix = now().timestamp_unix()
    let past_limit = now_unix - (validation_config.max_past_days * 86400)
    let future_limit = now_unix + (validation_config.max_future_days * 86400)
    
    root.validation.timestamp_reasonable = ts_unix >= past_limit && ts_unix <= future_limit
```

---

## Monitoring and Alerting Issues

Problems with observability and incident detection.

### Issue: Missing Metrics

**Symptom:**
```bash
# No metrics available
curl http://localhost:9090/metrics | grep timestamp
# (no output)
```

**Solutions:**

**1. Enable Metrics Configuration**
```yaml
# Add comprehensive metrics
pipeline:
  processors:
    # ... processing logic ...
    
    # Performance metrics
    - metric:
        type: histogram
        name: "timestamp_processing_duration_ms"
        value: '${! json("processing_metadata.processing_duration_ms") }'
        labels:
          format: '${! json("format_detected") }'
          success: '${! if json("quality_score") >= 0.8 { "true" } else { "false" } }'
    
    # Quality metrics
    - metric:
        type: gauge
        name: "timestamp_quality_score"
        value: '${! json("quality_score") }'
    
    # Business metrics
    - metric:
        type: counter
        name: "timestamp_business_hours_total"
        labels:
          is_business_hours: '${! json("time_metadata.is_business_hours").string() }'
        value: 1

# Enable Prometheus endpoint
metrics:
  prometheus:
    path: "/metrics"
    port: 9090
    enabled: true
```

**2. Health Check Endpoints**
```yaml
# Add health monitoring
http:
  address: "0.0.0.0:8080"
  enabled: true
  debug_endpoints: true
  
  # Health check endpoint
  endpoints:
    - path: "/health"
      method: "GET"
      response: |
        {
          "status": "healthy",
          "timestamp": "${timestamp}",
          "version": "1.3.0"
        }
```

### Issue: False Alert Storms

**Symptom:**
```
Alert: TimestampProcessingLatencyHigh firing continuously
Alert: TimestampSuccessRateLow flapping
```

**Solutions:**

**1. Improved Alert Thresholds**
```yaml
# Better alert rules
groups:
- name: timestamp-normalization-improved
  rules:
  - alert: TimestampProcessingLatencyHigh
    expr: histogram_quantile(0.95, rate(timestamp_processing_duration_ms_bucket[5m])) > 50
    for: 10m  # Wait 10 minutes before firing
    labels:
      severity: warning
    annotations:
      summary: "Sustained high timestamp processing latency"
      description: "95th percentile latency {{ $value }}ms for 10+ minutes"

  - alert: TimestampSuccessRateCritical
    expr: rate(timestamp_events_processed_total{success="true"}[5m]) / rate(timestamp_events_processed_total[5m]) < 0.90
    for: 5m   # Critical threshold
    labels:
      severity: critical
    annotations:
      summary: "Critical timestamp processing success rate"
      description: "Success rate {{ $value | humanizePercentage }} below 90%"
      runbook_url: "https://docs.company.com/runbooks/timestamp-normalization"
```

**2. Alert Grouping and Inhibition**
```yaml
# Group related alerts
route:
  group_by: ['service', 'severity']
  group_wait: 30s
  group_interval: 2m
  repeat_interval: 12h
  
  routes:
  - match:
      service: timestamp-normalizer
    group_by: ['alert_type']
    group_interval: 5m

# Inhibit lower-severity alerts when critical alerts are firing
inhibit_rules:
- source_match:
    severity: critical
  target_match:
    severity: warning
  equal: ['service']
```

---

## Disaster Recovery Issues

Problems with backup, restore, and failover scenarios.

### Issue: Data Loss During Failover

**Symptom:**
```
Primary instance failed at 14:23:45
Gap in processed events: 14:23:45 - 14:24:12
Lost approximately 2,700 events
```

**Solutions:**

**1. Implement Checkpointing**
```yaml
# Add processing checkpoints
input:
  kafka:
    checkpoint_limit: 1000  # Checkpoint every 1000 events
    auto_replay_nacks: true
    
pipeline:
  processors:
    # ... processing logic ...
    
    # Checkpoint successful processing
    - mapping: |
        root = this
        root.checkpoint = {
          "processed_at": now().format_timestamp_iso8601(),
          "kafka_offset": metadata("kafka_offset"),
          "kafka_partition": metadata("kafka_partition")
        }
```

**2. Exactly-Once Processing**
```yaml
# Idempotent processing with deduplication
output:
  kafka:
    topic: "normalized-timestamps"
    key: '${! json("event_id") }'  # Use event_id for deduplication
    idempotent: true
    max_in_flight: 1
    retry:
      max_retries: 3
```

### Issue: Backup Recovery Validation

**Symptom:**
```bash
# Restored pipeline produces different results
diff original-output.jsonl restored-output.jsonl
# 500+ differences found
```

**Solutions:**

**1. Deterministic Processing**
```yaml
# Ensure deterministic output
- mapping: |
    root = this
    # Use fixed timestamp for reproducible results in test environments
    root.processing_metadata.normalized_at = if env("ENVIRONMENT") == "test" {
      "2025-01-01T00:00:00.000Z"  # Fixed for testing
    } else {
      now().format_timestamp_iso8601()  # Real timestamp in production
    }
```

**2. Backup Validation Pipeline**
```bash
#!/bin/bash
# backup-validation.sh

# Test restoration process
echo "Testing backup restoration..."

# Restore from backup
expanso restore --source s3://backup-bucket/latest --pipeline timestamp-normalizer-test

# Process test dataset
expanso run timestamp-normalizer-test.yaml < test-dataset.jsonl > restored-output.jsonl

# Compare with expected output
if diff expected-output.jsonl restored-output.jsonl > /dev/null; then
    echo "✅ Backup restoration validated successfully"
else
    echo "❌ Backup restoration validation failed"
    diff expected-output.jsonl restored-output.jsonl | head -20
    exit 1
fi
```

---

## Production Deployment Issues

Problems with deployment, scaling, and operations.

### Issue: Container Resource Limits

**Symptom:**
```
Pod timestamp-normalizer-xyz OOMKilled
Container exceeded memory limit (2Gi)
```

**Solutions:**

**1. Right-Size Resources**
```yaml
# Optimized resource configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timestamp-normalizer
spec:
  template:
    spec:
      containers:
      - name: timestamp-normalizer
        resources:
          requests:
            cpu: "1"
            memory: "1Gi"
          limits:
            cpu: "2"
            memory: "3Gi"  # Increased memory limit
        
        # Memory optimization environment variables
        env:
        - name: GOGC
          value: "80"          # More aggressive garbage collection
        - name: GOMEMLIMIT  
          value: "2800MiB"     # Leave 200MB headroom for OS
```

**2. Vertical Pod Autoscaling**
```yaml
# VPA for automatic resource adjustment
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: timestamp-normalizer-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: timestamp-normalizer
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: timestamp-normalizer
      maxAllowed:
        cpu: "4"
        memory: "8Gi"
      minAllowed:
        cpu: "500m"
        memory: "512Mi"
```

### Issue: Rolling Update Failures

**Symptom:**
```
Deployment rollout stuck: 2/3 replicas updated
ReadinessProbe failures for new pods
```

**Solutions:**

**1. Improved Health Checks**
```yaml
# Better readiness and liveness probes
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      containers:
      - name: timestamp-normalizer
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
        
        livenessProbe:
          httpGet:
            path: /health
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 5
        
        # Graceful shutdown
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        terminationGracePeriodSeconds: 30
```

**2. Rolling Update Strategy**
```yaml
# Conservative rolling update
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Add one pod at a time
      maxUnavailable: 0  # Keep all replicas available
```

---

## Getting Help

If you're still stuck after trying these solutions:

### 1. Enable Debug Logging

```yaml
# Comprehensive debug configuration
logging:
  level: "DEBUG"
  format: "json"
  
pipeline:
  processors:
    # Add debug mappings
    - mapping: |
        root.debug = {
          "stage": "format_detection",
          "input_type": this.timestamp.type(),
          "input_value": this.timestamp,
          "input_length": if this.timestamp.type() == "string" { this.timestamp.string().length() } else { null }
        }
```

### 2. Collect Diagnostic Information

```bash
# Gather system information
expanso version
expanso pipeline status timestamp-normalizer
expanso logs timestamp-normalizer --lines 100 --error
docker stats timestamp-normalizer

# Export configuration
expanso config export timestamp-normalizer > current-config.yaml

# Performance profile
expanso profile timestamp-normalizer --duration 60s > performance-profile.txt
```

### 3. Community Support

- **Documentation:** [Expanso Documentation](https://docs.expanso.io)
- **GitHub Issues:** [Report bugs and request features](https://github.com/expanso-io/expanso)
- **Community Forum:** [Get help from the community](https://community.expanso.io)
- **Support Portal:** [Enterprise support](https://support.expanso.io)

### 4. Professional Support

For production issues requiring immediate assistance:

- **Enterprise Support:** 24/7 support with SLA guarantees
- **Professional Services:** Implementation and optimization consulting
- **Training:** Custom training for your team

---

## Related Resources

- [**Complete Pipeline**](./complete-pipeline) - Production deployment guide
- [**Setup Guide**](./setup) - Environment configuration  
- [**Interactive Explorer**](./explorer) - Visual debugging tool
- [**Step-by-Step Tutorials**](./index) - Learn each transformation in depth
