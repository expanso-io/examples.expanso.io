---
title: Setup Environment for Log Severity Filtering
sidebar_label: Setup
sidebar_position: 2
description: Configure sample logs, environment variables, and deploy a shell pipeline to verify setup
keywords: [setup, environment, configuration, log-processing]
---

# Setup Environment for Log Severity Filtering

Before building the log filtering pipeline, you'll set up sample application logs, configure environment variables, and deploy a minimal pipeline to verify your setup works correctly.

## Prerequisites

- âœ… Expanso edge platform installed ([Installation Guide](https://docs.expanso.io/install))
- âœ… Write access to `/var/log/app/` directory
- âœ… Basic familiarity with YAML configuration and command line tools

## Step 1: Create Sample Log Directory

First, create the directory structure where your application logs will reside:

```bash
# Create log directories with proper permissions
sudo mkdir -p /var/log/app
sudo mkdir -p /var/log/expanso
sudo chown $USER:$USER /var/log/app /var/log/expanso

# Verify directory creation
ls -la /var/log/ | grep -E "(app|expanso)"
```

**Expected output:**
```
drwxr-xr-x  2 youruser youruser 4096 Jan 15 10:30 app
drwxr-xr-x  2 youruser youruser 4096 Jan 15 10:30 expanso
```

## Step 2: Generate Sample Log Data

Create realistic sample logs with mixed JSON and plain text formats to test the filtering pipeline:

```bash
# Create sample JSON logs (structured)
cat > /var/log/app/application.log << 'EOF'
{"timestamp":"2024-01-15T10:30:00Z","level":"INFO","message":"User logged in","user_id":"12345","service":"auth"}
{"timestamp":"2024-01-15T10:30:01Z","level":"DEBUG","message":"Database query executed","query_time":"5ms","service":"api"}
{"timestamp":"2024-01-15T10:30:02Z","level":"ERROR","message":"Payment processing failed","error":"connection timeout","user_id":"67890","service":"payments"}
{"timestamp":"2024-01-15T10:30:03Z","level":"WARN","message":"High memory usage detected","usage_percent":"85","service":"api"}
{"timestamp":"2024-01-15T10:30:04Z","level":"INFO","message":"Cache refreshed","cache_size":"1024MB","service":"api"}
{"timestamp":"2024-01-15T10:30:05Z","level":"ERROR","message":"Database connection lost","error":"network unreachable","service":"api"}
{"timestamp":"2024-01-15T10:30:06Z","level":"WARN","message":"Rate limit approaching","current_rate":"950/1000","service":"auth"}
{"timestamp":"2024-01-15T10:30:07Z","level":"DEBUG","message":"Request processed","response_time":"12ms","service":"api"}
EOF

# Create sample plain text logs (unstructured)
cat > /var/log/app/legacy.log << 'EOF'
2024-01-15 10:30:00 [INFO] Application started successfully
2024-01-15 10:30:01 [DEBUG] Loading configuration from /etc/app.conf
2024-01-15 10:30:02 [ERROR] Failed to connect to external service: timeout after 30s
2024-01-15 10:30:03 [WARN] Disk usage at 90%, cleanup recommended
2024-01-15 10:30:04 [INFO] User session created for ID: 11111
2024-01-15 10:30:05 [ERROR] Critical: Data corruption detected in table users
2024-01-15 10:30:06 [WARN] SSL certificate expires in 7 days
EOF

# Verify log files were created
ls -la /var/log/app/
cat /var/log/app/application.log | wc -l
```

**Expected output:**
```
-rw-r--r-- 1 youruser youruser 1458 Jan 15 10:30 application.log
-rw-r--r-- 1 youruser youruser  567 Jan 15 10:30 legacy.log
8
```

## Step 3: Configure Environment Variables

Set up environment variables that will be used for processing metadata and node identification:

```bash
# Set processing node identifier
export NODE_ID="edge-001"

# Verify environment variable
echo "NODE_ID: $NODE_ID"

# Make the environment variable persistent (optional)
echo 'export NODE_ID="edge-001"' >> ~/.bashrc
```

For production deployments, you can configure environment variables through:
- Docker environment variables: `-e NODE_ID=edge-001`
- Kubernetes ConfigMaps or Secrets
- System environment files (`/etc/environment`)

## Step 4: Deploy Shell Pipeline

Before adding severity filtering, deploy a minimal "shell" pipeline that just reads and outputs logs. This verifies your setup works correctly.

Create `shell-filter-severity.yaml`:

```yaml title="shell-filter-severity.yaml"
# Shell pipeline to verify log file access and output functionality
input:
  file:
    paths:
      - /var/log/app/*.log
    codec: lines

pipeline:
  processors:
    # Add basic processing timestamp only
    - mapping: |
        root = this
        root.processed_at = now()
        root.node_id = env("NODE_ID").or("unknown")

output:
  stdout:
    codec: lines
```

Deploy the shell pipeline:

```bash
# Deploy to Expanso edge platform
expanso run shell-filter-severity.yaml

# Verify deployment succeeded (check for running status)
expanso status shell-filter-severity
```

**Expected output:**
```
Pipeline: shell-filter-severity
Status: RUNNING
Input: file (/var/log/app/*.log)
Output: stdout
```

## Step 5: Test Shell Pipeline

Generate some log activity to test the pipeline is reading and processing logs correctly:

```bash
# Add a new log entry to trigger processing
echo '{"timestamp":"2024-01-15T10:35:00Z","level":"INFO","message":"Test log entry","service":"test"}' >> /var/log/app/application.log

# Check the Expanso output logs for processed entries
expanso logs shell-filter-severity --tail=5
```

**Expected output:** You should see the log entries with added `processed_at` and `node_id` fields:
```json
{"timestamp":"2024-01-15T10:35:00Z","level":"INFO","message":"Test log entry","service":"test","processed_at":"2024-01-15T10:35:01.123Z","node_id":"edge-001"}
```

## Step 6: Verify Log File Monitoring

Test that the pipeline correctly monitors multiple log files and handles new entries:

```bash
# Write to both log files simultaneously
echo '{"timestamp":"2024-01-15T10:36:00Z","level":"ERROR","message":"New error","service":"monitoring"}' >> /var/log/app/application.log
echo "2024-01-15 10:36:00 [WARN] New warning message" >> /var/log/app/legacy.log

# Watch the pipeline output for 10 seconds
timeout 10s expanso logs shell-filter-severity --follow

# Stop watching and check the last few entries
expanso logs shell-filter-severity --tail=3
```

**Expected output:** You should see entries from both log files being processed with metadata added.

:::tip Success!
If you see log entries with `processed_at` and `node_id` fields being output from both log files, your environment is correctly configured!

**Next step:** Clean up the shell pipeline and start building the actual filtering pipeline.
:::

## Step 7: Clean Up Shell Pipeline

Stop the shell pipeline before proceeding to the actual implementation:

```bash
# Stop the shell pipeline
expanso stop shell-filter-severity

# Remove the configuration file
rm shell-filter-severity.yaml

# Verify pipeline is stopped
expanso status | grep shell-filter-severity || echo "Shell pipeline cleaned up successfully"
```

## Step 8: Verify Prerequisites for Next Steps

Before proceeding, verify all required resources are ready:

```bash
# Run this verification script
cat > verify-setup.sh << 'EOF'
#!/bin/bash

echo "=== Log Processing Setup Verification ==="
echo

# Check directories
echo "ğŸ“ Directory Setup:"
[ -d /var/log/app ] && echo "âœ… /var/log/app exists" || echo "âŒ /var/log/app missing"
[ -d /var/log/expanso ] && echo "âœ… /var/log/expanso exists" || echo "âŒ /var/log/expanso missing"
echo

# Check permissions
echo "ğŸ”‘ Permissions:"
[ -w /var/log/app ] && echo "âœ… Write access to /var/log/app" || echo "âŒ No write access to /var/log/app"
[ -w /var/log/expanso ] && echo "âœ… Write access to /var/log/expanso" || echo "âŒ No write access to /var/log/expanso"
echo

# Check log files
echo "ğŸ“„ Log Files:"
[ -f /var/log/app/application.log ] && echo "âœ… Sample JSON logs present ($(wc -l < /var/log/app/application.log) lines)" || echo "âŒ No JSON logs"
[ -f /var/log/app/legacy.log ] && echo "âœ… Sample plain text logs present ($(wc -l < /var/log/app/legacy.log) lines)" || echo "âŒ No plain text logs"
echo

# Check environment
echo "ğŸŒ Environment:"
[ ! -z "$NODE_ID" ] && echo "âœ… NODE_ID set to: $NODE_ID" || echo "âŒ NODE_ID not set"
echo

# Check Expanso platform
echo "ğŸš€ Expanso Platform:"
if command -v expanso > /dev/null; then
  echo "âœ… Expanso CLI available"
  if expanso version > /dev/null 2>&1; then
    echo "âœ… Expanso platform responsive"
  else
    echo "âŒ Expanso platform not responding"
  fi
else
  echo "âŒ Expanso CLI not found"
fi
echo

echo "=== Setup Verification Complete ==="
EOF

chmod +x verify-setup.sh
./verify-setup.sh
rm verify-setup.sh
```

**Expected output:**
```
=== Log Processing Setup Verification ===

ğŸ“ Directory Setup:
âœ… /var/log/app exists
âœ… /var/log/expanso exists

ğŸ”‘ Permissions:
âœ… Write access to /var/log/app
âœ… Write access to /var/log/expanso

ğŸ“„ Log Files:
âœ… Sample JSON logs present (9 lines)
âœ… Sample plain text logs present (7 lines)

ğŸŒ Environment:
âœ… NODE_ID set to: edge-001

ğŸš€ Expanso Platform:
âœ… Expanso CLI available
âœ… Expanso platform responsive

=== Setup Verification Complete ===
```

---

## Next Steps

Your environment is now configured and ready for building the log filtering pipeline.

**Continue to:** [Step 1: Parse JSON & Add Metadata](./step-1-parse-json-add-metadata) to start building the filtering functionality.

**Need help?** Check the [Troubleshooting Guide](./troubleshooting) for solutions to common issues.
