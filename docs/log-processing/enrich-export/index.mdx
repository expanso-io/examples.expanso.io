---
title: Log Enrichment & S3 Export
sidebar_label: Introduction
sidebar_position: 1
description: Learn to enrich logs with metadata and export to Amazon S3 in batches for cost-effective analytics
keywords: [log-enrichment, s3-export, metadata, lineage, batching, cloud-storage, analytics]
---

# Log Enrichment & S3 Export

Transform raw logs into analytics-ready datasets with metadata enrichment and efficient cloud storage.

## The Problem

Application logs lack context and aren't optimized for analytics:
- No data lineage or processing metadata
- Individual log writes create expensive S3 API calls
- Missing tracking context for debugging and compliance
- Not structured for business intelligence queries

## The Solution

Learn 5 log processing techniques:

1. **Generate/Capture Logs** - File input, syslog, or generated data for testing with consistent log streams
2. **Enrich with Lineage** - Environment variables and processing timestamps for full traceability
3. **Restructure Data** - Bloblang mapping to separate business data from operational metadata
4. **Batch Processing** - Time-based or count-based batching to reduce S3 API calls
5. **S3 Export** - JSON Lines format with partitioning for analytics-ready data

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See each enrichment and batching technique with side-by-side transformations

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [Generate Test Data](./step-1-generate-test-data)
2. [Add Lineage Metadata](./step-2-add-lineage-metadata)
3. [Restructure Format](./step-3-restructure-format)
4. [Configure Batching](./step-4-configure-batching)
5. [Export to S3](./step-5-export-s3)

### [Complete Pipeline](./complete-log-enrichment)
Download the production-ready solution
