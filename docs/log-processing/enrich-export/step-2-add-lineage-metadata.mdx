---
title: Step 2 - Add Lineage Metadata
sidebar_label: Step 2 - Add Lineage Metadata
sidebar_position: 5
description: Enrich logs with processing metadata for audit trails, debugging, and compliance tracking
keywords: [lineage, metadata, audit-trail, tracking, compliance, debugging]
---

# Step 2: Add Lineage Metadata

Learn how to enrich your logs with lineage metadata that tracks where and when data was processed. This critical step enables audit trails, debugging, and compliance reporting by adding processing context to every log message.

## What You'll Build

In this step, you'll add lineage metadata including:

- **Node identification** - Which edge node processed the data
- **Pipeline tracking** - Which specific pipeline performed the processing
- **Processing timestamps** - Exact time when enrichment occurred
- **Environment context** - Deployment environment and version information
- **Performance metrics** - Processing duration and resource usage

## Why Lineage Metadata Matters

**Compliance:** GDPR/CCPA require tracking data processing activities and locations
**Debugging:** Quickly identify which node or pipeline caused data issues
**Performance:** Track processing latency and identify bottlenecks
**Auditing:** Complete audit trail for regulatory and security requirements

## Core Lineage Concepts

### 1. Node Identification

Track which specific edge node processed each message:

```json
{
  "lineage_node_id": "edge-node-01",
  "lineage_node_region": "us-west-2",
  "lineage_node_zone": "us-west-2a"
}
```

### 2. Pipeline Context

Record which pipeline and version performed processing:

```json
{
  "lineage_pipeline": "log-enrichment-s3-demo",
  "lineage_pipeline_version": "1.2.3",
  "lineage_step": "enrichment"
}
```

### 3. Temporal Tracking

Capture precise timing information:

```json
{
  "lineage_processed_at": "2024-01-15T10:30:00.123Z",
  "lineage_processing_duration_ms": 42,
  "lineage_batch_id": "batch_20240115_103000"
}
```

## Implementation

### Basic Lineage Addition

Start by adding fundamental lineage fields to your generated logs:

```yaml title="step2-basic-lineage.yaml"
input:
  generate:
    interval: 2s
    mapping: |
      root.id = uuid_v4()
      root.timestamp = now()
      root.level = "INFO"
      root.service = "demo-service"
      root.message = "Demo log message from edge"
      root.user_id = "user_123"
      root.request_id = uuid_v4()

pipeline:
  processors:
    # Add basic lineage metadata
    - mapping: |
        # Preserve all original fields
        root = this
        
        # Add lineage information
        root.lineage_node_id = env("NODE_ID").or("edge-node-demo")
        root.lineage_pipeline = "log-enrichment-s3-demo"
        root.lineage_processed_at = now()

output:
  stdout: {}
```

Deploy and test basic lineage:

```bash
# Set environment variable for node identification
export NODE_ID="edge-node-01"

# Deploy pipeline with lineage
expanso pipeline deploy step2-basic-lineage.yaml --name basic-lineage

# Watch enriched output
expanso pipeline logs basic-lineage --follow --lines 5
```

**Expected output:**
```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "service": "demo-service",
  "message": "Demo log message from edge",
  "user_id": "user_123",
  "request_id": "b2c3d4e5-f6a7-8901-bcde-f12345678901",
  "lineage_node_id": "edge-node-01",
  "lineage_pipeline": "log-enrichment-s3-demo",
  "lineage_processed_at": "2024-01-15T10:30:00.145Z"
}
```

### Enhanced Lineage with Environment Context

Add comprehensive environment and deployment information:

```yaml title="step2-enhanced-lineage.yaml"
input:
  generate:
    interval: 2s
    mapping: |
      root.id = uuid_v4()
      root.timestamp = now()
      root.level = ["INFO", "WARN", "ERROR"].index(random_int() % 3)
      root.service = ["auth-service", "payment-service", "user-service"].index(random_int() % 3)
      root.message = "Demo log from " + this.service
      root.user_id = "user_" + (random_int() % 10)
      root.request_id = uuid_v4()

pipeline:
  processors:
    # Add comprehensive lineage metadata
    - mapping: |
        # Preserve original data
        root = this
        
        # Node identification
        root.lineage_node_id = env("NODE_ID").or("edge-node-" + uuid_v4().slice(0, 8))
        root.lineage_node_region = env("AWS_REGION").or("us-east-1")
        root.lineage_node_zone = env("AVAILABILITY_ZONE").or(env("AWS_REGION").or("us-east-1") + "a")
        
        # Pipeline context
        root.lineage_pipeline = "log-enrichment-s3-demo"
        root.lineage_pipeline_version = env("PIPELINE_VERSION").or("1.0.0")
        root.lineage_step = "metadata_enrichment"
        
        # Processing timestamps
        root.lineage_processed_at = now()
        root.lineage_batch_id = "batch_" + now().format_timestamp("20060102_150405", "UTC")
        
        # Environment context
        root.lineage_environment = env("ENVIRONMENT").or("production")
        root.lineage_deployment_id = env("DEPLOYMENT_ID").or("deploy_" + uuid_v4().slice(0, 8))
        
        # Processing metadata
        let original_timestamp = this.timestamp.parse_timestamp("2006-01-02T15:04:05Z")
        let current_timestamp = now()
        root.lineage_processing_delay_ms = ($current_timestamp.ts_unix_nano() - $original_timestamp.ts_unix_nano()) / 1000000

output:
  stdout: {}
```

Set up comprehensive environment variables:

```bash
# Core identification
export NODE_ID="edge-node-prod-01"
export AWS_REGION="us-west-2"
export AVAILABILITY_ZONE="us-west-2a"

# Pipeline context
export PIPELINE_VERSION="1.2.3"
export ENVIRONMENT="production"
export DEPLOYMENT_ID="deploy_20240115_103000"

# Deploy enhanced lineage pipeline
expanso pipeline stop basic-lineage
expanso pipeline deploy step2-enhanced-lineage.yaml --name enhanced-lineage

# Monitor enhanced output
expanso pipeline logs enhanced-lineage --follow --lines 3
```

**Expected output:**
```json
{
  "id": "...",
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "service": "auth-service",
  "message": "Demo log from auth-service",
  "user_id": "user_5",
  "request_id": "...",
  "lineage_node_id": "edge-node-prod-01",
  "lineage_node_region": "us-west-2", 
  "lineage_node_zone": "us-west-2a",
  "lineage_pipeline": "log-enrichment-s3-demo",
  "lineage_pipeline_version": "1.2.3",
  "lineage_step": "metadata_enrichment",
  "lineage_processed_at": "2024-01-15T10:30:00.167Z",
  "lineage_batch_id": "batch_20240115_103000",
  "lineage_environment": "production",
  "lineage_deployment_id": "deploy_20240115_103000",
  "lineage_processing_delay_ms": 167
}
```

### Production-Ready Lineage with Performance Tracking

Add performance metrics and error handling for production deployments:

```yaml title="step2-production-lineage.yaml"
input:
  generate:
    interval: 1s
    mapping: |
      root.id = uuid_v4()
      root.timestamp = now()
      root.level = ["INFO", "INFO", "INFO", "WARN", "ERROR"].index(random_int() % 5)
      root.service = ["auth-service", "payment-service", "user-service", "notification-service"].index(random_int() % 4)
      root.message = "Application log from " + this.service + " at severity " + this.level
      root.user_id = "user_" + (random_int() % 100)
      root.request_id = uuid_v4()
      
      # Add some application-specific fields
      root.duration_ms = random_int() % 5000 + 100
      root.status_code = if this.level == "ERROR" { 500 } else { 200 }

pipeline:
  processors:
    # Performance tracking preprocessor
    - mapping: |
        # Add processing start time for performance tracking
        root = this
        root._processing_start = now()
    
    # Main lineage enrichment processor
    - mapping: |
        # Preserve all original data (except internal processing fields)
        root = this.without("_processing_start")
        
        # Calculate processing metrics
        let processing_start = this._processing_start
        let processing_end = now()
        let processing_duration_ns = $processing_end.ts_unix_nano() - $processing_start.ts_unix_nano()
        
        # Core lineage fields
        root.lineage = {
          # Node identification
          "node_id": env("NODE_ID").or("edge-node-" + uuid_v4().slice(0, 8)),
          "node_region": env("AWS_REGION").or("us-east-1"),
          "node_zone": env("AVAILABILITY_ZONE").or(env("AWS_REGION").or("us-east-1") + "a"),
          "node_instance_type": env("INSTANCE_TYPE").or("unknown"),
          
          # Pipeline context
          "pipeline_name": "log-enrichment-s3-demo",
          "pipeline_version": env("PIPELINE_VERSION").or("1.0.0"),
          "pipeline_step": "lineage_enrichment",
          "pipeline_config_hash": env("CONFIG_HASH").or("unknown"),
          
          # Temporal tracking
          "processed_at": $processing_end,
          "processing_duration_ms": $processing_duration_ns / 1000000,
          "batch_id": "batch_" + $processing_end.format_timestamp("20060102_150405", "UTC"),
          "sequence_number": counter("processed_messages"),
          
          # Environment context
          "environment": env("ENVIRONMENT").or("production"),
          "deployment_id": env("DEPLOYMENT_ID").or("unknown"),
          "git_commit": env("GIT_COMMIT").or("unknown"),
          "build_timestamp": env("BUILD_TIMESTAMP").or("unknown"),
          
          # Data quality metrics
          "original_timestamp": this.timestamp,
          "processing_delay_ms": ($processing_end.ts_unix_nano() - this.timestamp.parse_timestamp("2006-01-02T15:04:05Z").ts_unix_nano()) / 1000000,
          "message_size_bytes": this.string().length(),
          
          # Quality flags
          "has_user_id": this.user_id != null,
          "has_request_id": this.request_id != null,
          "is_error_level": this.level == "ERROR"
        }

    # Add performance monitoring
    - mapping: |
        root = this
        
        # Add performance alerts for slow processing
        if this.lineage.processing_duration_ms > 1000 {
          root.lineage.performance_alert = "HIGH_PROCESSING_LATENCY"
        }
        
        # Add data quality alerts
        if this.lineage.processing_delay_ms > 60000 {
          root.lineage.quality_alert = "HIGH_DATA_DELAY"
        }
        
        if this.lineage.message_size_bytes > 10000 {
          root.lineage.size_alert = "LARGE_MESSAGE_SIZE" 
        }

output:
  broker:
    pattern: fan_out
    outputs:
      # Main output
      - stdout: {}
      
      # Performance monitoring output
      - file:
          path: /tmp/lineage-performance.jsonl
          codec: lines

# Add metrics collection
metrics:
  prometheus:
    prefix: lineage_enrichment
    push_gateway:
      url: http://localhost:9091
      job_name: log_enrichment
```

Deploy production lineage with full environment:

```bash
# Set comprehensive environment
export NODE_ID="edge-node-prod-01"
export AWS_REGION="us-west-2"
export AVAILABILITY_ZONE="us-west-2a"
export INSTANCE_TYPE="c5.large"
export PIPELINE_VERSION="2.1.0"
export ENVIRONMENT="production"
export DEPLOYMENT_ID="deploy_$(date +%Y%m%d_%H%M%S)"
export CONFIG_HASH="$(echo 'production-config' | sha256sum | cut -d' ' -f1)"
export GIT_COMMIT="$(git rev-parse --short HEAD 2>/dev/null || echo 'unknown')"
export BUILD_TIMESTAMP="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# Deploy production lineage
expanso pipeline stop enhanced-lineage
expanso pipeline deploy step2-production-lineage.yaml --name production-lineage

# Monitor output with lineage structure
expanso pipeline logs production-lineage --follow --lines 2 | jq '.lineage'
```

**Expected lineage structure:**
```json
{
  "node_id": "edge-node-prod-01",
  "node_region": "us-west-2",
  "node_zone": "us-west-2a",
  "node_instance_type": "c5.large",
  "pipeline_name": "log-enrichment-s3-demo",
  "pipeline_version": "2.1.0",
  "pipeline_step": "lineage_enrichment",
  "pipeline_config_hash": "abc123...",
  "processed_at": "2024-01-15T10:30:00.345Z",
  "processing_duration_ms": 2.3,
  "batch_id": "batch_20240115_103000",
  "sequence_number": 42,
  "environment": "production",
  "deployment_id": "deploy_20240115_103000",
  "git_commit": "a1b2c3d",
  "build_timestamp": "2024-01-15T09:15:30Z",
  "original_timestamp": "2024-01-15T10:30:00Z",
  "processing_delay_ms": 345,
  "message_size_bytes": 1247,
  "has_user_id": true,
  "has_request_id": true,
  "is_error_level": false
}
```

## Advanced Lineage Patterns

### Hierarchical Pipeline Tracking

Track data through multiple pipeline stages:

```yaml
# Track pipeline stage hierarchy
root.lineage.stage_hierarchy = [
  {
    "stage": "ingestion",
    "timestamp": env("INGESTION_TIMESTAMP"),
    "node": env("INGESTION_NODE")
  },
  {
    "stage": "enrichment", 
    "timestamp": now(),
    "node": env("NODE_ID")
  }
]
```

### Data Source Tracking

Track original data sources:

```yaml
# Add source lineage
root.lineage.data_source = {
  "type": "application_logs",
  "source_system": this.service,
  "source_file": env("SOURCE_FILE").or("generated"),
  "source_line_number": counter("source_lines"),
  "ingestion_method": "file_tail"
}
```

### Privacy and Compliance Metadata

Add privacy-related tracking for compliance:

```yaml
# Privacy compliance tracking
root.lineage.privacy = {
  "contains_pii": this.user_id != null || this.email != null,
  "gdpr_applicable": env("GDPR_REGION") == "true",
  "retention_policy": env("RETENTION_POLICY").or("default"),
  "consent_status": env("CONSENT_REQUIRED") == "true",
  "pseudonymization_applied": false,
  "encryption_applied": false
}
```

## Lineage Data Validation

### Verify Lineage Completeness

Check that all required lineage fields are present:

```bash
# Check for missing lineage fields
cat /tmp/lineage-performance.jsonl | jq 'select(.lineage.node_id == null or .lineage.processed_at == null)'

# Verify processing delays are reasonable
cat /tmp/lineage-performance.jsonl | jq '.lineage.processing_delay_ms' | sort -n | tail -10

# Check processing performance
cat /tmp/lineage-performance.jsonl | jq '.lineage.processing_duration_ms' | awk '{sum+=$1; count++} END {print "Average:", sum/count "ms"}'
```

### Monitor Lineage Quality

Track lineage metadata quality over time:

```bash
# Count messages with complete lineage
total_messages=$(cat /tmp/lineage-performance.jsonl | wc -l)
complete_lineage=$(cat /tmp/lineage-performance.jsonl | jq 'select(.lineage.node_id != null and .lineage.processed_at != null)' | wc -l)
echo "Lineage completeness: $complete_lineage/$total_messages"

# Check for performance alerts
cat /tmp/lineage-performance.jsonl | jq 'select(.lineage.performance_alert != null)'

# Monitor data quality flags
cat /tmp/lineage-performance.jsonl | jq '.lineage | {has_user_id, has_request_id, is_error_level}' | sort | uniq -c
```

## Troubleshooting Lineage Issues

### Missing Environment Variables

**Problem:** Lineage fields show "unknown" or default values

**Solutions:**

1. **Check environment variables:**
```bash
# Verify all required variables are set
env | grep -E "(NODE_ID|AWS_REGION|PIPELINE_VERSION|ENVIRONMENT)"
```

2. **Add fallback logic:**
```yaml
root.lineage_node_id = env("NODE_ID").or(env("HOSTNAME")).or("edge-node-" + uuid_v4().slice(0, 8))
```

3. **Use metadata file:**
```bash
# Create metadata file
cat > /etc/expanso/metadata.json << EOF
{
  "node_id": "edge-node-prod-01",
  "region": "us-west-2",
  "environment": "production"
}
EOF

# Reference in mapping
root.lineage_node_id = file("/etc/expanso/metadata.json").parse_json().node_id
```

### Performance Issues

**Problem:** Lineage enrichment adds too much latency

**Solutions:**

1. **Optimize mapping logic:**
```yaml
# Pre-calculate expensive operations
let processing_time = now()
let node_info = env("NODE_ID") + ":" + env("AWS_REGION")

root.lineage = {
  "processed_at": $processing_time,
  "node_info": $node_info
}
```

2. **Batch lineage updates:**
```yaml
# Add lineage in batches rather than per message
batching:
  count: 100
  processors:
    - mapping: |
        # Add batch-level lineage
        root.batch_lineage = {
          "batch_processed_at": now(),
          "batch_node": env("NODE_ID"),
          "batch_size": this.length()
        }
```

### Storage Overhead

**Problem:** Lineage metadata increases message size significantly

**Solutions:**

1. **Compress lineage fields:**
```yaml
# Use abbreviated field names
root.lin = {
  "nid": env("NODE_ID").slice(0, 8),  # Abbreviated node ID
  "pat": now().format_timestamp("150405", "UTC"),  # Time as HHMMSS
  "pip": "enrich"  # Abbreviated pipeline name
}
```

2. **External lineage storage:**
```yaml
# Store lineage separately and reference by ID
root.lineage_id = uuid_v4().slice(0, 8)

# Send lineage to separate storage
output:
  broker:
    pattern: fan_out
    outputs:
      - stdout: {}  # Main data without lineage
      - redis:      # Lineage storage
          url: redis://localhost:6379
          key: lineage:${! json("lineage_id") }
          value: ${! json("lineage") }
```

## Real-World Use Cases

### Compliance Auditing

Track data for regulatory compliance:

```yaml
# GDPR compliance lineage
root.lineage.compliance = {
  "gdpr_applicable": true,
  "data_controller": "MyCompany Inc",
  "processing_legal_basis": "legitimate_interest",
  "retention_period_days": 365,
  "data_protection_impact_assessment": "DPIA_2024_001"
}
```

### Incident Response

Enable rapid incident investigation:

```yaml
# Incident response metadata
root.lineage.incident_response = {
  "trace_id": this.request_id,
  "processing_chain": [
    {"component": "ingestion", "timestamp": this.timestamp},
    {"component": "enrichment", "timestamp": now()}
  ],
  "error_context": if this.level == "ERROR" {
    {
      "error_source": this.service,
      "error_category": "application",
      "escalation_required": true
    }
  } else { null }
}
```

### Performance Optimization

Track processing performance for optimization:

```yaml
# Performance tracking lineage
root.lineage.performance = {
  "processing_latency_p95": env("PROCESSING_P95").or("unknown"),
  "queue_depth": env("QUEUE_DEPTH").or("0").number(),
  "cpu_usage": env("CPU_USAGE").or("0").number(),
  "memory_usage": env("MEMORY_USAGE").or("0").number(),
  "throughput_per_second": counter("messages") / (now().ts_unix() - env("PIPELINE_START_TIME").or("0").number())
}
```

## Key Takeaways

After completing this step, you understand:

✅ **Lineage Fundamentals:** Core concepts of data lineage and why it matters
✅ **Metadata Enrichment:** How to add comprehensive processing context
✅ **Performance Tracking:** Measuring and monitoring processing performance
✅ **Compliance Support:** Adding metadata for regulatory requirements
✅ **Production Patterns:** Best practices for production lineage implementation

## Next Steps

Your logs now have complete processing lineage! The next step restructures data for analytics:

<div style={{display: 'flex', gap: '1.5rem', marginTop: '2rem', marginBottom: '3rem', flexWrap: 'wrap', justifyContent: 'flex-start'}}>
  <a href="./step-3-restructure-format" className="button button--primary button--lg" style={{display: 'inline-flex', alignItems: 'center', justifyContent: 'center', textDecoration: 'none', borderRadius: '8px', padding: '1rem 2rem', fontWeight: '600', minWidth: '240px', boxShadow: '0 2px 8px rgba(0,0,0,0.15)', cursor: 'pointer', transition: 'all 0.2s ease'}}>
    Step 3: Restructure Format
  </a>
  <a href="./complete-log-enrichment" className="button button--secondary button--lg" style={{display: 'inline-flex', alignItems: 'center', justifyContent: 'center', textDecoration: 'none', borderRadius: '8px', padding: '1rem 2rem', fontWeight: '600', minWidth: '240px', boxShadow: '0 2px 8px rgba(0,0,0,0.15)', cursor: 'pointer', transition: 'all 0.2s ease'}}>
    Skip to Complete Pipeline
  </a>
</div>

---

**Next:** [Restructure format](./step-3-restructure-format) to optimize data for analytics
