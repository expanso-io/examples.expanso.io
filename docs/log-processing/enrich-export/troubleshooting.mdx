---
title: Log Enrichment Troubleshooting
sidebar_label: Troubleshooting
sidebar_position: 10
description: Comprehensive troubleshooting guide for log enrichment and S3 export pipeline issues
keywords: [troubleshooting, debugging, errors, performance, monitoring]
---

# Log Enrichment Troubleshooting

This comprehensive guide helps you diagnose and resolve common issues with the log enrichment and S3 export pipeline. Issues are organized by category with diagnostic steps and proven solutions.

## Quick Diagnostic Commands

Start troubleshooting with these essential diagnostic commands:

```bash
# Check pipeline status
expanso pipeline status log-enrichment-production

# View recent logs
expanso pipeline logs log-enrichment-production --lines 50

# Check metrics
expanso pipeline metrics log-enrichment-production

# Test AWS connectivity
aws s3 ls s3://your-bucket-name --profile your-profile

# Validate configuration
expanso pipeline validate enrich-export-complete.yaml

# Check system resources
top -p $(pgrep expanso)
df -h /tmp
netstat -tulpn | grep :expanso
```

---

## Pipeline Deployment Issues

### Issue: Pipeline Fails to Deploy

**Symptoms:**
- `expanso pipeline deploy` command fails
- "Configuration validation error" messages
- Pipeline status shows "FAILED" or "PENDING"

**Diagnosis:**
```bash
# Validate YAML syntax
expanso pipeline validate enrich-export-complete.yaml

# Check for missing environment variables
env | grep -E "(NODE_ID|AWS_REGION|S3_BUCKET_NAME)"

# Verify platform connectivity
expanso status
```

**Solutions:**

**1. YAML Syntax Errors**
```bash
# Use YAML validator
python -c "import yaml; yaml.safe_load(open('enrich-export-complete.yaml'))"

# Check indentation (must be spaces, not tabs)
cat -A enrich-export-complete.yaml | grep -E "^\s*\t"
```

**2. Missing Environment Variables**
```bash
# Set required variables
export NODE_ID="edge-node-prod-01"
export AWS_REGION="us-west-2"
export S3_BUCKET_NAME="your-production-logs"

# Verify all variables are set
cat enrich-export-complete.yaml | grep -o '\${[^}]*}' | sort -u
```

**3. Platform Authentication Issues**
```bash
# Re-authenticate with platform
expanso auth login

# Check platform status
expanso config show
```

### Issue: Pipeline Starts But Immediately Fails

**Symptoms:**
- Pipeline deploys successfully but stops within minutes
- Error messages in pipeline logs
- Status shows "CRASHED" or "ERROR"

**Diagnosis:**
```bash
# Check detailed error logs
expanso pipeline logs log-enrichment-production --lines 100 | grep -i error

# Check resource usage
expanso pipeline metrics log-enrichment-production --metric memory_usage
expanso pipeline metrics log-enrichment-production --metric cpu_usage
```

**Solutions:**

**1. Memory/Resource Issues**
```yaml
# Reduce memory usage in configuration
buffer:
  memory:
    limit: "50MB"  # Reduce from default

batching:
  count: 50      # Smaller batches
  byte_size: 1MB # Smaller size limit
```

**2. Input Source Errors**
```yaml
# Test with simple generated input
input:
  generate:
    interval: 5s
    mapping: 'root = {"test": "message", "timestamp": now()}'
```

**3. Permission Issues**
```bash
# Test file permissions
touch /var/log/expanso/test.log && rm /var/log/expanso/test.log

# Test AWS permissions
aws s3 cp /dev/null s3://your-bucket/test.txt --profile your-profile
aws s3 rm s3://your-bucket/test.txt --profile your-profile
```

---

## Input Processing Issues

### Issue: No Data Being Processed

**Symptoms:**
- Pipeline runs but no messages processed
- Zero metrics in monitoring
- No output files generated

**Diagnosis:**
```bash
# Check if input source is producing data
tail -f /var/log/app/*.log  # For file input
nc -u localhost 1514       # For syslog input

# Check input metrics
expanso pipeline metrics log-enrichment-production --metric input_received
```

**Solutions:**

**1. File Input Issues**
```yaml
# Debug file input with explicit paths
input:
  file:
    paths:
      - /var/log/app/app.log  # Specific file instead of wildcard
    codec: lines
    processors:
      - mapping: |
          # Add debug info
          root = this
          root.debug_file_info = {
            "file": file_path(),
            "offset": file_offset(),
            "raw_content": this
          }
```

**2. Generated Input Not Working**
```yaml
# Simplify generated input for testing
input:
  generate:
    interval: 1s
    count: 10  # Generate only 10 messages for testing
    mapping: |
      root = {
        "id": uuid_v4(),
        "message": "test message " + counter("test"),
        "timestamp": now()
      }
```

**3. Syslog Input Problems**
```bash
# Test syslog connectivity
echo "test message" | nc -u localhost 1514

# Check port binding
netstat -ulpn | grep 1514

# Test with simple syslog input
input:
  socket_server:
    network: udp
    address: "0.0.0.0:1514"
    # No processors initially for testing
```

### Issue: Input Processing Errors

**Symptoms:**
- Some messages processed, others fail
- Parse errors in logs
- Inconsistent message counts

**Diagnosis:**
```bash
# Check for parsing errors
expanso pipeline logs log-enrichment-production --lines 200 | grep -i "parse\|invalid\|error"

# Sample raw input data
head -20 /var/log/app/app.log
```

**Solutions:**

**1. JSON Parsing Issues**
```yaml
# Add error handling for invalid JSON
pipeline:
  processors:
    - mapping: |
        # Try to parse JSON, fallback to raw message
        root = this.parse_json().catch({
          "raw_message": this,
          "parse_error": true,
          "parsed_at": now()
        })
```

**2. Syslog Format Issues**
```yaml
# Handle different syslog formats
pipeline:
  processors:
    - mapping: |
        # Try RFC5424, fallback to RFC3164, then raw
        root = this.parse_syslog_rfc5424().catch(
          this.parse_syslog_rfc3164().catch({
            "raw_syslog": this,
            "format": "unknown"
          })
        )
```

**3. Character Encoding Issues**
```yaml
# Handle different character encodings
input:
  file:
    paths: ["/var/log/app/*.log"]
    codec: lines
    encoding: "utf-8"  # Specify encoding explicitly
```

---

## Data Processing Issues

### Issue: Lineage Metadata Missing

**Symptoms:**
- Output messages missing lineage fields
- Lineage fields contain "unknown" or default values
- Inconsistent metadata across messages

**Diagnosis:**
```bash
# Check environment variables
env | grep -E "(NODE_ID|AWS_REGION|ENVIRONMENT)"

# Sample output to check lineage structure
expanso pipeline output log-enrichment-production --limit 5 | jq '.metadata.lineage'
```

**Solutions:**

**1. Missing Environment Variables**
```bash
# Set comprehensive environment
export NODE_ID="edge-node-$(hostname)-$(date +%s)"
export AWS_REGION="$(curl -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null || echo 'us-east-1')"
export ENVIRONMENT="production"
export PIPELINE_VERSION="$(git describe --tags 2>/dev/null || echo '1.0.0')"
```

**2. Environment Variable Not Available in Container**
```yaml
# Use fallback values in mapping
pipeline:
  processors:
    - mapping: |
        root = this
        root.lineage = {
          "node_id": env("NODE_ID").or(env("HOSTNAME")).or("unknown-node"),
          "region": env("AWS_REGION").or("unknown-region"),
          "environment": env("ENVIRONMENT").or("unknown-env"),
          "processed_at": now()
        }
```

**3. Performance Issues with Lineage Generation**
```yaml
# Cache expensive operations
pipeline:
  processors:
    - mapping: |
        # Calculate once, reuse
        let node_info = env("NODE_ID") + "@" + env("AWS_REGION")
        let processing_timestamp = now()
        
        root = this
        root.lineage = {
          "node_info": $node_info,
          "processed_at": $processing_timestamp
        }
```

### Issue: Data Restructuring Failures

**Symptoms:**
- Output missing event or metadata sections
- Field mapping errors in logs
- Inconsistent output structure

**Diagnosis:**
```bash
# Check for field mapping errors
expanso pipeline logs log-enrichment-production | grep -i "field\|mapping\|structure"

# Compare input vs output structure
expanso pipeline input log-enrichment-production --limit 1 | jq .
expanso pipeline output log-enrichment-production --limit 1 | jq .
```

**Solutions:**

**1. Required Fields Missing**
```yaml
# Add field validation and defaults
pipeline:
  processors:
    - mapping: |
        # Validate required fields exist
        if this.id == null {
          error("Missing required field: id")
        }
        
        root.event = {
          "id": this.id,
          "timestamp": this.timestamp.or(now()),
          "level": this.level.or("INFO"),
          "service": this.service.or("unknown"),
          "message": this.message.or(""),
          "user_id": this.user_id,
          "request_id": this.request_id
        }
```

**2. Dynamic Field Mapping**
```yaml
# Handle variable input structures
pipeline:
  processors:
    - mapping: |
        # Create event from available fields
        root.event = this.pick("id", "timestamp", "level", "service", "message", "user_id", "request_id")
        
        # Add any remaining fields to metadata
        root.metadata = {
          "lineage": {
            "processed_at": now(),
            "node_id": env("NODE_ID")
          },
          "additional_fields": this.without("id", "timestamp", "level", "service", "message", "user_id", "request_id")
        }
```

---

## Batching and Performance Issues

### Issue: Batches Not Being Created

**Symptoms:**
- No output files generated despite processed messages
- S3 uploads not happening
- Batch timeouts in logs

**Diagnosis:**
```bash
# Check batching configuration
expanso pipeline config log-enrichment-production | grep -A 10 batching

# Monitor batch accumulation
expanso pipeline metrics log-enrichment-production --metric batch_size
expanso pipeline metrics log-enrichment-production --metric batch_timeout
```

**Solutions:**

**1. Batch Triggers Not Met**
```yaml
# Lower thresholds for testing
output:
  aws_s3:
    batching:
      count: 5        # Very small for testing
      period: 10s     # Short timeout
      byte_size: 1KB  # Small size limit
```

**2. Memory Pressure Preventing Batching**
```bash
# Check available memory
free -h

# Monitor pipeline memory usage
ps aux | grep expanso
```

```yaml
# Reduce memory usage
buffer:
  memory:
    limit: "25MB"

batching:
  byte_size: 512KB  # Smaller batches
```

**3. Output Destination Issues**
```yaml
# Test with local file output first
output:
  file:
    path: /tmp/batch_test_${!timestamp_unix()}.jsonl
    codec: lines
    batching:
      count: 10
      period: 30s
```

### Issue: High Processing Latency

**Symptoms:**
- Messages taking long time to process
- High CPU usage
- Batch delays affecting downstream systems

**Diagnosis:**
```bash
# Monitor processing metrics
expanso pipeline metrics log-enrichment-production --metric processing_duration
expanso pipeline metrics log-enrichment-production --metric cpu_usage

# Check system load
top -p $(pgrep expanso)
```

**Solutions:**

**1. Optimize Mapping Functions**
```yaml
# Use efficient transformations
pipeline:
  processors:
    - mapping: |
        # Avoid expensive operations in loops
        let timestamp_val = this.timestamp
        let service_val = this.service
        
        # Use pick() instead of manual field assignment
        root.event = this.pick("id", "timestamp", "level", "service", "message")
        root.metadata = {
          "processed_at": now(),
          "node_id": env("NODE_ID")
        }
```

**2. Reduce Processing Complexity**
```yaml
# Simplify lineage metadata
pipeline:
  processors:
    - mapping: |
        root = this
        # Add minimal lineage for performance
        root.metadata = {
          "node": env("NODE_ID"),
          "ts": now().format_timestamp("15:04:05", "UTC")
        }
```

**3. Parallel Processing**
```yaml
# Use multiple processor threads
pipeline:
  processors:
    - parallel:
        cap: 4  # 4 parallel processing threads
        processors:
          - mapping: |
              # Your processing logic here
              root.event = this.pick("id", "timestamp", "level")
              root.metadata = {"processed_at": now()}
```

---

## S3 Export Issues

### Issue: S3 Upload Failures

**Symptoms:**
- "Access denied" errors in logs
- Files not appearing in S3 bucket
- Authentication errors

**Diagnosis:**
```bash
# Test AWS credentials
aws sts get-caller-identity --profile your-profile

# Test S3 access
aws s3 ls s3://your-bucket --profile your-profile

# Check S3 permissions
aws s3api get-bucket-policy --bucket your-bucket --profile your-profile
```

**Solutions:**

**1. Credential Issues**
```bash
# Re-configure AWS credentials
aws configure --profile your-profile

# OR use IAM role (recommended for EC2)
# Remove credentials section from pipeline config
```

**2. Insufficient S3 Permissions**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:PutObjectAcl",
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::your-bucket/*",
        "arn:aws:s3:::your-bucket"
      ]
    }
  ]
}
```

**3. Bucket Policy Conflicts**
```bash
# Check for restrictive bucket policies
aws s3api get-bucket-policy --bucket your-bucket --profile your-profile

# Test with different bucket
export S3_BUCKET_NAME="test-bucket-$(date +%s)"
aws s3 mb s3://$S3_BUCKET_NAME --profile your-profile
```

### Issue: S3 Upload Performance Problems

**Symptoms:**
- Very slow upload speeds
- Timeout errors
- High network latency

**Diagnosis:**
```bash
# Test S3 upload speed
time aws s3 cp /dev/zero s3://your-bucket/speedtest.dat --profile your-profile --cli-write-timeout 0 --cli-read-timeout 0

# Check network connectivity
ping s3.amazonaws.com
traceroute s3.amazonaws.com
```

**Solutions:**

**1. Optimize Upload Settings**
```yaml
output:
  aws_s3:
    bucket: your-bucket
    upload_cutoff: 10485760   # 10MB (lower for slow networks)
    chunk_size: 1048576       # 1MB chunks
    max_upload_parts: 1000
```

**2. Use Appropriate Storage Class**
```yaml
output:
  aws_s3:
    bucket: your-bucket
    storage_class: STANDARD_IA  # For infrequent access
    # OR
    storage_class: REDUCED_REDUNDANCY  # For non-critical data
```

**3. Enable Transfer Acceleration**
```yaml
output:
  aws_s3:
    bucket: your-bucket
    use_accelerate_endpoint: true
```

### Issue: S3 Path and Partitioning Problems

**Symptoms:**
- Files in wrong S3 paths
- Partitioning not working as expected
- Analytics queries failing

**Diagnosis:**
```bash
# Check actual S3 structure
aws s3 ls s3://your-bucket/logs/ --recursive --profile your-profile | head -20

# Verify path template rendering
echo '{"timestamp":"2024-01-15T10:30:00Z","service":"auth-service"}' | \
  bloblang 'root = "year=" + this.timestamp.format_timestamp("2006", "UTC") + "/service=" + this.service'
```

**Solutions:**

**1. Fix Path Template Syntax**
```yaml
# Correct Bloblang syntax for paths
output:
  aws_s3:
    path: logs/year=${!timestamp("2006")}/month=${!timestamp("01")}/day=${!timestamp("02")}/service=${!json("event.service")}/logs_${!timestamp_unix()}.jsonl
```

**2. Handle Missing Fields in Path**
```yaml
# Add fallback values for path components
pipeline:
  processors:
    - mapping: |
        root = this
        # Ensure service field exists for partitioning
        if this.event.service == null {
          root.event.service = "unknown"
        }
```

**3. Test Partitioning Logic**
```yaml
# Add debug output to verify partitioning
output:
  broker:
    pattern: fan_out
    outputs:
      # Debug output
      - stdout:
          processors:
            - mapping: |
                root = {
                  "debug_partition": "year=" + this.event.timestamp.format_timestamp("2006", "UTC") + "/service=" + this.event.service,
                  "original": this
                }
      
      # Actual S3 output
      - aws_s3:
          bucket: your-bucket
          path: logs/year=${!timestamp("2006")}/service=${!json("event.service")}/logs_${!timestamp_unix()}.jsonl
```

---

## Monitoring and Alerting Issues

### Issue: Metrics Not Available

**Symptoms:**
- No metrics in monitoring dashboard
- Prometheus scraping failures
- Missing performance data

**Diagnosis:**
```bash
# Check metrics endpoint
curl http://localhost:4040/metrics  # Default Expanso metrics port

# Verify Prometheus configuration
curl http://pushgateway:9091/metrics | grep log_enrichment

# Check metrics configuration
expanso pipeline config log-enrichment-production | grep -A 20 metrics
```

**Solutions:**

**1. Enable Metrics Collection**
```yaml
metrics:
  prometheus:
    prefix: log_enrichment_prod
    labels:
      environment: ${ENVIRONMENT}
      node_id: ${NODE_ID}
    
    # Push to gateway if prometheus can't scrape
    push_gateway:
      url: http://pushgateway:9091
      job_name: log_enrichment
      push_interval: 30s
```

**2. Fix Prometheus Pushgateway**
```bash
# Test pushgateway connectivity
curl -X POST http://pushgateway:9091/metrics/job/log_enrichment/instance/test

# Check pushgateway logs
docker logs pushgateway 2>&1 | tail -20
```

**3. Custom Metrics for Debugging**
```yaml
pipeline:
  processors:
    - mapping: |
        root = this
        # Increment custom counters
        let _ = counter("messages_processed_total", 1)
        let _ = counter("messages_by_level_" + this.level.or("unknown"), 1)
```

### Issue: Alerts Not Firing

**Symptoms:**
- No alerts despite obvious issues
- Alert fatigue from false positives
- Missing critical event notifications

**Solutions:**

**1. Validate Alert Rules**
```yaml
# Test alert expressions in Prometheus UI
up{job="log_enrichment"} == 0
rate(log_enrichment_errors_total[5m]) > 0.1
```

**2. Adjust Alert Thresholds**
```yaml
# More sensitive error rate alerting
- alert: LogProcessingErrors
  expr: increase(log_enrichment_errors_total[1m]) > 0
  for: 0s  # Alert immediately
  labels:
    severity: warning
```

**3. Add Custom Health Check Alerts**
```yaml
# Health check metric
pipeline:
  processors:
    - mapping: |
        root = this
        # Set health check metric
        let _ = gauge("pipeline_health", if this.error == null { 1 } else { 0 })
```

---

## Advanced Troubleshooting

### Performance Profiling

Debug performance issues with detailed profiling:

```bash
# Enable debug logging
export LOG_LEVEL=debug
expanso pipeline deploy enrich-export-complete.yaml --name debug-enrichment

# Profile memory usage
pmap -d $(pgrep expanso)

# Profile CPU usage
strace -c -p $(pgrep expanso)

# Network profiling
netstat -i
ss -tulpn
```

### Configuration Debugging

Debug complex configuration issues:

```yaml
# Add debug processors throughout pipeline
pipeline:
  processors:
    - mapping: |
        root = this
        root.debug_step_1 = {
          "fields": this.keys(),
          "timestamp": now()
        }
    
    # Your actual processing
    - mapping: |
        root.event = this.pick("id", "timestamp")
        root.metadata = {"processed_at": now()}
        
        # Debug output
        root.debug_step_2 = {
          "event_fields": root.event.keys(),
          "metadata_fields": root.metadata.keys()
        }
```

### Log Analysis

Analyze pipeline logs for patterns:

```bash
# Find most common error patterns
expanso pipeline logs log-enrichment-production --lines 1000 | \
  grep ERROR | \
  sed 's/.*ERROR: //' | \
  sort | uniq -c | sort -rn | head -10

# Analyze processing timing
expanso pipeline logs log-enrichment-production --lines 1000 | \
  grep "processing_duration" | \
  awk '{print $NF}' | \
  sort -n | \
  awk '{a[++i]=$1} END {print "median:", a[int(i/2)]}'

# Check memory usage patterns
expanso pipeline logs log-enrichment-production --lines 1000 | \
  grep "memory" | \
  tail -20
```

## Getting Additional Help

If you're still experiencing issues after trying these solutions:

1. **Enable Debug Logging**
```bash
export LOG_LEVEL=debug
expanso pipeline restart log-enrichment-production
```

2. **Collect Diagnostic Information**
```bash
# Create diagnostic bundle
expanso pipeline diagnostic log-enrichment-production > diagnostic.json
expanso pipeline config log-enrichment-production > config.yaml
expanso pipeline logs log-enrichment-production --lines 500 > logs.txt
```

3. **Test with Minimal Configuration**
```yaml
# Minimal test pipeline
input:
  generate:
    interval: 5s
    mapping: 'root = {"test": "message"}'

output:
  stdout: {}
```

4. **Community Resources**
- [Expanso Documentation](https://docs.expanso.io)
- [Community Forum](https://community.expanso.io)
- [GitHub Issues](https://github.com/expanso-io/examples)

5. **Provide Context When Asking for Help**
Include these details:
- Pipeline configuration (sanitized)
- Error messages and logs
- System environment (OS, resources)
- Expected vs actual behavior
- Steps already tried

---

**Related:** [Complete Pipeline](./complete-log-enrichment) | [Interactive Explorer](./explorer) | [Setup Guide](./setup)
