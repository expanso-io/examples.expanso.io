---
title: How to Create Priority Queues
sidebar_label: Priority Queues
sidebar_position: 5
description: Route messages to priority-based queues for differential processing and SLA management
keywords: [routing, priority, queues, switch, sla, tiering]
---

import CodeBlock from '@theme/CodeBlock';
import pipelineYaml from '!!raw-loader!../../examples/data-routing/priority-queues.yaml';


# How to Create Priority Queues

When you're running production systems, not all messages deserve the same treatment. Premium customer requests need faster processing than free tier traffic. Security alerts require immediate attention while routine metrics can wait. Critical system events must bypass the queue while background analytics can be batched and delayed.

Priority queues solve this problem by routing messages to different processing paths based on their importance. High-priority messages get expedited delivery with minimal batching and aggressive retries, while low-priority messages are batched heavily to optimize throughput and reduce overhead.

## Problem Statement

Consider a SaaS platform processing millions of events per day across different customer tiers and message types. Without priority queuing, you face several challenges:

- **Starvation of critical events**: Important alerts get stuck behind millions of routine log messages
- **SLA violations**: Premium customers experience the same delays as free tier users
- **Resource waste**: Background tasks consume the same processing resources as real-time operations
- **Poor user experience**: Time-sensitive operations (password resets, payment confirmations) compete with bulk data imports
- **Inefficient batching**: You can't batch aggressively because critical messages need immediate delivery

Priority queues address these challenges by routing each message to a queue matching its importance level. Critical alerts bypass batching entirely, high-priority requests get small batches with fast delivery, normal traffic uses standard batching, and low-priority bulk operations are batched aggressively.

## Prerequisites

Before implementing priority queues, ensure you have:

- An Expanso edge node running and connected to the orchestrator
- Access to your message broker (Kafka, Redis Streams, or NATS)
- Defined SLA tiers or priority levels for your application

For background on routing patterns in Expanso, review the [Content Routing guide](/examples/data-routing/content-routing).

## Solution Overview

Priority queuing uses the switch output to evaluate message priority and route to dedicated queues. Each priority level has its own queue with tailored processing characteristics: batching behavior, retry logic, timeout settings, and resource allocation.

```
                                    â”Œâ”€â†’ Critical Queue (no batching, immediate)
                                    â”‚
Input â†’ Priority Classification â”€â”€â”€â”€â”¼â”€â†’ High Queue (small batches, fast)
                                    â”‚
                                    â”œâ”€â†’ Normal Queue (standard batching)
                                    â”‚
                                    â””â”€â†’ Low Queue (large batches, deferred)
```

Key characteristics of priority queues:

- **Priority classification**: Messages are evaluated and assigned a priority level
- **Differential processing**: Each priority gets unique batching, retry, and timeout settings
- **Fair scheduling**: Lower priorities still process, avoiding complete starvation
- **Resource allocation**: Critical queues get more resources (connections, retries, threads)
- **SLA compliance**: Processing guarantees map to business requirements
- **Edge optimization**: High-volume low-priority data stays local, reducing cloud costs

## Step-by-Step Implementation

### Step 1: Severity-Based Priority Queues

Let's start with a common pattern: routing log messages by severity level. Critical errors get immediate delivery, warnings are batched moderately, and info logs are batched heavily.

<CodeBlock language="yaml" title="severity-priority-queues.yaml" showLineNumbers>
  {pipelineYaml}
</CodeBlock>

<a
  href="/files/data-routing/priority-queues.yaml"
  download
  className="button button--primary button--lg margin-top--md"
>
  ðŸ“¥ Download Pipeline
</a>

---


This configuration demonstrates the core priority queue pattern:

- **Critical**: Single-message delivery (no batching), maximum retries (10), aggressive backoff (100ms-2s)
- **High**: Small batches (10 messages, 1s window), moderate retries (5), faster backoff (500ms-5s)
- **Normal**: Standard batches (100 messages, 5s window), standard retries (3), normal backoff (1s-10s)
- **Low**: Large batches (1000 messages, 1m window), minimal retries (1), slow backoff (5s-30s)

**Key Pattern**: The priority classification happens in the pipeline processor using a `match` expression that maps severity levels to priority tiers.

### Step 2: Customer Tier Priority Queues

Let's implement priority queuing based on customer subscription tiers. Premium customers get fast processing, while free tier users get batched delivery.

```yaml title="customer-tier-priority-queues.yaml"
name: customer-tier-priority-queues
description: Route events to priority queues based on customer subscription tier
type: pipeline
namespace: production

config:
  input:
    http_server:
      address: 0.0.0.0:8080
      path: /events
      timeout: 5s

  pipeline:
    processors:
      # Parse incoming events
      - json_documents:
          parts: []

      # Classify priority based on customer tier
      - mapping: |
          root = this

          # Extract customer tier from JWT claims or event metadata
          root.customer_tier = this.user.tier.or(
            this.customer_tier.or("free")
          ).lowercase()

          # Map customer tier to priority
          root.priority = match root.customer_tier {
            "enterprise" => "critical"
            "premium" => "high"
            "pro" => "high"
            "standard" => "normal"
            "free" => "low"
            "trial" => "low"
            _ => "normal"
          }

          # Add SLA target based on tier
          root.sla_target_ms = match root.customer_tier {
            "enterprise" => 100    # 100ms SLA
            "premium" => 500       # 500ms SLA
            "pro" => 500           # 500ms SLA
            "standard" => 2000     # 2s SLA
            "free" => 10000        # 10s SLA
            "trial" => 10000       # 10s SLA
            _ => 5000              # 5s default
          }

          root.received_at = now()
          root.edge_node_id = env("NODE_ID").or("unknown")

  output:
    switch:
      cases:
        # Enterprise tier - premium processing
        - check: this.priority == "critical"
          output:
            label: enterprise_queue
            broker:
              pattern: fan_out
              outputs:
                # Send to dedicated enterprise Kafka cluster
                - kafka:
                    addresses: ["${ENTERPRISE_KAFKA_BROKERS}"]
                    topic: enterprise-events
                    batching:
                      count: 1
                      period: 0s
                    max_in_flight: 1
                    ack_replicas: true
                    idempotent_write: true
                    max_retries: 10

                # Also send to real-time analytics
                - http_client:
                    url: ${ANALYTICS_API_URL}/enterprise-events
                    verb: POST
                    timeout: 2s
                    max_retries: 3

        # Premium/Pro tier - high priority
        - check: this.priority == "high"
          output:
            label: premium_queue
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: premium-events
              batching:
                count: 25
                period: 2s
              max_in_flight: 5
              ack_replicas: true
              max_retries: 5
              compression: snappy

        # Standard tier - normal priority
        - check: this.priority == "normal"
          output:
            label: standard_queue
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: standard-events
              batching:
                count: 200
                period: 10s
              max_in_flight: 10
              max_retries: 3
              compression: snappy

        # Free tier - low priority
        - check: this.priority == "low"
          output:
            label: free_tier_queue
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: free-tier-events
              batching:
                count: 2000
                period: 5m
              max_in_flight: 20
              max_retries: 1
              compression: gzip

        # Default: standard tier
        - output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: standard-events
```

**SLA Tracking**: This pipeline adds `sla_target_ms` metadata to each message, enabling downstream consumers to track whether they're meeting SLA requirements. Combined with the `received_at` timestamp, you can measure end-to-end latency per tier.

**Dedicated Infrastructure**: Enterprise customers get routed to a dedicated Kafka cluster, ensuring their traffic isn't impacted by free tier volume spikes.

### Step 3: Multi-Criteria Priority Queues

In production systems, priority often depends on multiple factors. Let's build a priority queue that considers message type, customer tier, AND operational urgency.

```yaml title="multi-criteria-priority-queues.yaml"
name: multi-criteria-priority-queues
description: Priority routing based on event type, customer tier, and urgency
type: pipeline
namespace: production

config:
  input:
    http_server:
      address: 0.0.0.0:8080
      path: /events
      timeout: 5s

  pipeline:
    processors:
      # Parse and validate
      - json_documents:
          parts: []

      # Complex priority classification
      - mapping: |
          root = this

          # Extract and normalize fields
          root.event_type = this.event_type.or("unknown").lowercase()
          root.customer_tier = this.user.tier.or("free").lowercase()
          root.urgency = this.urgency.or("normal").lowercase()

          # Calculate priority score (0-100)
          let base_score = match root.customer_tier {
            "enterprise" => 60
            "premium" => 50
            "pro" => 40
            "standard" => 30
            "free" => 10
            _ => 20
          }

          let event_score = match {
            root.event_type.has_prefix("payment.") => 30
            root.event_type.has_prefix("auth.") => 25
            root.event_type.has_prefix("security.") => 40
            root.event_type.has_prefix("api.") => 20
            root.event_type.has_prefix("analytics.") => 5
            _ => 15
          }

          let urgency_score = match root.urgency {
            "critical" => 10
            "high" => 7
            "normal" => 3
            "low" => 0
            _ => 3
          }

          # Final priority score
          root.priority_score = base_score + event_score + urgency_score

          # Map score to priority tier
          root.priority = match {
            root.priority_score >= 80 => "critical"
            root.priority_score >= 60 => "high"
            root.priority_score >= 40 => "normal"
            _ => "low"
          }

          root.processed_at = now()
          root.edge_node_id = env("NODE_ID").or("unknown")

  output:
    switch:
      cases:
        # Critical priority (score >= 80)
        - check: this.priority == "critical"
          output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: critical-priority-events
              batching:
                count: 1
                period: 0s
              max_in_flight: 1
              ack_replicas: true
              max_retries: 10

        # High priority (score 60-79)
        - check: this.priority == "high"
          output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: high-priority-events
              batching:
                count: 20
                period: 2s
              max_retries: 5
              compression: snappy

        # Normal priority (score 40-59)
        - check: this.priority == "normal"
          output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: normal-priority-events
              batching:
                count: 100
                period: 10s
              max_retries: 3
              compression: snappy

        # Low priority (score < 40)
        - check: this.priority == "low"
          output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: low-priority-events
              batching:
                count: 1000
                period: 2m
              max_retries: 1
              compression: gzip

        # Default
        - output:
            kafka:
              addresses: ["${KAFKA_BROKERS}"]
              topic: default-priority-events
```

**Scoring System**: This pipeline uses a weighted scoring system that combines:
- **Customer tier** (10-60 points): Enterprise customers start with a higher base
- **Event type** (5-40 points): Security events score highest, analytics lowest
- **Urgency** (0-10 points): User-specified urgency adds bonus points

The final score (0-100) maps to priority tiers, ensuring critical combinations (enterprise payment events, security alerts) get the highest priority.

## Production Considerations

### Preventing Priority Starvation

The biggest risk with priority queues is **starvation**: low-priority messages never process because high-priority messages keep arriving. Prevent this with age-based priority boost:

```yaml
pipeline:
  processors:
    - mapping: |
        root = this

        # Calculate message age
        let age_seconds = now().unix() - this.timestamp.parse_timestamp_unix("2006-01-02T15:04:05Z")

        # Boost priority for old messages
        let age_boost = match {
          age_seconds > 3600 => 20      # 1+ hour old: +20 points
          age_seconds > 1800 => 10      # 30+ min old: +10 points
          age_seconds > 900 => 5        # 15+ min old: +5 points
          _ => 0
        }

        # Add age boost to priority score
        root.priority_score = root.priority_score + age_boost
```

### Performance Tuning by Priority

Different priorities warrant different performance characteristics:

| Priority | Batching | Compression | Retries | Ack | Use Case |
|----------|----------|-------------|---------|-----|----------|
| Critical | 1 msg, 0s | none | 10 | all replicas | Security alerts |
| High | 25 msgs, 2s | snappy | 5 | replicas | Premium customers |
| Normal | 100 msgs, 10s | snappy | 3 | leader only | Standard traffic |
| Low | 1000 msgs, 1m | gzip | 1 | leader only | Bulk analytics |

### Edge Context: Bandwidth Optimization

Priority queues are particularly valuable at the edge where bandwidth is limited:

**Before (flat priority):**
```
All events â†’ Cloud (5 GB/day)
Cost at $0.09/GB: $13.50/day = $405/month
```

**After (priority-based routing):**
```
Critical (1%): â†’ Cloud immediately (50 MB/day)
High (5%): â†’ Cloud in small batches (250 MB/day)
Normal (30%): â†’ Cloud in standard batches (1.5 GB/day)
Low (64%): â†’ Local storage, sync daily (3.2 GB â†’ 320 MB compressed)

Total cloud bandwidth: 2.12 GB/day
Cost at $0.09/GB: $5.73/month

Savings: $399.27/month (93% reduction)
```

**Implementation**:

```yaml
output:
  switch:
    cases:
      # Low priority: Keep local, sync periodically
      - check: this.priority == "low"
        output:
          file:
            path: /var/expanso/data/low-priority-${!timestamp_unix_date("2006-01-02")}.jsonl.gz
            codec: lines
            gzip_compression: true
            batching:
              count: 10000
              period: 1h
```

### Monitoring Priority Distribution

Track how messages distribute across priorities to detect anomalies:

```bash
# View priority distribution metrics
curl http://localhost:8080/metrics | grep 'output_sent_total'

# Expected output showing healthy distribution
pipeline_output_sent_total{output="critical_priority_queue"} 342
pipeline_output_sent_total{output="high_priority_queue"} 8234
pipeline_output_sent_total{output="normal_priority_queue"} 52103
pipeline_output_sent_total{output="low_priority_queue"} 145820
```

## Troubleshooting

### Problem: All Messages Routing to Single Priority

**Symptom**: 99% of messages classified as one priority (usually "normal" or "low").

**Cause**: Priority classification logic too conservative or incorrect field mapping.

**Solution**: Adjust scoring thresholds:

```bloblang title="Before: Too conservative"
root.priority = match {
  root.priority_score >= 90 => "critical"  # Almost nothing reaches 90
  root.priority_score >= 70 => "high"
  root.priority_score >= 40 => "normal"
  _ => "low"
}
```

```bloblang title="After: More balanced"
root.priority = match {
  root.priority_score >= 75 => "critical"  # Easier to reach
  root.priority_score >= 50 => "high"
  root.priority_score >= 25 => "normal"
  _ => "low"
}
```

### Problem: Priority Starvation

**Symptom**: Low-priority queue has millions of messages, never processing.

**Cause**: Insufficient consumer capacity for low-priority queue.

**Solution**: Implement age-based boost to prevent indefinite starvation (see above), or add more consumers to low-priority queue.

### Problem: Critical Messages Experiencing Latency

**Symptom**: Critical priority messages have >1s latency, violating SLA.

**Cause**: Batching configuration or network latency.

**Solution**: Ensure no batching for critical:

```yaml
# Correct: No batching for critical
- check: this.priority == "critical"
  output:
    kafka:
      batching:
        count: 1
        period: 0s
      max_retries: 3
      backoff:
        initial_interval: 50ms
        max_interval: 500ms
```

### Problem: Unexpected Priority Classifications

**Symptom**: Events classified differently than expected.

**Cause**: Field mapping errors or incorrect scoring logic.

**Solution**: Add priority breakdown to debug:

```bloblang
# Store priority calculation breakdown for debugging
root.priority_breakdown = {
  "tier_score": tier_score,
  "event_score": event_score,
  "severity_score": severity_score,
  "urgency_score": urgency_score,
  "total_score": root.priority_score,
  "assigned_priority": root.priority
}
```

## See Also

- [Content Routing](/examples/data-routing/content-routing) - Content-based routing patterns
- [Fan-Out Pattern](/examples/data-routing/fan-out-pattern) - Send to multiple destinations
- [Bloblang Guide](https://docs.expanso.io/guides/bloblang) - Transformation language reference
