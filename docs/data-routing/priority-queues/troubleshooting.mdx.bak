---
title: Priority Queues Troubleshooting
sidebar_label: Troubleshooting
sidebar_position: 9
description: Comprehensive troubleshooting guide for priority queue issues - classification problems, performance issues, starvation, and monitoring failures
keywords: [troubleshooting, priority-queues, debugging, performance, monitoring, errors]
---

# Priority Queues Troubleshooting

**Diagnose and resolve priority queue issues quickly.** This guide covers common problems, diagnostic techniques, and proven solutions for production priority queue systems.

## Quick Diagnosis Checklist

When priority queues aren't working correctly, start with this rapid diagnosis:

```bash
# 1. Check pipeline status
expanso pipeline status complete-priority-pipeline

# 2. Check recent errors
expanso pipeline logs complete-priority-pipeline --tail 50 | grep -i error

# 3. Check message distribution
curl -s http://localhost:8081/metrics | grep 'output_sent_total.*priority'

# 4. Check queue latencies
curl -s http://localhost:8081/metrics | grep 'output_latency.*priority'

# 5. Check for starvation
ls -la /var/expanso/monitoring/starvation-watch.jsonl
```

If any of these show issues, proceed to the detailed troubleshooting sections below.

---

## Classification Issues

### Issue: All Messages Routing to Same Priority

**Symptoms:**
- 99% of messages appear in one priority queue (usually "normal")
- Priority distribution heavily skewed
- Expected high-priority messages not getting fast processing

**Diagnosis:**
```bash
# Check priority distribution
echo "=== Priority Distribution ===" 
for priority in critical high normal low bulk; do
  count=$(timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
    --bootstrap-server $KAFKA_BROKERS \
    --topic ${priority}-priority-events \
    --from-beginning \
    --max-messages 100 | wc -l)
  echo "$priority: $count messages"
done

# Check scoring breakdown for recent messages
timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic normal-priority-events \
  --from-beginning \
  --max-messages 5 | jq '.scoring_breakdown'
```

**Root Causes and Solutions:**

**1. Missing or Incorrect Field Mapping**
```bloblang title="Problem: Fields not extracted correctly"
# Check if fields exist in input
root.debug_fields = {
  "severity_exists": this.severity.exists(),
  "severity_value": this.severity,
  "customer_tier_exists": this.customer_tier.exists(),
  "customer_tier_value": this.customer_tier,
  "event_type_exists": this.event_type.exists(),
  "event_type_value": this.event_type
}
```

```bloblang title="Solution: Enhanced field extraction"
# Robust field extraction with fallbacks
root.severity = match {
  this.severity.exists() && this.severity != "" => this.severity.string().uppercase()
  this.level.exists() && this.level != "" => this.level.string().uppercase()
  this.priority.exists() && this.priority != "" => this.priority.string().uppercase()
  _ => "INFO"  # Safe default
}

root.customer_tier = match {
  this.user.subscription.exists() => this.user.subscription.lowercase()
  this.customer_tier.exists() => this.customer_tier.lowercase()
  this.subscription.plan.exists() => this.subscription.plan.lowercase()
  this.headers."x-customer-tier".exists() => this.headers."x-customer-tier".lowercase()
  _ => "free"
}
```

**2. Conservative Scoring Thresholds**
```bloblang title="Problem: Thresholds too high"
root.priority = match {
  root.priority_score >= 300 => "critical"  # Almost nothing reaches 300
  root.priority_score >= 200 => "high"
  root.priority_score >= 100 => "normal"
  _ => "low"
}
```

```bloblang title="Solution: Balanced thresholds"
root.priority = match {
  root.priority_score >= 150 => "critical"  # More achievable
  root.priority_score >= 100 => "high"
  root.priority_score >= 50 => "normal"
  root.priority_score >= 20 => "low"
  _ => "bulk"
}
```

**3. Multiplier Not Applied**
```bloblang title="Problem: Missing tier multiplication"
# Base score calculated but tier multiplier not applied
root.priority_score = severity_score + event_type_score  # Missing multiplication
```

```bloblang title="Solution: Correct score calculation"
let base_score = severity_score * tier_multiplier  # Apply multiplication
root.priority_score = base_score + event_type_score + urgency_score
```

### Issue: Unexpected Priority Classifications

**Symptoms:**
- High-priority customers getting low priority routing
- Debug messages getting critical priority
- Random-seeming priority assignments

**Diagnosis:**
```bash
# Add detailed debugging to pipeline
cat << 'EOF' > debug-priority.yaml
# Add to mapping processor for detailed debugging
root.debug_priority = {
  "input_fields": {
    "severity": this.severity,
    "customer_tier": this.customer_tier,
    "event_type": this.event_type,
    "urgency": this.urgency
  },
  "normalized_fields": {
    "severity": root.severity,
    "customer_tier": root.customer_tier,
    "event_type": root.event_type,
    "urgency": root.urgency
  },
  "score_components": {
    "severity_score": severity_score,
    "tier_multiplier": tier_multiplier,
    "event_type_score": event_type_score,
    "urgency_score": urgency_score,
    "age_boost": age_boost
  },
  "final_calculation": {
    "base_score": severity_score * tier_multiplier,
    "total_bonus": event_type_score + urgency_score + age_boost,
    "final_score": root.priority_score,
    "assigned_priority": root.priority
  }
}
EOF

# Apply debug configuration and test
expanso pipeline deploy debug-priority.yaml

# Send test message and examine debug output
curl -X POST http://localhost:8080/events \
  -H "Content-Type: application/json" \
  -d '{
    "severity": "ERROR",
    "customer_tier": "premium",
    "event_type": "payment.failed",
    "urgency": "high"
  }'

# Check debug output
timeout 5s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic high-priority-events \
  --from-beginning \
  --max-messages 1 | jq '.debug_priority'
```

**Common Issues and Fixes:**

**1. String vs Number Comparison**
```bloblang title="Problem: String comparison instead of numeric"
# This compares strings, not numbers!
root.priority_score = "85"  # String
root.priority = match {
  root.priority_score >= 100 => "high"  # String comparison fails
  _ => "low"
}
```

```bloblang title="Solution: Ensure numeric values"
root.priority_score = 85  # Number, not string
# OR
root.priority_score = this.calculated_score.number()  # Convert to number
```

**2. Case Sensitivity Issues**
```bloblang title="Problem: Case-sensitive matching"
root.priority = match root.severity {
  "critical" => "critical"    # Won't match "CRITICAL"
  "error" => "high"           # Won't match "ERROR"
  _ => "normal"
}
```

```bloblang title="Solution: Normalize case first"
root.severity = this.severity.string().uppercase()
root.priority = match root.severity {
  "CRITICAL" => "critical"
  "ERROR" => "high"
  _ => "normal"
}
```

**3. Null/Missing Value Handling**
```bloblang title="Problem: Not handling missing values"
# Throws error if severity doesn't exist
root.priority_score = this.severity_score + this.tier_score
```

```bloblang title="Solution: Use .or() for defaults"
root.priority_score = this.severity_score.or(0) + this.tier_score.or(0)
```

---

## Performance Issues

### Issue: High Latency for Critical Messages

**Symptoms:**
- Critical priority messages taking >1 second
- SLA violations for high-priority customers
- Critical queue showing high latency in metrics

**Diagnosis:**
```bash
# Check critical queue latency
curl -s http://localhost:8081/metrics | grep 'critical.*latency'

# Check critical queue configuration
timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events \
  --from-beginning \
  --max-messages 1 | jq '{
    timestamp: .timestamp,
    received_at: .received_at,
    processed_at: .processed_at,
    priority: .priority,
    batching_info: .routing_decision
  }'

# Check Kafka topic configuration
$KAFKA_HOME/bin/kafka-topics.sh --bootstrap-server $KAFKA_BROKERS \
  --describe --topic critical-priority-events
```

**Root Causes and Solutions:**

**1. Batching Configuration Problem**
```yaml title="Problem: Critical messages being batched"
# Critical queue has batching enabled
- check: this.priority == "critical"
  output:
    kafka:
      batching:
        count: 10        # BAD: Batches critical messages
        period: 5s       # BAD: Waits up to 5 seconds
```

```yaml title="Solution: Disable batching for critical"
- check: this.priority == "critical"
  output:
    kafka:
      batching:
        count: 1         # Send immediately
        period: 0s       # No time-based batching
      max_in_flight: 1   # Process one at a time
```

**2. Network Latency Issues**
```bash
# Test Kafka connectivity
ping kafka1.internal
traceroute kafka1.internal

# Test Kafka cluster performance
kafka-producer-perf-test.sh \
  --topic critical-priority-events \
  --num-records 100 \
  --record-size 1000 \
  --throughput 100 \
  --producer-props bootstrap.servers=$KAFKA_BROKERS
```

**Solution: Optimize network configuration**
```yaml
# Kafka optimizations for low latency
kafka:
  addresses: ["${KAFKA_BROKERS}"]
  topic: critical-priority-events
  
  # Minimize network roundtrips
  ack_replicas: false          # Don't wait for replicas (if acceptable)
  idempotent_write: false      # Disable if not required
  compression: none            # No compression for minimum latency
  
  # Aggressive retry settings
  max_retries: 3               # Fewer retries, fail fast
  backoff:
    initial_interval: 50ms     # Quick initial retry
    max_interval: 500ms        # Cap retry delay
```

**3. Consumer Lag**
```bash
# Check consumer group lag
kafka-consumer-groups.sh --bootstrap-server $KAFKA_BROKERS \
  --describe --group critical-priority-consumer

# Scale consumers if needed
kubectl scale deployment critical-priority-consumer --replicas=5
```

### Issue: Low Priority Queue Overwhelmed

**Symptoms:**
- Low priority queue has millions of unprocessed messages
- Age escalations flooding critical queue
- Free tier users complaining about delays

**Diagnosis:**
```bash
# Check queue depths
for priority in critical high normal low bulk; do
  lag=$(kafka-consumer-groups.sh --bootstrap-server $KAFKA_BROKERS \
    --describe --group ${priority}-consumer | tail -1 | awk '{print $5}')
  echo "$priority queue lag: $lag"
done

# Check age escalation rate
timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events \
  --from-beginning \
  --max-messages 50 | \
  jq 'select(.routing_decision.was_escalated == true)' | wc -l
```

**Solutions:**

**1. Scale Consumer Capacity**
```bash
# Temporarily increase low priority consumers
kubectl scale deployment low-priority-consumer --replicas=20

# Increase bulk processing capacity  
kubectl scale deployment bulk-priority-consumer --replicas=15

# Monitor improvement
watch "kafka-consumer-groups.sh --bootstrap-server $KAFKA_BROKERS --describe --group low-priority-consumer"
```

**2. Adjust Batching for Throughput**
```yaml title="Increase batch size for efficiency"
# Low priority: Optimize for throughput
- check: this.priority == "low"
  output:
    kafka:
      batching:
        count: 2000      # Larger batches
        period: 2m       # Longer batching window
      max_in_flight: 25  # Higher concurrency
      compression: gzip  # Better compression
```

**3. Implement Overflow Handling**
```yaml title="Add overflow protection"
# Detect queue overflow and take action
- mapping: |
    # Query queue depth (simplified for example)
    let queue_depth = http_client(
      "http://monitoring.internal/api/queue-depth",
      {"timeout": "100ms", "verb": "GET"}
    ).low_priority_depth.or(0)
    
    # If queue is overwhelmed, route to bulk instead
    if queue_depth > 50000 && root.priority == "low" {
      root.priority = "bulk"
      root.overflow_routing = true
    }
```

---

## Age Escalation Issues

### Issue: Too Many Age Escalations

**Symptoms:**
- Critical queue flooded with escalated low-priority messages
- Original high-priority messages delayed by escalated messages
- Age escalation alerts firing constantly

**Diagnosis:**
```bash
# Check escalation rate
escalated_count=$(timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events \
  --from-beginning \
  --max-messages 100 | \
  jq 'select(.routing_decision.was_escalated == true)' | wc -l)

echo "Escalated messages in critical queue: $escalated_count/100"

# Analyze escalation reasons
timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events \
  --from-beginning \
  --max-messages 100 | \
  jq -r 'select(.routing_decision.was_escalated == true) | .routing_decision.escalation_reason' | \
  sort | uniq -c
```

**Solutions:**

**1. Adjust Escalation Thresholds**
```bloblang title="More conservative escalation"
# Current: Too aggressive
let age_boost = match {
  root.age_seconds > 86400 => 100    # 24 hours
  root.age_seconds > 14400 => 60     # 4 hours  
  root.age_seconds > 3600 => 35      # 1 hour
  _ => 0
}

# Solution: More conservative thresholds
let age_boost = match {
  root.age_seconds > 259200 => 100   # 72 hours (3 days)
  root.age_seconds > 86400 => 60     # 24 hours (1 day)
  root.age_seconds > 21600 => 35     # 6 hours
  root.age_seconds > 7200 => 15      # 2 hours
  _ => 0
}
```

**2. Implement Escalation Rate Limiting**
```bloblang title="Rate limit escalations"
# Track escalation budget to prevent overflow
let escalation_budget = http_client(
  "http://monitoring.internal/api/escalation-budget",
  {"timeout": "100ms", "verb": "GET"}
).remaining_escalations.or(100)

# Only escalate if we have budget
let age_boost = if escalation_budget > 0 {
  # Normal escalation logic
  match {
    root.age_seconds > 86400 => 100
    root.age_seconds > 14400 => 60
    _ => 0
  }
} else {
  # No escalation when budget exhausted
  0
}

# Decrement budget when escalating
if age_boost > 0 {
  http_client(
    "http://monitoring.internal/api/escalation-budget/decrement",
    {"timeout": "100ms", "verb": "POST"},
    {}
  )
}
```

**3. Customer Tier-Specific Escalation**
```bloblang title="Different escalation rules by tier"
# Enterprise customers get faster escalation
let tier_escalation_multiplier = match root.customer_tier {
  "enterprise" => 0.5  # Escalate 2x faster
  "premium" => 0.8     # Escalate 25% faster
  "free" => 2.0        # Escalate 2x slower
  _ => 1.0
}

# Apply tier-specific thresholds
let age_boost = match {
  root.age_seconds > (86400 * tier_escalation_multiplier) => 100
  root.age_seconds > (14400 * tier_escalation_multiplier) => 60
  _ => 0
}
```

### Issue: Starvation Still Occurring

**Symptoms:**
- Messages sitting in low/bulk queues for days
- Age escalation not working
- Fairness violations detected

**Diagnosis:**
```bash
# Check for ancient messages
echo "=== Messages by Age Category ==="
for priority in low bulk; do
  echo "$priority queue age distribution:"
  timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
    --bootstrap-server $KAFKA_BROKERS \
    --topic ${priority}-priority-events \
    --from-beginning \
    --max-messages 50 | \
    jq -r '.age_category' | sort | uniq -c
done

# Check starvation monitoring file
if [ -f /var/expanso/monitoring/starvation-watch.jsonl ]; then
  echo "Starvation watch entries:"
  tail -20 /var/expanso/monitoring/starvation-watch.jsonl | \
    jq -r '"\(.timestamp) \(.event_type) age:\(.age_seconds)s priority:\(.priority)"'
fi
```

**Solutions:**

**1. Emergency Escalation for Ancient Messages**
```bloblang title="Emergency handling for very old messages"
# Emergency escalation for severely aged messages
if root.age_seconds > 604800 {  # > 7 days
  root.priority = "critical"
  root.emergency_escalation = true
  
  # Send immediate alert
  http_client(
    env("EMERGENCY_WEBHOOK_URL"),
    {"timeout": "2s", "verb": "POST"},
    {
      "alert": "emergency_starvation",
      "message_age_days": root.age_seconds / 86400,
      "original_priority": root.original_priority,
      "message_id": root.event_id
    }
  )
}
```

**2. Scale Consumer Resources**
```bash
# Emergency scaling for backlog processing
kubectl patch deployment low-priority-consumer --patch '{
  "spec": {
    "replicas": 50,
    "template": {
      "spec": {
        "containers": [
          {
            "name": "consumer",
            "resources": {
              "requests": {"cpu": "2", "memory": "4Gi"},
              "limits": {"cpu": "4", "memory": "8Gi"}
            }
          }
        ]
      }
    }
  }
}'

# Monitor backlog reduction
watch "kafka-consumer-groups.sh --bootstrap-server $KAFKA_BROKERS --describe --group low-priority-consumer | tail -5"
```

**3. Implement Catch-Up Mode**
```yaml title="Catch-up processing for backlogs"
# Detect backlog and enable catch-up mode
- mapping: |
    let queue_depth = http_client(
      "http://monitoring.internal/api/queue-depth",
      {"timeout": "100ms", "verb": "GET"}
    ).total_backlog.or(0)
    
    # Enable catch-up mode if significant backlog
    let catch_up_mode = queue_depth > 100000
    
    if catch_up_mode {
      # Boost all priorities slightly to process backlog faster
      root.priority_score = root.priority_score + 20
      root.catch_up_boost = true
    }
```

---

## Monitoring and Alerting Issues

### Issue: Metrics Not Available

**Symptoms:**
- Monitoring dashboard shows no data
- Metrics endpoint returning 404
- Unable to track priority distribution

**Diagnosis:**
```bash
# Check metrics endpoint
curl -I http://localhost:8081/metrics

# Check pipeline configuration for metrics
expanso pipeline config complete-priority-pipeline | grep -A5 -B5 metrics

# Check edge node status
expanso node status
```

**Solutions:**

**1. Enable Metrics in Pipeline Configuration**
```yaml title="Add metrics configuration"
# Add to pipeline config
metrics:
  prometheus:
    enabled: true
    push_gateway_url: ${PROMETHEUS_PUSHGATEWAY_URL}
    push_interval: 30s
    job_name: priority-queue-pipeline
    
  http_server:
    enabled: true
    address: 0.0.0.0:8081
    path: /metrics
```

**2. Check Network Configuration**
```bash
# Test metrics endpoint accessibility
netstat -tln | grep 8081

# Check firewall rules
sudo iptables -L | grep 8081

# Test from external host
curl http://your-edge-node:8081/metrics
```

**3. Verify Prometheus Configuration**
```yaml title="prometheus.yml"
scrape_configs:
  - job_name: 'priority-queues'
    static_configs:
      - targets: ['edge-node1:8081', 'edge-node2:8081']
    scrape_interval: 30s
    metrics_path: /metrics
```

### Issue: Alerts Not Firing

**Symptoms:**
- Age escalations happening but no alerts
- SLA violations not triggering notifications
- Starvation conditions not detected

**Diagnosis:**
```bash
# Check webhook endpoint
curl -X POST $MONITORING_WEBHOOK_URL/test \
  -H "Content-Type: application/json" \
  -d '{"test": "webhook connectivity"}'

# Check webhook configuration in pipeline
expanso pipeline config complete-priority-pipeline | grep -A10 webhook

# Check for webhook errors in logs
expanso pipeline logs complete-priority-pipeline | grep -i webhook
```

**Solutions:**

**1. Webhook Authentication Issues**
```yaml title="Fix webhook authentication"
# Ensure correct authentication headers
http_client:
  url: ${MONITORING_WEBHOOK_URL}/escalation-alert
  verb: POST
  headers:
    Content-Type: application/json
    Authorization: "Bearer ${MONITORING_API_TOKEN}"
    X-API-Key: "${WEBHOOK_API_KEY}"
  timeout: 5s
  max_retries: 3
```

**2. Add Webhook Error Handling**
```yaml title="Webhook with fallback"
broker:
  pattern: fan_out
  outputs:
    # Primary: Webhook alert
    - try:
        - http_client:
            url: ${MONITORING_WEBHOOK_URL}/alert
            verb: POST
            headers:
              Content-Type: application/json
            timeout: 5s
      catch:
        # Fallback: Log alert locally
        - file:
            path: /var/expanso/alerts/failed-webhooks.jsonl
            codec: lines
```

**3. Set Up Health Checks**
```bash
# Create webhook health check
cat << 'EOF' > webhook-health-check.sh
#!/bin/bash

WEBHOOK_URL="${MONITORING_WEBHOOK_URL}/health"

response=$(curl -s -w "%{http_code}" -o /dev/null "$WEBHOOK_URL")

if [ "$response" != "200" ]; then
    echo "ERROR: Webhook health check failed (HTTP $response)"
    exit 1
else
    echo "OK: Webhook endpoint healthy"
fi
EOF

chmod +x webhook-health-check.sh

# Run health check every 5 minutes
(crontab -l 2>/dev/null; echo "*/5 * * * * /path/to/webhook-health-check.sh") | crontab -
```

---

## Kafka Integration Issues

### Issue: Messages Not Reaching Kafka

**Symptoms:**
- Pipeline shows messages processed but Kafka topics empty
- Consumer groups show no activity
- High error rates in pipeline metrics

**Diagnosis:**
```bash
# Check Kafka connectivity
kafka-topics.sh --bootstrap-server $KAFKA_BROKERS --list

# Test producer connectivity
echo "test message" | kafka-console-producer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events

# Check consumer groups
kafka-consumer-groups.sh --bootstrap-server $KAFKA_BROKERS --list

# Check pipeline error logs
expanso pipeline logs complete-priority-pipeline | grep -i kafka
```

**Root Causes and Solutions:**

**1. Kafka Authentication Failure**
```bash
# Check if authentication required
kafka-configs.sh --bootstrap-server $KAFKA_BROKERS \
  --describe --entity-type brokers

# Configure SASL authentication if needed
export KAFKA_USERNAME="your-username"
export KAFKA_PASSWORD="your-password"
export KAFKA_SECURITY_PROTOCOL="SASL_SSL"
export KAFKA_SASL_MECHANISM="PLAIN"
```

```yaml title="Add authentication to pipeline"
kafka:
  addresses: ["${KAFKA_BROKERS}"]
  topic: critical-priority-events
  
  # Add authentication
  sasl:
    mechanism: PLAIN
    user: "${KAFKA_USERNAME}"
    password: "${KAFKA_PASSWORD}"
  
  tls:
    enabled: true
    skip_cert_verify: false
```

**2. Topic Auto-Creation Disabled**
```bash
# Check if topics exist
kafka-topics.sh --bootstrap-server $KAFKA_BROKERS --list | grep priority

# Create missing topics
for priority in critical high normal low bulk; do
  kafka-topics.sh --create \
    --bootstrap-server $KAFKA_BROKERS \
    --topic ${priority}-priority-events \
    --partitions 6 \
    --replication-factor 2
done
```

**3. Network/Firewall Issues**
```bash
# Test connectivity to each broker
for broker in $(echo $KAFKA_BROKERS | tr ',' ' '); do
  echo "Testing $broker..."
  nc -zv ${broker%:*} ${broker##*:}
done

# Check DNS resolution
nslookup kafka1.internal
```

### Issue: Message Ordering Problems

**Symptoms:**
- Messages arriving out of order
- Newer messages processed before older ones
- Timestamp inconsistencies

**Diagnosis:**
```bash
# Check message order in priority queue
timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-priority-events \
  --from-beginning \
  --max-messages 10 | \
  jq -r '"\(.timestamp) \(.priority_score) \(.event_type)"' | sort

# Check partition distribution
kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list $KAFKA_BROKERS \
  --topic critical-priority-events
```

**Solutions:**

**1. Use Keyed Messages for Ordering**
```yaml title="Add message keys for ordering"
kafka:
  addresses: ["${KAFKA_BROKERS}"]
  topic: critical-priority-events
  
  # Use customer ID as key to ensure ordering per customer
  key: ${!json("customer_id").or(json("user.id")).or("default")}
  
  # Alternative: Use event type as key
  # key: ${!json("event_type")}
```

**2. Single Partition for Strict Ordering**
```bash
# Create single-partition topic for critical events requiring strict ordering
kafka-topics.sh --create \
  --bootstrap-server $KAFKA_BROKERS \
  --topic critical-ordered-events \
  --partitions 1 \
  --replication-factor 3
```

**3. Add Sequence Numbers**
```bloblang title="Add sequence numbers"
# Add sequence number for ordering
root.sequence_number = count("global_sequence")
root.partition_key = this.customer_id.or("default")
```

---

## Getting Help

If you're still experiencing issues after trying these solutions:

### 1. Collect Diagnostic Information

Create a comprehensive diagnostic report:

```bash
# Create diagnostic collection script
cat << 'EOF' > collect-priority-diagnostics.sh
#!/bin/bash

DIAG_DIR="/tmp/priority-queue-diagnostics-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$DIAG_DIR"

echo "Collecting priority queue diagnostics..."

# Pipeline status and logs
expanso pipeline status complete-priority-pipeline > "$DIAG_DIR/pipeline-status.txt"
expanso pipeline logs complete-priority-pipeline --tail 1000 > "$DIAG_DIR/pipeline-logs.txt"
expanso pipeline config complete-priority-pipeline > "$DIAG_DIR/pipeline-config.yaml"

# Metrics
curl -s http://localhost:8081/metrics > "$DIAG_DIR/metrics.txt"

# Kafka information
kafka-topics.sh --bootstrap-server $KAFKA_BROKERS --list > "$DIAG_DIR/kafka-topics.txt"
for priority in critical high normal low bulk; do
  kafka-topics.sh --bootstrap-server $KAFKA_BROKERS \
    --describe --topic ${priority}-priority-events > "$DIAG_DIR/kafka-topic-${priority}.txt"
done

# Recent messages from each queue
for priority in critical high normal low bulk; do
  timeout 10s $KAFKA_HOME/bin/kafka-console-consumer.sh \
    --bootstrap-server $KAFKA_BROKERS \
    --topic ${priority}-priority-events \
    --from-beginning \
    --max-messages 20 > "$DIAG_DIR/messages-${priority}.json" 2>/dev/null
done

# System resources
ps aux | grep expanso > "$DIAG_DIR/expanso-processes.txt"
df -h > "$DIAG_DIR/disk-usage.txt"
free -h > "$DIAG_DIR/memory-usage.txt"

# Environment variables
env | grep -E "(KAFKA|EXPANSO|MONITORING)" > "$DIAG_DIR/environment.txt"

echo "Diagnostics collected in: $DIAG_DIR"
tar -czf "${DIAG_DIR}.tar.gz" -C /tmp "$(basename $DIAG_DIR)"
echo "Archive created: ${DIAG_DIR}.tar.gz"
EOF

chmod +x collect-priority-diagnostics.sh
./collect-priority-diagnostics.sh
```

### 2. Enable Debug Logging

Add detailed debug logging to your pipeline:

```yaml title="debug-logging-config.yaml"
# Add to pipeline processors for detailed logging
- mapping: |
    # Detailed debug logging
    root = this
    
    # Log every decision point
    log_info("Priority Classification", {
      "event_id": root.event_id,
      "input_severity": this.severity,
      "normalized_severity": root.severity,
      "customer_tier": root.customer_tier,
      "priority_score": root.priority_score,
      "assigned_priority": root.priority,
      "escalated": root.routing_decision.was_escalated
    })
```

### 3. Community Resources

- **Documentation:** [Priority Queues Guide](https://docs.expanso.io/guides/priority-queues)
- **Community Forum:** [Expanso Community](https://community.expanso.io)
- **GitHub Issues:** [Priority Queue Examples](https://github.com/expanso-io/examples)
- **Slack Channel:** #priority-queues in Expanso Community Slack

### 4. Provide Context When Asking for Help

When seeking help, include:

1. **Symptom description:** What's not working as expected?
2. **Expected vs actual behavior:** What should happen vs what's happening?
3. **Error messages:** Exact error text from logs
4. **Configuration:** Your pipeline YAML configuration
5. **Environment details:** Edge node version, Kafka version, infrastructure
6. **Diagnostic archive:** Output from the diagnostic collection script above

---

## Preventive Measures

### Regular Health Checks

Set up automated monitoring to catch issues early:

```bash
# Create health check script
cat << 'EOF' > priority-health-check.sh
#!/bin/bash

ALERT_EMAIL="ops-team@yourcompany.com"
HEALTH_STATUS=0

# Check pipeline status
if ! expanso pipeline status complete-priority-pipeline | grep -q "running"; then
    echo "CRITICAL: Priority pipeline not running"
    HEALTH_STATUS=1
fi

# Check message distribution
critical_count=$(curl -s http://localhost:8081/metrics | grep 'critical.*sent_total' | tail -1 | awk '{print $2}')
normal_count=$(curl -s http://localhost:8081/metrics | grep 'normal.*sent_total' | tail -1 | awk '{print $2}')

# Alert if no critical messages in last hour (might indicate classification issues)
if [ "${critical_count:-0}" -eq 0 ] && [ "${normal_count:-0}" -gt 100 ]; then
    echo "WARNING: No critical messages but many normal messages - check classification logic"
    HEALTH_STATUS=1
fi

# Check for starvation
if [ -f /var/expanso/monitoring/starvation-watch.jsonl ]; then
    starved_count=$(wc -l < /var/expanso/monitoring/starvation-watch.jsonl)
    if [ "$starved_count" -gt 10 ]; then
        echo "WARNING: $starved_count messages at starvation risk"
        HEALTH_STATUS=1
    fi
fi

if [ $HEALTH_STATUS -ne 0 ]; then
    # Send alert (replace with your alerting system)
    echo "Priority queue health check failed" | mail -s "Priority Queue Alert" $ALERT_EMAIL
fi

exit $HEALTH_STATUS
EOF

chmod +x priority-health-check.sh

# Run every 10 minutes
(crontab -l 2>/dev/null; echo "*/10 * * * * /path/to/priority-health-check.sh") | crontab -
```

### Performance Baseline Monitoring

Establish performance baselines and monitor for degradation:

```bash
# Create performance monitoring
cat << 'EOF' > priority-performance-monitor.sh
#!/bin/bash

# Define SLA targets
declare -A SLA_TARGETS=(
    ["critical"]=100
    ["high"]=500
    ["normal"]=2000
)

# Check current performance against SLAs
for priority in critical high normal; do
    current_latency=$(curl -s http://localhost:8081/metrics | grep "${priority}.*latency" | tail -1 | awk '{print $2}')
    target_latency=${SLA_TARGETS[$priority]}
    
    if [ "${current_latency%.*}" -gt "$target_latency" ]; then
        echo "SLA VIOLATION: $priority latency ${current_latency}ms exceeds target ${target_latency}ms"
    fi
done
EOF

chmod +x priority-performance-monitor.sh
```

With these troubleshooting techniques and preventive measures, you should be able to maintain a healthy, high-performance priority queue system in production.
