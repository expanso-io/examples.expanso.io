---
title: Add Kafka for Real-Time Streaming
sidebar_label: Step 2 - Add Kafka
sidebar_position: 5
description: Integrate Kafka as a real-time destination with optimized batching and security
keywords: [kafka, real-time, streaming, sasl, ssl, batching, performance]
---

# Step 2: Add Kafka for Real-Time Streaming

**Transform your fan-out pipeline into a real-time streaming powerhouse**. This step teaches you how to add Kafka as a high-throughput, low-latency destination with production-grade security, batching optimization, and resilience patterns.

## Understanding Kafka in Fan-Out Architecture

Kafka serves as the **real-time processing destination** in multi-destination architectures. While S3 handles long-term archival and Elasticsearch provides search capabilities, Kafka enables:

### Real-Time Processing Benefits

**Stream Processing Integration:**
- Connect to Apache Flink, Kafka Streams, or Apache Spark
- Enable complex event processing (CEP) and real-time analytics  
- Support for event sourcing and event-driven architectures

**Low-Latency Data Flow:**
- Sub-second message delivery for time-sensitive applications
- Support for high-frequency trading, IoT monitoring, fraud detection
- Real-time alerting and notification systems

**Scalable Event Distribution:**  
- Horizontal scaling through partitioning
- Consumer group load balancing
- Replay capabilities for new consumers

### Edge Computing Context

**Bandwidth Efficiency:**
- Compress data before transmission to cloud Kafka clusters
- Batch small events to reduce per-message overhead
- Use local buffering to handle network interruptions

**Security at Scale:**
- SASL authentication for multi-tenant environments
- SSL/TLS encryption for data in transit
- Schema Registry integration for data governance

## Step-by-Step Kafka Integration

### Starting Point: Current Broker Foundation

From Step 1, you have this broker foundation with local file outputs:

```yaml title="Current production-broker-foundation.yaml (outputs section)"
output:
  broker:
    pattern: fan_out
    outputs:
      - file:
          path: /var/expanso/data/realtime/events-${!timestamp_unix_date("2006-01-02")}-${!timestamp_unix_hour()}.jsonl
          # ... existing realtime file config
      - file:
          path: /var/expanso/archive/events-${!timestamp_unix_date("2006/01/02")}/hour-${!timestamp_unix_hour()}/batch-${!count("archive_batches")}.jsonl
          # ... existing archive file config  
      - file:
          path: /var/expanso/analytics/events-${!timestamp_unix_date("2006-01-02")}.jsonl
          # ... existing analytics file config
```

### Replace Real-Time File with Kafka

Replace the real-time file destination with a Kafka output optimized for streaming:

```yaml title="Add Kafka as real-time destination"
output:
  broker:
    pattern: fan_out
    outputs:
      # Real-time streaming to Kafka
      - kafka:
          # Multi-broker configuration for high availability
          addresses:
            - ${KAFKA_BROKER_1}
            - ${KAFKA_BROKER_2} 
            - ${KAFKA_BROKER_3}
          
          # Topic configuration
          topic: sensor-events
          
          # Partition key for even distribution and ordering
          key: ${!json("sensor_id")}
          
          # Optimized for real-time performance
          batching:
            count: 100        # Small batches for low latency
            period: 2s        # Fast delivery
            byte_size: 1MB    # Reasonable network chunks
          
          # Compression for bandwidth efficiency  
          compression: snappy
          
          # Reliability settings
          idempotent_write: true  # Prevent duplicates
          ack_replicas: true      # Wait for replica acknowledgment
          max_in_flight: 1        # Ensure ordering per partition
          
          # Authentication (SASL + SSL)
          sasl:
            mechanism: SCRAM-SHA-512
            user: ${KAFKA_USERNAME}
            password: ${KAFKA_PASSWORD}
          
          # TLS encryption
          tls:
            enabled: true
            skip_cert_verify: false
            
          # Retry configuration for transient failures
          max_retries: 5
          backoff:
            initial_interval: 200ms
            max_interval: 5s
            multiplier: 1.5
            
          # Timeout settings
          timeout: 10s
          
      # Keep existing archive file output
      - file:
          path: /var/expanso/archive/events-${!timestamp_unix_date("2006/01/02")}/hour-${!timestamp_unix_hour()}/batch-${!count("archive_batches")}.jsonl
          # ... keep existing config
          
      # Keep existing analytics file output  
      - file:
          path: /var/expanso/analytics/events-${!timestamp_unix_date("2006-01-02")}.jsonl
          # ... keep existing config
```

**Key Kafka-specific optimizations:**

**Batching Strategy:**
- **Count: 100** - Small batches minimize latency while reducing per-message overhead
- **Period: 2s** - Fast delivery ensures real-time responsiveness
- **Byte Size: 1MB** - Reasonable network utilization without excessive memory usage

**Reliability Configuration:**
- **Idempotent writes** prevent duplicate messages during retries
- **Ack replicas** ensures message durability across Kafka cluster
- **Max in-flight: 1** maintains message ordering within each partition

**Security Configuration:**
- **SCRAM-SHA-512** provides strong password-based authentication
- **TLS encryption** protects data in transit to cloud Kafka clusters
- **Certificate validation** ensures connection to legitimate brokers

### Add Kafka-Specific Processing

Add processing tailored to Kafka's event streaming requirements:

```yaml title="Add Kafka-optimized processing"
pipeline:
  processors:
    # Existing edge metadata processor
    - mapping: |
        root = this
        root.edge_node_id = env("NODE_ID").or("unknown")
        root.edge_location = env("NODE_LOCATION").or("unknown")
        root.processing_timestamp = now()
        root.pipeline_version = "kafka-integration-v1"

    # Add Kafka-specific metadata
    - mapping: |
        root = this
        
        # Kafka routing metadata
        root.kafka_metadata = {
          "partition_key": this.sensor_id,
          "expected_topic": "sensor-events",
          "delivery_mode": "at_least_once",
          "compression": "snappy"
        }
        
        # Add event classification for stream processing
        root.event_classification = {
          "priority": if this.device_type == "critical_sensor" { "high" } else { "normal" },
          "processing_window": "realtime",
          "requires_ordering": true
        }
        
        # Add schema version for compatibility
        root.schema_version = "sensor-event-v2"

    # Existing validation processor  
    - mapping: |
        # Strict validation for Kafka streaming
        if !this.exists("event_id") {
          throw("missing required field for Kafka: event_id")
        }
        if !this.exists("sensor_id") {
          throw("missing required field for Kafka: sensor_id") 
        }
        if !this.exists("timestamp") {
          throw("missing required field for Kafka: timestamp")
        }
        
        # Kafka-specific validation
        if this.sensor_id.type() != "string" {
          throw("sensor_id must be string for Kafka partitioning")
        }
        
        # Validate timestamp is recent (streaming context)
        event_age = now() - this.timestamp.parse_timestamp()
        if event_age > 300 { # 5 minutes
          throw("event too old for real-time streaming: " + this.timestamp)
        }
        
        root = this
```

### Configure Advanced Kafka Settings

For production environments, add advanced Kafka configuration:

```yaml title="Production Kafka configuration"
- kafka:
    addresses:
      - ${KAFKA_BROKER_1}
      - ${KAFKA_BROKER_2}
      - ${KAFKA_BROKER_3}
    
    topic: sensor-events
    key: ${!json("sensor_id")}
    
    # Advanced batching configuration
    batching:
      count: 100
      period: 2s
      byte_size: 1MB
      
      # Advanced batching options for high throughput
      linger_ms: 5              # Wait up to 5ms for more messages
      buffer_memory: 33554432   # 32MB buffer for batching
    
    # Producer performance tuning
    compression: snappy
    idempotent_write: true
    ack_replicas: true
    max_in_flight: 1
    
    # Advanced reliability settings
    enable_auto_commit: false
    transaction_timeout: 30s
    delivery_timeout: 120s
    request_timeout: 30s
    
    # Connection management
    connections_max_idle: 540s
    metadata_refresh_interval: 300s
    
    # Security configuration
    sasl:
      mechanism: SCRAM-SHA-512
      user: ${KAFKA_USERNAME}
      password: ${KAFKA_PASSWORD}
    
    tls:
      enabled: true
      skip_cert_verify: false
      
      # Certificate paths for production
      client_cert_file: ${KAFKA_CLIENT_CERT_PATH}
      client_key_file: ${KAFKA_CLIENT_KEY_PATH}
      root_cas_file: ${KAFKA_CA_CERT_PATH}
    
    # Retry and backoff configuration
    max_retries: 5
    backoff:
      initial_interval: 200ms
      max_interval: 5s
      multiplier: 1.5
      jitter: 0.1
      
    # Monitoring and observability
    client_id: "expanso-edge-${!env("NODE_ID")}"
    
    # Custom headers for monitoring
    metadata:
      static:
        producer_version: "expanso-kafka-v2.1"
        deployment_env: ${ENVIRONMENT}
        edge_cluster: ${EDGE_CLUSTER_ID}
      
      # Dynamic headers from message content
      from_message:
        message_sensor_type: ${!json("device_type")}
        message_priority: ${!json("event_classification.priority")}
```

### Add Local Kafka Fallback

Ensure resilience by adding a local file fallback when Kafka is unavailable:

```yaml title="Kafka with local fallback"
- fallback:
    # Primary: Kafka streaming
    - kafka:
        addresses:
          - ${KAFKA_BROKER_1}
          - ${KAFKA_BROKER_2}
          - ${KAFKA_BROKER_3}
        topic: sensor-events
        key: ${!json("sensor_id")}
        
        # Kafka configuration as above
        batching:
          count: 100
          period: 2s
        compression: snappy
        # ... rest of Kafka config
        
    # Fallback: Local buffer for Kafka outages
    - file:
        path: /var/expanso/kafka-fallback/events-${!timestamp_unix_date("2006-01-02")}-${!timestamp_unix_hour()}.jsonl
        codec: lines
        
        # Optimized for later Kafka replay
        batching:
          count: 1000     # Larger batches for efficiency
          period: 5m      # Less frequent writes
          
        processors:
          - mapping: |
              root = this
              root.fallback_metadata = {
                "reason": "kafka_unavailable", 
                "buffered_at": now(),
                "intended_destination": "kafka_sensor-events",
                "replay_priority": "high"
              }
```

**Fallback behavior:**
1. **Primary attempt**: Send to Kafka with normal retry logic
2. **Fallback activation**: If Kafka fails after all retries, write to local file
3. **Automatic replay**: When Kafka reconnects, replay buffered events (requires additional tooling)

## Complete Kafka Integration Configuration

Here's the complete configuration combining all Kafka integration concepts:

```yaml title="complete-kafka-fan-out-pipeline.yaml"
name: kafka-fan-out-pipeline
description: Multi-destination pipeline with Kafka real-time streaming
type: pipeline
namespace: production
labels:
  environment: production
  pattern: fan-out-kafka
  version: v2.0

config:
  input:
    http_server:
      address: 0.0.0.0:8080
      path: /events
      timeout: 5s
      rate_limit: "10000/s"

  pipeline:
    processors:
      # Edge metadata enrichment
      - mapping: |
          root = this
          root.edge_node_id = env("NODE_ID").or("unknown")
          root.edge_location = env("NODE_LOCATION").or("unknown") 
          root.processing_timestamp = now()
          root.pipeline_version = "kafka-v2.0"

      # Kafka-specific enrichment
      - mapping: |
          root = this
          root.kafka_metadata = {
            "partition_key": this.sensor_id,
            "expected_topic": "sensor-events", 
            "delivery_mode": "at_least_once",
            "compression": "snappy"
          }
          root.event_classification = {
            "priority": if this.device_type == "critical_sensor" { "high" } else { "normal" },
            "processing_window": "realtime",
            "requires_ordering": true
          }
          root.schema_version = "sensor-event-v2"

      # Enhanced validation for streaming
      - mapping: |
          # Required fields validation
          if !this.exists("event_id") {
            throw("missing required field: event_id")
          }
          if !this.exists("sensor_id") {
            throw("missing required field: sensor_id")
          }
          if !this.exists("timestamp") {
            throw("missing required field: timestamp")
          }
          
          # Kafka-specific validation
          if this.sensor_id.type() != "string" {
            throw("sensor_id must be string for Kafka partitioning")
          }
          
          # Freshness validation for real-time processing
          event_age = now() - this.timestamp.parse_timestamp()
          if event_age > 300 {
            throw("event too old for streaming: " + this.timestamp)
          }
          
          root = this

  output:
    broker:
      pattern: fan_out
      outputs:
        # Real-time Kafka streaming with fallback
        - fallback:
            # Primary: Kafka cluster
            - kafka:
                addresses:
                  - ${KAFKA_BROKER_1}
                  - ${KAFKA_BROKER_2}
                  - ${KAFKA_BROKER_3}
                
                topic: sensor-events
                key: ${!json("sensor_id")}
                
                # Real-time optimized batching
                batching:
                  count: 100
                  period: 2s
                  byte_size: 1MB
                  
                # Compression and reliability
                compression: snappy
                idempotent_write: true
                ack_replicas: true
                max_in_flight: 1
                
                # Security
                sasl:
                  mechanism: SCRAM-SHA-512
                  user: ${KAFKA_USERNAME}
                  password: ${KAFKA_PASSWORD}
                tls:
                  enabled: true
                  skip_cert_verify: false
                  
                # Retry configuration
                max_retries: 5
                backoff:
                  initial_interval: 200ms
                  max_interval: 5s
                  
                # Monitoring
                client_id: "expanso-edge-${!env("NODE_ID")}"
                
            # Fallback: Local buffer
            - file:
                path: /var/expanso/kafka-fallback/events-${!timestamp_unix_date("2006-01-02")}-${!timestamp_unix_hour()}.jsonl
                codec: lines
                batching:
                  count: 1000
                  period: 5m
                processors:
                  - mapping: |
                      root = this
                      root.fallback_metadata = {
                        "reason": "kafka_unavailable",
                        "buffered_at": now(),
                        "intended_destination": "kafka_sensor-events"
                      }

        # Archive destination (unchanged)
        - file:
            path: /var/expanso/archive/events-${!timestamp_unix_date("2006/01/02")}/hour-${!timestamp_unix_hour()}/batch-${!count("archive_batches")}.jsonl
            codec: lines
            batching:
              count: 1000
              period: 15m
            processors:
              - mapping: |
                  root = this
                  root.destination_type = "archive"
                  root.archived_at = now()

        # Analytics destination (unchanged)
        - file:
            path: /var/expanso/analytics/events-${!timestamp_unix_date("2006-01-02")}.jsonl 
            codec: lines
            batching:
              count: 200
              period: 5m
            processors:
              - mapping: |
                  root = this
                  root.destination_type = "analytics"
                  root.processed_at = now()
```

## Testing and Verification

### Deploy Kafka Integration

```bash title="Deploy Kafka-enabled pipeline"
# Set environment variables
source .env

# Deploy the Kafka integration
expanso job deploy complete-kafka-fan-out-pipeline.yaml

# Monitor deployment
watch -n 2 'expanso job status kafka-fan-out-pipeline'
```

### Test Kafka Connectivity

```bash title="Test Kafka integration"
# Generate test events
./generate-test-data.sh http://localhost:8080/events 10

# Verify Kafka received messages
kafka_2.13-2.8.1/bin/kafka-console-consumer.sh \
  --bootstrap-server $KAFKA_BROKER_1 \
  --topic sensor-events \
  --from-beginning \
  --consumer-config <(echo -e "security.protocol=SASL_SSL\nsasl.mechanism=SCRAM-SHA-512\nsasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=\"$KAFKA_USERNAME\" password=\"$KAFKA_PASSWORD\";") \
  --timeout-ms 10000 | head -10
```

**Expected output:** JSON events with Kafka metadata:
```json
{
  "event_id": "test-1705747200-1",
  "sensor_id": "sensor-1", 
  "timestamp": "2025-01-20T10:00:00Z",
  "kafka_metadata": {
    "partition_key": "sensor-1",
    "expected_topic": "sensor-events",
    "delivery_mode": "at_least_once"
  },
  "event_classification": {
    "priority": "normal",
    "processing_window": "realtime"
  }
}
```

### Performance Testing

```bash title="Test Kafka performance"
# Create high-load test
cat > kafka-performance-test.sh << 'EOF'
#!/bin/bash

ENDPOINT=${1:-http://localhost:8080/events}
DURATION=${2:-300}  # 5 minutes
RATE=${3:-100}      # 100 msg/s

echo "Testing Kafka performance: ${DURATION}s at ${RATE} msg/s"

# Start monitoring
echo "Starting monitoring..."
kafka_2.13-2.8.1/bin/kafka-run-class.sh kafka.tools.ConsumerPerformance \
  --bootstrap-server $KAFKA_BROKER_1 \
  --consumer.config <(echo -e "security.protocol=SASL_SSL\nsasl.mechanism=SCRAM-SHA-512\nsasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=\"$KAFKA_USERNAME\" password=\"$KAFKA_PASSWORD\";") \
  --topic sensor-events \
  --messages 10000 \
  --reporting-interval 1000 &

CONSUMER_PID=$!

# Run load test
./load-test-fan-out.sh $ENDPOINT $DURATION $RATE

# Stop consumer
kill $CONSUMER_PID

# Check partition distribution
kafka_2.13-2.8.1/bin/kafka-log-dirs.sh \
  --bootstrap-server $KAFKA_BROKER_1 \
  --command-config <(echo -e "security.protocol=SASL_SSL\nsasl.mechanism=SCRAM-SHA-512\nsasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=\"$KAFKA_USERNAME\" password=\"$KAFKA_PASSWORD\";") \
  --topic-list sensor-events \
  --describe
EOF

chmod +x kafka-performance-test.sh

# Run performance test
./kafka-performance-test.sh http://localhost:8080/events 120 50
```

### Verify Fallback Behavior

```bash title="Test Kafka fallback"
# Simulate Kafka outage by using wrong credentials
export KAFKA_USERNAME="wrong_user"
export KAFKA_PASSWORD="wrong_password"

# Redeploy with wrong credentials
expanso job deploy complete-kafka-fan-out-pipeline.yaml

# Generate events (should fall back to local files)
./generate-test-data.sh http://localhost:8080/events 5

# Check fallback files were created
ls -la /var/expanso/kafka-fallback/

# Verify fallback metadata
tail -1 /var/expanso/kafka-fallback/events-*.jsonl | jq '.fallback_metadata'

# Restore correct credentials
source .env
expanso job deploy complete-kafka-fan-out-pipeline.yaml
```

## Production Optimization Strategies

### Partitioning Strategy

**Optimize Kafka partitions for your use case:**

```yaml title="Advanced partitioning strategies"
# Strategy 1: Sensor-based partitioning (default)
kafka:
  key: ${!json("sensor_id")}        # Even distribution by sensor

# Strategy 2: Location-based partitioning  
kafka:
  key: ${!json("edge_location")}    # Group by geographic location

# Strategy 3: Device type partitioning
kafka:
  key: ${!json("device_type")}      # Group by device type

# Strategy 4: Time-based partitioning
kafka:
  key: ${!json("timestamp").parse_timestamp().ts_hour()}  # Group by hour

# Strategy 5: Composite partitioning
kafka:
  key: "${!json("edge_location")}-${!json("device_type")}"  # Composite key
```

### Compression Analysis

**Choose compression based on your data characteristics:**

```yaml title="Compression options comparison"
# Snappy: Fast compression, good for high-throughput
kafka:
  compression: snappy  # ~2x compression, low CPU overhead

# Gzip: Better compression ratio, higher CPU usage  
kafka:
  compression: gzip    # ~3-4x compression, higher CPU

# LZ4: Balanced performance and compression
kafka:
  compression: lz4     # ~2.5x compression, moderate CPU

# Zstd: Best compression, highest CPU usage
kafka:
  compression: zstd    # ~4-5x compression, high CPU
```

**Performance benchmark data:**
```
Compression  | Ratio | CPU Usage | Throughput | Best For
-------------|-------|-----------|------------|----------
none         | 1.0x  | 0%        | 100%       | Low latency, abundant bandwidth
snappy       | 2.1x  | 5%        | 95%        | General purpose, balanced
lz4          | 2.4x  | 8%        | 90%        | Slightly better compression
gzip         | 3.2x  | 15%       | 75%        | Limited bandwidth, archival
zstd         | 4.1x  | 20%       | 70%        | Maximum compression efficiency
```

### Monitoring and Observability

**Add Kafka-specific monitoring:**

```yaml title="Kafka monitoring configuration"
pipeline:
  processors:
    # Add monitoring metadata
    - mapping: |
        root = this
        root.monitoring = {
          "kafka_latency_target_ms": 100,
          "batch_target_size": 100,
          "compression_enabled": true,
          "partition_strategy": "sensor_id",
          "delivery_guarantee": "at_least_once"
        }
        
        # Add timing metadata for latency tracking
        root.timing = {
          "edge_ingress": now(),
          "processing_start": now(),
          "kafka_send_target": now() + duration("2s")
        }

# Add output monitoring
kafka:
  # ... existing config
  
  # Monitoring configuration
  metadata:
    static:
      monitoring_enabled: "true"
      latency_target_ms: "100"
      throughput_target_rps: "1000"
      
    from_message:
      message_size_bytes: ${!this.length()}
      processing_latency_ms: ${!now() - this.timing.processing_start}
```

## Common Issues and Solutions

### Issue: High Kafka Latency

**Symptom:** Messages take longer than expected to appear in Kafka topic.

**Diagnosis:**
```bash
# Check batch sizes and timing
expanso job logs kafka-fan-out-pipeline | grep -i "batch\|kafka"

# Monitor Kafka broker performance
kafka_2.13-2.8.1/bin/kafka-broker-api-versions.sh \
  --bootstrap-server $KAFKA_BROKER_1
```

**Solutions:**

1. **Reduce batch size for lower latency:**
```yaml
batching:
  count: 50     # Reduce from 100
  period: 1s    # Reduce from 2s
```

2. **Optimize network settings:**
```yaml
kafka:
  linger_ms: 1          # Reduce from 5ms
  buffer_memory: 16MB   # Reduce if memory constrained
```

3. **Check partition count:**
```bash
# Increase partitions for better parallelism
kafka_2.13-2.8.1/bin/kafka-topics.sh \
  --bootstrap-server $KAFKA_BROKER_1 \
  --topic sensor-events \
  --alter \
  --partitions 12
```

### Issue: Kafka Connection Failures

**Symptom:** Regular connection timeouts or authentication failures.

**Solutions:**

1. **Connection pooling optimization:**
```yaml
kafka:
  connections_max_idle: 300s    # Reduce idle timeout
  metadata_refresh_interval: 60s  # More frequent metadata refresh
```

2. **Retry configuration tuning:**
```yaml
kafka:
  max_retries: 10
  backoff:
    initial_interval: 100ms
    max_interval: 10s
    multiplier: 2.0
```

3. **Security configuration verification:**
```bash
# Test SASL configuration separately
echo "security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=\"$KAFKA_USERNAME\" password=\"$KAFKA_PASSWORD\";" > kafka-test.properties

kafka_2.13-2.8.1/bin/kafka-console-producer.sh \
  --bootstrap-server $KAFKA_BROKER_1 \
  --topic sensor-events \
  --producer.config kafka-test.properties
```

### Issue: Uneven Partition Distribution

**Symptom:** Some Kafka partitions receive significantly more messages than others.

**Root Cause:** Poor partition key selection leading to hotspots.

**Solutions:**

1. **Analyze partition key distribution:**
```bash
# Check partition distribution
kafka_2.13-2.8.1/bin/kafka-run-class.sh kafka.tools.ConsumerPerformance \
  --bootstrap-server $KAFKA_BROKER_1 \
  --topic sensor-events \
  --reporting-interval 1000 \
  --show-detailed-stats
```

2. **Improve partition key strategy:**
```yaml
# Before: Hotspot-prone key
key: ${!json("device_type")}  # Few unique values

# After: Better distribution
key: "${!json("sensor_id")}-${!timestamp_unix_nano()}"  # More unique values
```

3. **Use hash-based keys for even distribution:**
```yaml
key: ${!json("sensor_id").hash("xxhash64").string()}  # Hash for distribution
```

## Key Concepts Recap

**Kafka Fan-Out Benefits:**
- ✅ **Real-time processing**: Sub-second latency for time-sensitive applications
- ✅ **Horizontal scalability**: Partition-based scaling and consumer group load balancing  
- ✅ **Stream processing integration**: Connect to Flink, Spark, Kafka Streams
- ✅ **Event replay capabilities**: Historical data processing for new consumers

**Optimization Guidelines:**
- **Latency-sensitive**: Small batches (50-100), short periods (1-2s), snappy compression
- **Throughput-optimized**: Larger batches (200-500), moderate periods (5-10s), gzip compression
- **Balanced approach**: Medium batches (100-200), short periods (2-5s), lz4 compression

**Security Best Practices:**
- **Always use SASL + SSL** for production Kafka clusters
- **Rotate credentials regularly** using secret management systems
- **Validate certificates** to prevent man-in-the-middle attacks
- **Use least-privilege topic access** with Kafka ACLs

## Next Steps

✅ **Kafka integration complete!** Your pipeline now streams real-time data to Kafka with production-grade reliability and security.

**Ready for long-term storage?** Continue building your multi-destination architecture:

<div style={{display: 'flex', gap: '1rem', marginTop: '2rem', marginBottom: '2rem', flexWrap: 'wrap'}}>
  <a href="./step-3-add-s3" className="button button--primary button--lg" style={{flex: '1', minWidth: '200px'}}>
    Step 3: Add S3 Archive
  </a>
  <a href="./troubleshooting" className="button button--secondary button--lg" style={{flex: '1', minWidth: '200px'}}>
    Troubleshooting Guide
  </a>
</div>

---

**Next:** [Add S3 for long-term archival storage](./step-3-add-s3)
