---
title: Step 1 - HTTP Client Circuit Breakers
sidebar_label: Step 1 - HTTP Circuit Breakers
sidebar_position: 3
description: Implement circuit breaker protection for HTTP API calls with timeouts and retry strategies
keywords: [http-circuit-breaker, api-protection, timeout, retry, fallback]
---

# Step 1: HTTP Client Circuit Breakers

HTTP APIs are one of the most common failure points in edge pipelines. External APIs can become slow, unresponsive, or return errors, causing your pipeline to back up and consume resources while waiting for responses that may never come. HTTP circuit breakers protect your pipeline by failing fast when APIs are unhealthy and providing fallback mechanisms.

In this step, you'll implement HTTP circuit breakers using Expanso's `http` processor with timeout, retry, and fallback configurations. You'll learn to tune these settings for different API characteristics and implement proper fallback strategies.

## Understanding HTTP Circuit Breaker Mechanics

### Circuit Breaker States in HTTP Context

HTTP circuit breakers operate through three states based on API response behavior:

```
[CLOSED] → API is healthy, requests pass through normally
    ↓ (successive failures exceed threshold)
[OPEN] → API appears unhealthy, requests fail immediately
    ↓ (after timeout period, test with limited requests)
[HALF-OPEN] → Testing API recovery with limited requests
    ↓ (if API responds successfully)
[CLOSED] → API is healthy again, resume normal operation
```

### Key HTTP-Specific Considerations

**Timeout Strategy:**
- **Connection timeout:** Time to establish TCP connection (1-3s)
- **Request timeout:** Total time for request/response (5-30s)
- **Read timeout:** Time to read response body (3-10s)

**Error Classification:**
- **Immediate failures:** DNS errors, connection refused (fail fast)
- **Timeout failures:** No response within timeout (likely overload)
- **HTTP errors:** 5xx errors (server problems), 4xx errors (client problems)
- **Response errors:** Malformed JSON, unexpected format

**Retry Considerations:**
- **Idempotent operations:** Safe to retry GET, PUT, DELETE
- **Non-idempotent operations:** Be cautious with POST, PATCH
- **Rate limiting:** Don't overwhelm struggling APIs

## Implementation: Basic HTTP Circuit Breaker

Let's start with a basic HTTP circuit breaker that enriches sensor data by calling a metadata API.

### Pipeline Configuration

Create `http-circuit-breaker.yaml`:

```yaml title="http-circuit-breaker.yaml"
name: http-circuit-breaker
description: HTTP enrichment with circuit breaker protection
type: pipeline
namespace: circuit-breaker-test

config:
  input:
    http_server:
      address: 0.0.0.0:8080
      path: /sensor-data
      timeout: 30s

  pipeline:
    processors:
      # Step 1: Validate incoming data
      - mapping: |
          root = this
          
          # Ensure required fields exist
          if !this.sensor_id.exists() {
            throw("missing required field: sensor_id")
          }
          
          # Add tracking metadata
          root.processing_started_at = now()
          root.circuit_breaker_attempt = 1

      # Step 2: Call external API with circuit breaker protection
      - try:
          # HTTP call with circuit breaker configuration
          - http:
              url: ${MOCK_API_URL}/metadata/${!this.sensor_id}
              verb: GET
              
              # Circuit breaker timeouts
              timeout: 5s                    # Total request timeout
              
              # Retry configuration (implements circuit breaker logic)
              retries: 3                     # Maximum retry attempts
              retry_period: 2s               # Initial delay between retries
              max_retry_backoff: 30s         # Maximum delay (exponential backoff)
              
              # Headers for authentication and tracking
              headers:
                Authorization: Bearer ${!env("API_TOKEN")}
                X-Request-ID: ${!uuid_v4()}
                X-Source: expanso-circuit-breaker
              
              # Rate limiting to prevent overwhelming API
              rate_limit: "50/s"

          # Step 3: Process successful API response
          - mapping: |
              root = this
              
              # Parse API response
              api_response = content().parse_json()
              
              # Merge metadata into original payload
              root.metadata = api_response.metadata
              root.api_status = "success"
              root.enriched = true
              root.enriched_at = now()
              
              # Track success metrics
              root.api_response_time = (now() - this.processing_started_at).seconds()

        # Step 4: Handle API failures (circuit breaker fallback)
        catch:
          - mapping: |
              root = this
              
              # Mark as unenriched but continue processing
              root.metadata = null
              root.api_status = "failed"
              root.enriched = false
              root.fallback_reason = "api_circuit_breaker_open"
              root.failed_at = now()
              
              # Log failure for monitoring
              root.error_info = {
                "type": "api_failure",
                "timestamp": now(),
                "retry_attempts": this.circuit_breaker_attempt || 1
              }

          # Log circuit breaker activation
          - log:
              level: WARN
              message: "API circuit breaker activated for sensor: ${!this.sensor_id}"

      # Step 5: Add final processing metadata
      - mapping: |
          root = this
          root.processing_completed_at = now()
          root.total_processing_time = (now() - this.processing_started_at).seconds()

  # Output with fallback strategy
  output:
    fallback:
      # Primary output: Successfully enriched data
      - switch:
          cases:
            # Route enriched data to premium topic
            - check: this.enriched == true
              output:
                stdout:
                  codec: lines

      # Fallback output: Unenriched data (still valuable)
      - processors:
          # Add fallback processing flag
          - mapping: |
              root = this
              root.processing_mode = "fallback"
              root.circuit_breaker_fallback = true

        stdout:
          codec: lines
```

### Deploy and Test

Deploy the HTTP circuit breaker pipeline:

```bash
# Deploy pipeline
expanso apply -f http-circuit-breaker.yaml

# Verify deployment
expanso get pipeline http-circuit-breaker
```

### Test Normal Operation

First, test with the API responding normally:

```bash
# Send test data to pipeline
curl -X POST http://localhost:8080/sensor-data \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "temp_001",
    "temperature": 23.5,
    "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
    "location": "lab_a"
  }'

# Check pipeline logs for successful enrichment
expanso logs pipeline http-circuit-breaker --tail=10
```

**Expected successful output:**
```json
{
  "sensor_id": "temp_001",
  "temperature": 23.5,
  "timestamp": "2024-01-15T14:30:10Z",
  "location": "lab_a",
  "processing_started_at": "2024-01-15T14:30:15.123Z",
  "metadata": {
    "location": "Building A, Floor 2",
    "device_type": "temperature_sensor",
    "last_calibration": "2024-01-15T10:00:00Z"
  },
  "api_status": "success",
  "enriched": true,
  "enriched_at": "2024-01-15T14:30:15.456Z",
  "api_response_time": 0.333,
  "processing_completed_at": "2024-01-15T14:30:15.789Z",
  "total_processing_time": 0.666
}
```

### Test Circuit Breaker Activation

Now test the circuit breaker by simulating API failures:

```bash
# Test with timeout simulation
curl -X POST http://localhost:8080/sensor-data \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "temp_002",
    "temperature": 25.1,
    "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
    "location": "lab_b"
  }'

# To trigger timeout, modify the mock API URL temporarily
export MOCK_API_URL="http://localhost:8081?failure_mode=timeout"
```

```bash
# Send request that will trigger circuit breaker
curl -X POST http://localhost:8080/sensor-data \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "temp_003",
    "temperature": 22.8,
    "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
    "location": "lab_c"
  }'

# Check logs for circuit breaker activation
expanso logs pipeline http-circuit-breaker --tail=15
```

**Expected fallback output:**
```json
{
  "sensor_id": "temp_003",
  "temperature": 22.8,
  "timestamp": "2024-01-15T14:35:10Z",
  "location": "lab_c",
  "processing_started_at": "2024-01-15T14:35:15.123Z",
  "metadata": null,
  "api_status": "failed",
  "enriched": false,
  "fallback_reason": "api_circuit_breaker_open",
  "failed_at": "2024-01-15T14:35:20.456Z",
  "error_info": {
    "type": "api_failure",
    "timestamp": "2024-01-15T14:35:20.456Z",
    "retry_attempts": 1
  },
  "processing_completed_at": "2024-01-15T14:35:20.789Z",
  "total_processing_time": 5.666,
  "processing_mode": "fallback",
  "circuit_breaker_fallback": true
}
```

## Advanced HTTP Circuit Breaker Patterns

### Pattern 1: Service-Specific Circuit Breakers

For systems calling multiple APIs, implement separate circuit breaker configurations:

```yaml title="multi-api-circuit-breaker.yaml"
name: multi-api-circuit-breaker
description: Different circuit breaker settings per API service
type: pipeline
namespace: circuit-breaker-test

config:
  input:
    http_server:
      address: 0.0.0.0:8081
      path: /multi-api

  pipeline:
    processors:
      # Critical API: Conservative circuit breaker (fail fast)
      - try:
          - http:
              url: ${CRITICAL_API_URL}/essential-data/${!this.id}
              timeout: 3s           # Aggressive timeout
              retries: 2            # Few retries
              retry_period: 1s      # Quick retry
              rate_limit: "20/s"    # Conservative rate limit
              
        catch:
          - mapping: |
              root = this
              root.critical_api_failed = true
              root.processing_mode = "degraded"

      # Enhancement API: Tolerant circuit breaker (try harder)  
      - try:
          - http:
              url: ${ENHANCEMENT_API_URL}/enrich/${!this.id}
              timeout: 10s          # Longer timeout
              retries: 5            # More retries
              retry_period: 2s      # Patient retry
              rate_limit: "100/s"   # Higher rate limit
              
        catch:
          - mapping: |
              root = this
              root.enhancement_api_failed = true
              # Continue processing without enrichment

  output:
    switch:
      cases:
        # Reject if critical API failed
        - check: this.critical_api_failed == true
          output:
            processors:
              - log:
                  level: ERROR
                  message: "Rejecting due to critical API failure: ${!this.id}"
            drop: {}

        # Accept with or without enhancement
        - output:
            stdout:
              codec: lines
```

### Pattern 2: Circuit Breaker with Caching

Reduce API calls and improve resilience with caching:

```yaml title="cached-circuit-breaker.yaml"
name: cached-circuit-breaker  
description: HTTP circuit breaker with local caching
type: pipeline
namespace: circuit-breaker-test

config:
  cache_resources:
    - label: api_cache
      memory:
        cap: 1000               # Cache 1000 entries
        default_ttl: 5m         # 5-minute cache TTL

  input:
    http_server:
      address: 0.0.0.0:8082
      path: /cached-api

  pipeline:
    processors:
      # Step 1: Check cache first
      - cache:
          resource: api_cache
          operator: get
          key: metadata_${!this.sensor_id}

      # Step 2: Route based on cache hit/miss
      - switch:
          cases:
            # Cache hit: Use cached data
            - check: this.cached_data.exists()
              processors:
                - mapping: |
                    root = this
                    root.metadata = this.cached_data.parse_json()
                    root.cache_hit = true
                    root.api_calls_avoided = 1

            # Cache miss: Call API with circuit breaker
            - processors:
                - try:
                    # API call with circuit breaker
                    - http:
                        url: ${MOCK_API_URL}/metadata/${!this.sensor_id}
                        timeout: 5s
                        retries: 3
                        retry_period: 2s

                    # Parse and cache response
                    - mapping: |
                        root = this
                        api_response = content().parse_json()
                        root.metadata = api_response.metadata
                        root.cache_hit = false

                    # Store in cache for future requests
                    - cache:
                        resource: api_cache
                        operator: set
                        key: metadata_${!this.sensor_id}
                        value: ${!this.metadata.format_json()}

                  # Fallback on API failure
                  catch:
                    - mapping: |
                        root = this
                        root.metadata = null
                        root.api_failed = true
                        root.cache_hit = false

  output:
    stdout:
      codec: lines
```

### Pattern 3: Adaptive Circuit Breaker

Adjust circuit breaker behavior based on API health:

```yaml title="adaptive-circuit-breaker.yaml"
name: adaptive-circuit-breaker
description: Circuit breaker that adapts based on API health metrics
type: pipeline  
namespace: circuit-breaker-test

config:
  input:
    http_server:
      address: 0.0.0.0:8083
      path: /adaptive

  pipeline:
    processors:
      # Track request metrics for adaptive behavior
      - mapping: |
          root = this
          root.request_id = uuid_v4()
          root.attempt_started_at = now()

      # Health check API first (lightweight)
      - try:
          - http:
              url: ${MOCK_API_URL}/health
              verb: GET
              timeout: 1s           # Quick health check
              retries: 1            # Single retry
              
          - mapping: |
              root = this
              root.api_healthy = true
              
        catch:
          - mapping: |
              root = this  
              root.api_healthy = false

      # Adaptive API call based on health
      - switch:
          cases:
            # API is healthy: Normal circuit breaker settings
            - check: this.api_healthy == true
              processors:
                - http:
                    url: ${MOCK_API_URL}/metadata/${!this.sensor_id}
                    timeout: 10s       # Generous timeout when healthy
                    retries: 5         # More retries when healthy
                    retry_period: 2s

            # API is unhealthy: Aggressive circuit breaker settings
            - processors:
                - http:
                    url: ${MOCK_API_URL}/metadata/${!this.sensor_id}
                    timeout: 3s        # Quick timeout when unhealthy
                    retries: 1         # Single retry when unhealthy
                    retry_period: 1s

      # Process response
      - mapping: |
          root = this
          if content().length() > 0 {
            root.metadata = content().parse_json()
            root.enriched = true
          } else {
            root.metadata = null
            root.enriched = false
          }

  output:
    stdout:
      codec: lines
```

## Production Tuning Guidelines

### Timeout Configuration by API Type

**Internal Services (same network):**
```yaml
timeout: 3s
retries: 3
retry_period: 1s
```

**External APIs (internet):**
```yaml
timeout: 10s
retries: 5
retry_period: 2s
max_retry_backoff: 30s
```

**Critical Services (high availability required):**
```yaml
timeout: 1s
retries: 2
retry_period: 500ms
```

**Batch/Background APIs (can be slow):**
```yaml
timeout: 30s
retries: 10
retry_period: 5s
max_retry_backoff: 2m
```

### Error Handling Strategies

**Classify HTTP Errors:**

```yaml
processors:
  - try:
      - http:
          url: ${API_URL}/endpoint
          
    catch:
      # Determine error type and appropriate action
      - mapping: |
          root = this
          error = error()
          
          # Connection errors (DNS, network) - fail fast
          if error.contains("connection") || error.contains("dns") {
            root.error_type = "connection"
            root.retry_recommended = false
          }
          
          # Timeout errors - may retry with longer timeout
          else if error.contains("timeout") {
            root.error_type = "timeout"  
            root.retry_recommended = true
          }
          
          # HTTP 5xx errors - server problem, may retry
          else if error.contains("500") || error.contains("503") {
            root.error_type = "server_error"
            root.retry_recommended = true
          }
          
          # HTTP 4xx errors - client problem, don't retry
          else if error.contains("400") || error.contains("401") || error.contains("403") {
            root.error_type = "client_error"
            root.retry_recommended = false
          }
          
          else {
            root.error_type = "unknown"
            root.retry_recommended = false
          }
```

### Monitoring and Alerting

Add metrics to track circuit breaker behavior:

```yaml
processors:
  # Count total attempts
  - metric:
      type: counter
      name: http_requests_total
      labels:
        api_endpoint: ${!this.endpoint_name}
        
  - try:
      - http:
          url: ${API_URL}/endpoint
          
      # Count successes
      - metric:
          type: counter
          name: http_requests_total
          labels:
            api_endpoint: ${!this.endpoint_name}
            status: success
            
    catch:
      # Count failures and circuit breaker activations
      - metric:
          type: counter
          name: http_requests_total
          labels:
            api_endpoint: ${!this.endpoint_name}
            status: failure
            
      - metric:
          type: counter  
          name: circuit_breaker_opened_total
          labels:
            api_endpoint: ${!this.endpoint_name}
```

## Troubleshooting HTTP Circuit Breakers

### Issue: Circuit Breaker Never Opens

**Symptoms:**
- Pipeline continues waiting for slow API
- Resource consumption increases
- No fallback behavior triggered

**Diagnosis:**
```bash
# Check if retries are set to unlimited
expanso describe pipeline http-circuit-breaker | grep -A5 "retries"

# Check timeout settings
expanso logs pipeline http-circuit-breaker | grep timeout
```

**Solutions:**

1. **Set finite retries:**
```yaml
http:
  retries: 3  # Not: retries: -1 or missing
```

2. **Add reasonable timeout:**
```yaml
http:
  timeout: 5s  # Not: timeout: 0s or missing
```

3. **Implement catch block:**
```yaml
- try:
    - http:
        url: ${API_URL}
  catch:
    - mapping: |
        root.api_failed = true  # Required fallback
```

### Issue: Circuit Breaker Opens Too Frequently

**Symptoms:**
- Most requests go to fallback
- API is actually healthy
- Timeout too aggressive

**Diagnosis:**
```bash
# Check API response times
curl -w "Total: %{time_total}s\n" ${MOCK_API_URL}/metadata/test

# Check network latency
ping -c 5 localhost
```

**Solutions:**

1. **Increase timeout:**
```yaml
http:
  timeout: 10s  # was: 3s
```

2. **Increase retry attempts:**
```yaml
http:
  retries: 5    # was: 2
```

3. **Adjust retry period:**
```yaml
http:
  retry_period: 3s  # was: 1s
```

### Issue: High Resource Consumption

**Symptoms:**
- High CPU usage during API failures
- Memory consumption increasing
- Many pending requests

**Diagnosis:**
```bash
# Check Expanso resource usage
expanso describe pipeline http-circuit-breaker

# Check retry settings
expanso get pipeline http-circuit-breaker -o yaml | grep -A10 retry
```

**Solutions:**

1. **Implement rate limiting:**
```yaml
http:
  rate_limit: "20/s"  # Limit concurrent requests
```

2. **Add request timeout:**
```yaml
http:
  timeout: 5s
  retries: 3
  retry_period: 2s     # Don't retry too quickly
```

3. **Use connection pooling:**
```yaml
http:
  max_idle_connections: 10
  max_connections_per_host: 50
```

### Issue: Fallback Path Failing

**Symptoms:**
- Circuit breaker activates but pipeline still fails
- No data being processed
- Error logs show fallback issues

**Diagnosis:**
```bash
# Check fallback configuration
expanso get pipeline http-circuit-breaker -o yaml | grep -A20 fallback

# Check logs for fallback errors
expanso logs pipeline http-circuit-breaker | grep fallback
```

**Solutions:**

1. **Ensure fallback output exists:**
```yaml
output:
  fallback:
    - # Primary output
    - stdout:  # Simple fallback that should always work
        codec: lines
```

2. **Add fallback data processing:**
```yaml
catch:
  - mapping: |
      root = this
      root.enriched = false
      root.metadata = null  # Provide default values
```

3. **Test fallback independently:**
```bash
# Test that fallback output works
curl -X POST http://localhost:8080/test \
  -d '{"test": "fallback_only"}'
```

## What You've Learned

You've successfully implemented HTTP circuit breakers that:

✅ **Protect against API timeouts** with configurable timeout and retry settings
✅ **Fail fast on unhealthy APIs** preventing resource exhaustion
✅ **Provide graceful fallback** continuing to process data without enrichment
✅ **Support multiple patterns** including caching and adaptive behavior
✅ **Include production monitoring** with metrics and logging

The circuit breaker automatically detects API failures and switches to fallback mode, protecting your pipeline from cascading failures while maintaining data processing capability.

---

**Next:** [Step 2: Database Circuit Breakers](./step-2-database-circuit-breakers) - Implement circuit breaker protection for database connections and queries
