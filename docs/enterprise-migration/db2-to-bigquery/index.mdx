---
title: DB2 to BigQuery Migration
sidebar_label: Introduction
sidebar_position: 1
description: Replace DataStage ETL with edge-native processing for migrating financial transactions from DB2 to BigQuery
keywords: [db2, bigquery, datastage, etl, migration, gcp, enterprise, mainframe]
---

# DB2 to BigQuery Migration

Replace DataStage ETL with edge-native processing that runs **on or near your data center**.

## The Problem

Your organization has spent years building ETL pipelines in DataStage:
- DB2 databases with decades of transaction data
- Complex transformation logic embedded in proprietary stages
- Nightly batch jobs moving data to cloud analytics

**The challenge:** Migrating to GCP/BigQuery means rewriting everythingâ€”or paying for DataStage Cloud licenses forever.

## The Solution: 6 Edge-Native Transformations

This pipeline replaces DataStage with Expanso processors that run at the edge:

### 1. **Add Lineage Metadata** â†’ Audit Trail
- **DataStage:** Custom annotations or external logging
- **Expanso:** Automatic lineage injection with source tracking
- **Result:** Complete audit trail for compliance

### 2. **Normalize Currency** â†’ USD Conversion
- **DataStage:** Lookup Stage + Transformer
- **Expanso:** `branch` + `mapping` with inline rates
- **Result:** All amounts in USD with originals preserved

### 3. **Mask Account Numbers** â†’ PCI Compliance
- **DataStage:** Transformer with custom routines
- **Expanso:** `mapping` with slice/hash functions
- **Result:** Last 4 digits visible, full number hashed for joins

### 4. **Categorize Transactions** â†’ MCC Mapping
- **DataStage:** Switch/Case or lookup table
- **Expanso:** `match` expression with pattern matching
- **Result:** Human-readable categories for analytics

### 5. **Standardize Schema** â†’ BigQuery Format
- **DataStage:** Transformer with field mapping
- **Expanso:** `mapping` with field assignment
- **Result:** Clean, lowercase field names for BigQuery

### 6. **Validate Before Load** â†’ Data Quality
- **DataStage:** Data Rules Stage
- **Expanso:** `mapping` with conditional throw
- **Result:** Reject bad records before they hit BigQuery

## Why Process at the Edge?

**ðŸ”’ Data Sovereignty:** Transform data before it leaves your data center
**âš¡ Reduced Egress:** Send only clean, compressed data to GCP
**ðŸ“Š Real-time Audit:** Lineage metadata generated at extraction time
**ðŸ’° No License Fees:** Replace per-CPU DataStage licensing with flat-rate edge nodes

## What You'll Learn

By the end of this guide, you'll be able to:

âœ… **Replace DataStage lookup stages** with Expanso branch/mapping processors
âœ… **Add automatic lineage tracking** for regulatory compliance
âœ… **Mask sensitive data** at the edge before cloud transmission
âœ… **Deploy to edge nodes** near your DB2 servers
âœ… **Schedule nightly migrations** with production-ready error handling

## Get Started

### Option 1: Step-by-Step Tutorial (Recommended)
Build the pipeline incrementally, understanding each DataStage replacement:

1. [**Setup Guide**](./setup) - Prerequisites and environment
2. [**Step 1: Add Lineage**](./step-1-add-lineage-metadata) - Audit trail injection
3. [**Step 2: Normalize Currency**](./step-2-normalize-currency) - Lookup replacement
4. [**Step 3: Mask Accounts**](./step-3-mask-account-numbers) - PCI compliance
5. [**Step 4: Categorize**](./step-4-categorize-transactions) - MCC mapping
6. [**Step 5: Standardize Schema**](./step-5-standardize-schema) - BigQuery format
7. [**Step 6: Validate**](./step-6-validate-required-fields) - Data quality gates

### Option 2: Jump to Complete Pipeline
Download the production-ready configuration:

[**â†’ Get Complete Pipeline**](./complete-pipeline)

## Who This Guide Is For

- **Data Engineers** replacing DataStage ETL jobs
- **Cloud Architects** planning DB2 â†’ BigQuery migrations
- **Compliance Teams** needing audit trails for financial data
- **Platform Teams** modernizing legacy ETL infrastructure

## Prerequisites

- DB2 database with ODBC connectivity
- GCP project with BigQuery access
- Expanso Edge installed on a node with DB2 network access
- Basic familiarity with YAML and SQL

## Time to Complete

- **Step-by-Step Tutorial:** 45-60 minutes
- **Quick Deploy:** 10 minutes

## Real-World Impact

**Before (DataStage):**
- License cost: $50K+/year per CPU
- Deployment: Days to weeks for changes
- Audit trail: Manual, incomplete

**After (Expanso Edge):**
- License cost: Flat rate, unlimited nodes
- Deployment: Minutes via CLI
- Audit trail: Automatic, complete lineage
