---
title: Setup Environment for Schema Validation
sidebar_label: Setup
sidebar_position: 2
description: Configure edge nodes, sample data, and deploy a shell schema validation pipeline
keywords: [setup, environment, configuration, edge nodes, schema validation]
---

# Setup Environment for Schema Validation

Before building the complete schema validation solution, you'll set up edge nodes, prepare sample data, and deploy a minimal validation pipeline to verify your environment works.

## Prerequisites

- **Kafka:** Set up [Kafka](/getting-started/local-development#kafka) for validated message delivery
- **Expanso:** Installed and running ([Installation Guide](https://docs.expanso.io/installation))
- **Environment Variables:** See the [local development guide](/getting-started/local-development#environment-variables)

## Step 1: Verify Edge Node Configuration

Confirm your edge nodes are properly configured for schema validation:

```bash
# Check edge node status
expanso node list

# Verify node labels for schema validation
expanso node describe <NODE_ID> | grep -A 5 "labels"
```

**Expected output:**
```
NODE_ID                           STATUS    ROLE              LABELS
edge-sensor-001                   ready     sensor-collector  validation=required
edge-sensor-002                   ready     sensor-collector  validation=required
```

If your nodes don't have the required labels, add them:

```bash
# Add required labels to edge nodes
expanso node label edge-sensor-001 role=sensor-collector validation=required
expanso node label edge-sensor-002 role=sensor-collector validation=required

# Verify labels were added
expanso node describe edge-sensor-001 | grep validation
```

## Step 2: Create Schema Directory on Edge Nodes

Schema files need to be accessible to validation processors on each edge node:

```bash
# Connect to each edge node and create schema directory
for node in edge-sensor-001 edge-sensor-002; do
  echo "Setting up schema directory on $node..."
  
  # Create directory for schema files
  expanso node exec $node -- mkdir -p /etc/expanso/schemas
  
  # Set proper permissions
  expanso node exec $node -- chmod 755 /etc/expanso/schemas
  
  # Verify directory exists
  expanso node exec $node -- ls -ld /etc/expanso/schemas
done
```

**Expected output:**
```
Setting up schema directory on edge-sensor-001...
drwxr-xr-x 2 expanso expanso 4096 Oct 20 14:30 /etc/expanso/schemas

Setting up schema directory on edge-sensor-002...
drwxr-xr-x 2 expanso expanso 4096 Oct 20 14:30 /etc/expanso/schemas
```

## Step 3: Prepare Sample Sensor Data

Create test data to verify schema validation works correctly:

```bash
# Create sample data directory
mkdir -p /tmp/sensor-test-data

# Create valid sensor reading
cat > /tmp/sensor-test-data/valid-reading.json << 'EOF'
{
  "sensor_id": "sensor-42",
  "timestamp": "2025-10-20T14:30:00Z",
  "location": {
    "building": "warehouse-3",
    "floor": 2,
    "zone": "A"
  },
  "readings": {
    "temperature_celsius": 23.5,
    "humidity_percent": 45.2
  },
  "metadata": {
    "firmware_version": "2.1.0",
    "battery_percent": 87
  }
}
EOF

# Create invalid sensor reading (missing required fields)
cat > /tmp/sensor-test-data/invalid-reading-1.json << 'EOF'
{
  "sensor_id": "sensor-99",
  "timestamp": "2025-10-20T14:30:00Z"
}
EOF

# Create invalid sensor reading (wrong data types)
cat > /tmp/sensor-test-data/invalid-reading-2.json << 'EOF'
{
  "sensor_id": "sensor-42",
  "timestamp": "2025-10-20T14:30:00Z",
  "location": {
    "building": "warehouse-3",
    "floor": "second floor",
    "zone": "A"
  },
  "readings": {
    "temperature_celsius": "twenty-three point five",
    "humidity_percent": 45.2
  },
  "metadata": {
    "firmware_version": "2.1.0",
    "battery_percent": 87
  }
}
EOF

# Create invalid sensor reading (values out of range)
cat > /tmp/sensor-test-data/invalid-reading-3.json << 'EOF'
{
  "sensor_id": "sensor-42",
  "timestamp": "not-a-timestamp",
  "location": {
    "building": "warehouse-3",
    "floor": 2,
    "zone": "A"
  },
  "readings": {
    "temperature_celsius": -500,
    "humidity_percent": 150
  },
  "metadata": {
    "firmware_version": "2.1.0",
    "battery_percent": 87
  }
}
EOF

# Verify test data files
echo "Test data files created:"
ls -la /tmp/sensor-test-data/
echo ""

echo "Valid reading sample:"
jq . /tmp/sensor-test-data/valid-reading.json
```

## Step 4: Set Environment Variables

Configure endpoints for analytics and metrics collection:

```bash
# Set up environment variables for pipeline configuration
export ANALYTICS_ENDPOINT="http://localhost:9000"
export METRICS_ENDPOINT="http://localhost:9001"
export NODE_ID="edge-sensor-001"

# Verify environment variables
echo "Analytics endpoint: $ANALYTICS_ENDPOINT"
echo "Metrics endpoint: $METRICS_ENDPOINT"
echo "Node ID: $NODE_ID"

# Make environment variables persistent
cat >> ~/.bashrc << 'EOF'
# Expanso Schema Validation Environment
export ANALYTICS_ENDPOINT="http://localhost:9000"
export METRICS_ENDPOINT="http://localhost:9001"
export NODE_ID="edge-sensor-001"
EOF

# Apply environment variables to current session
source ~/.bashrc
```

## Step 5: Deploy Shell Schema Validation Pipeline

Before adding schema validation, deploy a minimal "shell" pipeline that accepts sensor readings without validation. This verifies your setup works.

Create `shell-schema-validation.yaml`:

```yaml title="shell-schema-validation.yaml"
name: shell-sensor-validation
description: Shell pipeline to test sensor data ingestion without validation
type: pipeline
namespace: testing
labels:
  environment: testing
  data-type: sensor-readings
priority: 50

# Deploy to edge nodes with validation labels
selector:
  match_labels:
    role: sensor-collector
    validation: required

# Basic deployment strategy for testing
deployment:
  strategy: rolling
  max_parallel: 1
  health_check:
    type: http
    endpoint: /ping
    interval: 30s

# Simple pipeline without validation
config:
  # Accept sensor readings via HTTP
  input:
    http_server:
      address: "0.0.0.0:8080"
      path: /sensor/readings
      allowed_verbs:
        - POST
      timeout: 5s

  # Minimal processing - just add timestamp
  pipeline:
    processors:
      - mapping: |
          root = this
          root.pipeline_metadata = {
            "received_at": now(),
            "node_id": env("NODE_ID").or("unknown"),
            "status": "shell_mode"
          }

  # Simple output to verify message flow
  output:
    http_client:
      url: "${ANALYTICS_ENDPOINT:http://localhost:9000}/test"
      verb: POST
      headers:
        Content-Type: application/json
      max_retries: 1
      timeout: 5s

# Basic logging
logger:
  level: INFO
  format: json

# Health check endpoint
metrics:
  prometheus:
    path: /metrics
```

Deploy the shell pipeline:

```bash
# Deploy the shell pipeline
expanso job deploy shell-schema-validation.yaml

# Verify deployment
expanso job status shell-sensor-validation

# Wait for pipeline to start
sleep 10

# Check deployment status
expanso job list | grep shell-sensor-validation
```

**Expected output:**
```
Job: shell-sensor-validation
Status: running
Type: pipeline
Executions:
  - Node: edge-sensor-001
    State: running
    Since: 15 seconds ago
    Health: healthy
```

## Step 6: Test Shell Pipeline

Verify the shell pipeline accepts and processes sensor readings:

```bash
# Test with valid sensor reading
echo "Testing shell pipeline with valid data..."
curl -X POST http://localhost:8080/sensor/readings \
  -H "Content-Type: application/json" \
  -d @/tmp/sensor-test-data/valid-reading.json

# Check if request succeeded (should return 200)
if [ $? -eq 0 ]; then
  echo "✅ Shell pipeline accepting requests"
else
  echo "❌ Shell pipeline not responding"
  exit 1
fi

# Test pipeline health endpoint
echo "Testing pipeline health..."
curl -s http://localhost:8080/ping

# Check pipeline metrics
echo "Checking pipeline metrics..."
curl -s http://localhost:8080/metrics | grep -E "(pipeline_input|http_server)"
```

**Expected output:**
```
✅ Shell pipeline accepting requests
{"status":"ok","uptime":"45s"}

# pipeline_input_received 1
# http_server_request_duration_seconds_count 1
```

## Step 7: Set Up Mock Analytics Endpoint

Create a simple HTTP server to capture messages for testing:

```bash
# Start mock analytics endpoint in background
echo "Starting mock analytics endpoint..."
python3 -m http.server 9000 --bind localhost &
ANALYTICS_PID=$!

echo "Analytics endpoint PID: $ANALYTICS_PID"

# Start mock metrics endpoint  
python3 -m http.server 9001 --bind localhost &
METRICS_PID=$!

echo "Metrics endpoint PID: $METRICS_PID"

# Test endpoints are responding
sleep 2
curl -s http://localhost:9000/ > /dev/null && echo "✅ Analytics endpoint ready"
curl -s http://localhost:9001/ > /dev/null && echo "✅ Metrics endpoint ready"

# Save PIDs for cleanup
echo "export ANALYTICS_PID=$ANALYTICS_PID" >> ~/.bashrc
echo "export METRICS_PID=$METRICS_PID" >> ~/.bashrc
```

## Step 8: Verify Shell Pipeline Works End-to-End

Send a test message through the complete pipeline:

```bash
# Send valid sensor reading
echo "Testing complete pipeline flow..."
curl -X POST http://localhost:8080/sensor/readings \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "sensor-test",
    "timestamp": "2025-10-20T10:00:00Z",
    "location": {"building": "warehouse-1", "floor": 1, "zone": "A"},
    "readings": {"temperature_celsius": 20.0, "humidity_percent": 50.0},
    "metadata": {"firmware_version": "1.0.0", "battery_percent": 100}
  }'

echo ""

# Check pipeline processed the message
echo "Checking pipeline metrics after test..."
TOTAL_MESSAGES=$(curl -s http://localhost:8080/metrics | grep 'pipeline_input_received' | awk '{print $2}')
echo "Total messages processed: $TOTAL_MESSAGES"

if [ "$TOTAL_MESSAGES" -ge 1 ]; then
  echo "✅ Shell pipeline processing messages successfully"
else
  echo "❌ Pipeline not processing messages"
  exit 1
fi
```

:::tip Success!
If you see "Shell pipeline processing messages successfully", your environment is correctly configured!

**Next step:** [Define JSON Schema](./step-1-define-json-schema) to add comprehensive data validation.
:::

## Step 9: Verify Prerequisites for Schema Validation

Before proceeding, verify all required components are ready:

```bash
# Run this verification script
echo "=== Schema Validation Setup Verification ==="
echo ""

# Check edge nodes
echo "1. Edge Nodes:"
expanso node list | grep -E "(sensor-collector|validation=required)" || echo "❌ No edge nodes with required labels"

# Check schema directory
echo ""
echo "2. Schema Directory:"
expanso node exec edge-sensor-001 -- ls -ld /etc/expanso/schemas 2>/dev/null && echo "✅ Schema directory exists" || echo "❌ Schema directory missing"

# Check sample data
echo ""
echo "3. Sample Data:"
[ -f /tmp/sensor-test-data/valid-reading.json ] && echo "✅ Sample data ready" || echo "❌ Sample data missing"

# Check environment variables
echo ""
echo "4. Environment Variables:"
[ -n "$ANALYTICS_ENDPOINT" ] && echo "✅ ANALYTICS_ENDPOINT set" || echo "❌ ANALYTICS_ENDPOINT not set"
[ -n "$METRICS_ENDPOINT" ] && echo "✅ METRICS_ENDPOINT set" || echo "❌ METRICS_ENDPOINT not set"
[ -n "$NODE_ID" ] && echo "✅ NODE_ID set" || echo "❌ NODE_ID not set"

# Check shell pipeline
echo ""
echo "5. Shell Pipeline:"
expanso job status shell-sensor-validation 2>/dev/null | grep -q "running" && echo "✅ Shell pipeline running" || echo "❌ Shell pipeline not running"

# Check endpoints
echo ""
echo "6. Mock Endpoints:"
curl -s http://localhost:9000/ > /dev/null && echo "✅ Analytics endpoint responding" || echo "❌ Analytics endpoint not responding"
curl -s http://localhost:9001/ > /dev/null && echo "✅ Metrics endpoint responding" || echo "❌ Metrics endpoint not responding"

echo ""
echo "=== Setup Verification Complete ==="
```

## Cleanup Commands (for reference)

If you need to clean up the setup:

```bash
# Stop shell pipeline
expanso job delete shell-sensor-validation

# Stop mock endpoints
[ -n "$ANALYTICS_PID" ] && kill $ANALYTICS_PID
[ -n "$METRICS_PID" ] && kill $METRICS_PID

# Remove test data
rm -rf /tmp/sensor-test-data

# Remove schema directories from edge nodes
for node in edge-sensor-001 edge-sensor-002; do
  expanso node exec $node -- rm -rf /etc/expanso/schemas
done
```

## Next Steps

With your environment set up and verified, you're ready to build the complete schema validation solution:

<div style={{display: 'flex', gap: '1.5rem', marginTop: '2rem', marginBottom: '3rem', flexWrap: 'wrap', justifyContent: 'flex-start'}}>
  <a href="./step-1-define-json-schema" className="button button--primary button--lg" style={{display: 'inline-flex', alignItems: 'center', justifyContent: 'center', textDecoration: 'none', borderRadius: '8px', padding: '1rem 2rem', fontWeight: '600', minWidth: '240px', boxShadow: '0 2px 8px rgba(0,0,0,0.15)', cursor: 'pointer', transition: 'all 0.2s ease'}}>
    Step 1: Define JSON Schema
  </a>
  <a href="./troubleshooting" className="button button--secondary button--lg" style={{display: 'inline-flex', alignItems: 'center', justifyContent: 'center', textDecoration: 'none', borderRadius: '8px', padding: '1rem 2rem', fontWeight: '600', minWidth: '240px', boxShadow: '0 2px 8px rgba(0,0,0,0.15)', cursor: 'pointer', transition: 'all 0.2s ease'}}>
    Troubleshooting Guide
  </a>
</div>

## Summary

You've successfully:
- ✅ Configured edge nodes with proper labels and schema directories
- ✅ Created comprehensive test data for validation scenarios
- ✅ Deployed and verified a shell pipeline for basic data flow
- ✅ Set up mock endpoints for testing analytics and metrics
- ✅ Verified the complete environment is ready for schema validation

**Next:** [Define JSON Schema](./step-1-define-json-schema) to create comprehensive data validation rules.
