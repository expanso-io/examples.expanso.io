---
title: "Edge Processing for Splunk Environments"
description: "Get cleaner, faster data into your Splunk index with edge processing"
tags: [splunk, edge-processing, log-management, data-quality]
---

# Edge Processing for Splunk Environments

## The Problem: Raw Data Slows Everything Down

If you're a Splunk administrator, you know the pain:

- **Searches are slow** because your indexes are full of noise — DEBUG messages, health checks, duplicate events that nobody queries
- **Field extraction at search time is expensive** — `props.conf` and `transforms.conf` run on every search, burning compute
- **Heavy Forwarders are a pain to manage** — config drift across hundreds of forwarders, no central visibility, manual updates
- **Data arrives unparsed and unstructured** — your analysts spend time cleaning data instead of finding insights

Your Splunk deployment works. But it could work **much better**.

## The Solution: Clean Data Before It Hits the Index

Expanso Edge sits between your data sources and Splunk. It does the heavy lifting *before* data reaches your indexers — so what arrives is already parsed, enriched, deduplicated, and routed to the right index.

✅ **Faster searches** — pre-parsed fields mean less search-time extraction, cleaner data means more relevant results  
✅ **Simpler management** — one pipeline config replaces `inputs.conf` + `props.conf` + `transforms.conf` across every forwarder  
✅ **Better data quality** — normalize timestamps, enrich with metadata, deduplicate at the edge  
✅ **Smarter routing** — security events to `security`, metrics to `metrics`, compliance data tagged and masked automatically  

## Architecture: Expanso + Splunk Integration

<div style={{display: 'flex', gap: '2rem', flexWrap: 'wrap', margin: '2rem 0'}}>

<div style={{flex: '1', minWidth: '280px', padding: '1.5rem', borderRadius: '12px', border: '1px solid var(--ifm-color-emphasis-300)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{fontSize: '0.75rem', fontWeight: 600, textTransform: 'uppercase', letterSpacing: '0.05em', color: 'var(--ifm-font-color-secondary)', marginBottom: '1rem'}}>Traditional Splunk</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.5rem'}}>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Log Sources</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Heavy Forwarder</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>raw, unparsed data</div>
<div style={{fontSize: '1.2rem'}}>↓ 100% noise + signal</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-300)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Splunk Indexers</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>search-time field extraction</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Slow Searches</div>
</div>
</div>

<div style={{flex: '1', minWidth: '280px', padding: '1.5rem', borderRadius: '12px', border: '2px solid var(--ifm-color-primary)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{fontSize: '0.75rem', fontWeight: 600, textTransform: 'uppercase', letterSpacing: '0.05em', color: 'var(--ifm-color-primary)', marginBottom: '1rem'}}>✅ With Expanso Edge</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.5rem'}}>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Log Sources</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.75rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-primary)', color: 'white', fontWeight: 600, textAlign: 'center', width: '100%', boxShadow: '0 2px 8px rgba(107,70,193,0.3)'}}>Expanso Edge</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-color-primary)'}}>parse, enrich, dedupe, route</div>
<div style={{display: 'flex', gap: '1rem', width: '100%', justifyContent: 'center'}}>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', flex: 1}}>
<div style={{fontSize: '1rem'}}>↓ clean data</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: '#16a34a', color: 'white', fontWeight: 600, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>Splunk HEC</div>
<div style={{fontSize: '1rem'}}>↓</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>Fast Searches</div>
<div style={{fontSize: '0.7rem', color: '#16a34a'}}>pre-parsed fields</div>
</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', flex: 1}}>
<div style={{fontSize: '1rem'}}>↓ archive</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>S3 / Archive</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>full fidelity backup</div>
</div>
</div>
</div>
</div>

</div>

**What changes:**
- **Search performance** — pre-extracted fields, no more search-time `rex` commands
- **Data quality** — normalized timestamps, deduplicated events, enriched metadata
- **Simpler ops** — one pipeline YAML replaces configs spread across every forwarder
- **Multi-destination** — same data to Splunk + S3 + metrics systems, parsed once

## If You Know Splunk, You Already Know Expanso

Expanso uses familiar Splunk concepts — but simpler to manage:

| **Splunk Concept** | **Expanso Equivalent** | **What's Better** |
|---|---|---|
| `inputs.conf` | Pipeline `input` section | Real-time parsing, multiformat support |
| `props.conf` / `transforms.conf` | Pipeline `processors` + Bloblang | One file, not three. Side-by-side SPL translations |
| `outputs.conf` | Pipeline `output` section | Multi-destination routing built in |
| Heavy Forwarder fleet | Expanso Edge nodes | Cloud-managed, no config drift |
| SPL field extraction | Bloblang mapping | Runs at ingest, not search time |
| Deployment Server | Expanso Cloud Console | GitOps-driven, instant rollouts |

## What You'll Build

In this tutorial, you'll create a complete Splunk integration that:

1. **Collects logs like inputs.conf** — file monitoring, multiline parsing
2. **Parses data like props.conf** — field extraction, normalization at ingest time
3. **Filters noise before indexing** — so your indexes only contain data people actually query
4. **Routes to Splunk HEC** — proper index/sourcetype tagging, pre-parsed fields
5. **Advanced patterns** — multi-destination, compliance masking, metrics extraction

## Prerequisites

- Expanso Edge installed ([installation guide](https://docs.expanso.io/edge/install))
- Splunk instance with HEC token configured
- Basic familiarity with Splunk configuration files

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See each Splunk integration technique with side-by-side transformations

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [Collect Like inputs.conf](./step-1-collect-like-inputs-conf)
2. [Parse Like props.conf](./step-2-parse-like-props-conf)
3. [Filter Before Indexing](./step-3-filter-before-indexing)
4. [Route to Splunk HEC](./step-4-route-to-splunk-hec)
5. [Advanced Splunk Patterns](./step-5-advanced-splunk-patterns)

### [Complete Pipeline](./complete-splunk-integration)
Download the production-ready solution

---

*Expanso makes your Splunk investment go further. Faster searches, cleaner data, simpler management.*
