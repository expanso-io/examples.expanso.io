---
title: "Edge Processing for Splunk Environments"
description: "Unlock the data Splunk can't see today — then make everything faster"
tags: [splunk, edge-processing, log-management, data-quality, iot, ot, edge]
---

# Edge Processing for Splunk Environments

## The Blind Spot: Data Splunk Has Never Seen

Splunk is a global brand with enormous reach. But every Splunk deployment is gated by a critical problem: **Splunk only sees data that someone already decided to send it.**

Across every enterprise, there are thousands of endpoints generating data that never touches Splunk. Not because it isn't valuable — because there was never a practical way to collect it, structure it, and make it usable:

- **A wind farm with 200 turbines** generating vibration and thermal data? That stays in a local historian.
- **A hospital with 10,000 medical devices** producing telemetry? That lives on the device.
- **A retail chain with 3,000 stores** running point-of-sale systems? Local logs, never aggregated.
- **A manufacturing floor with hundreds of PLCs and SCADA systems?** The OT team guards that data like a dragon sitting on gold.

None of this is in Splunk today. Not because Splunk can't handle it — but because there was never an intelligent way to get it there.

**That's the opportunity.** Not "do the same thing for less." It's **"bring Splunk into places it's never been."**

## Two Wins, One Pipeline

Expanso Edge sits between your data sources and Splunk. It unlocks two things simultaneously:

### Win #1: New Data Sources
Expanso Edge deploys anywhere — edge devices, OT networks, remote sites, IoT gateways. It collects data from sources that were never practical to connect to Splunk, structures it at the edge, and delivers it ready to index.

✅ **Edge collection** — deploy lightweight pipelines on devices, gateways, and remote infrastructure  
✅ **Protocol translation** — MQTT, OPC-UA, Modbus, syslog, file tailing — all normalized to Splunk-ready events  
✅ **Smart filtering at source** — send the signal, not the noise. A 200-turbine wind farm doesn't need to ship raw vibration data at 1kHz — it needs anomaly summaries  
✅ **OT/IT bridge** — the OT team keeps control of their network; Expanso filters and forwards only what's needed  

### Win #2: Better Existing Data
For data you're *already* sending to Splunk, Expanso makes it arrive cleaner, faster, and cheaper:

✅ **Faster searches** — pre-parsed fields mean less search-time extraction, cleaner data means more relevant results  
✅ **Simpler management** — one pipeline config replaces `inputs.conf` + `props.conf` + `transforms.conf` across every forwarder  
✅ **Better data quality** — normalize timestamps, enrich with metadata, deduplicate at the edge  
✅ **Smarter routing** — security events to `security`, metrics to `metrics`, compliance data tagged and masked automatically  

## Architecture: Expanso + Splunk Integration

<div style={{display: 'flex', gap: '2rem', flexWrap: 'wrap', margin: '2rem 0'}}>

<div style={{flex: '1', minWidth: '280px', padding: '1.5rem', borderRadius: '12px', border: '1px solid var(--ifm-color-emphasis-300)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{fontSize: '0.75rem', fontWeight: 600, textTransform: 'uppercase', letterSpacing: '0.05em', color: 'var(--ifm-font-color-secondary)', marginBottom: '1rem'}}>Traditional Splunk</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.5rem'}}>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Log Sources</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Heavy Forwarder</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>raw, unparsed data</div>
<div style={{fontSize: '1.2rem'}}>↓ 100% noise + signal</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-300)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Splunk Indexers</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>search-time field extraction</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Slow Searches</div>
</div>
</div>

<div style={{flex: '1', minWidth: '280px', padding: '1.5rem', borderRadius: '12px', border: '2px solid var(--ifm-color-primary)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{fontSize: '0.75rem', fontWeight: 600, textTransform: 'uppercase', letterSpacing: '0.05em', color: 'var(--ifm-color-primary)', marginBottom: '1rem'}}>✅ With Expanso Edge</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.5rem'}}>
<div style={{padding: '0.6rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%'}}>Log Sources</div>
<div style={{fontSize: '1.2rem'}}>↓</div>
<div style={{padding: '0.75rem 1.5rem', borderRadius: '8px', background: 'var(--ifm-color-primary)', color: 'white', fontWeight: 600, textAlign: 'center', width: '100%', boxShadow: '0 2px 8px rgba(107,70,193,0.3)'}}>Expanso Edge</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-color-primary)'}}>parse, enrich, dedupe, route</div>
<div style={{display: 'flex', gap: '1rem', width: '100%', justifyContent: 'center'}}>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', flex: 1}}>
<div style={{fontSize: '1rem'}}>↓ clean data</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: '#16a34a', color: 'white', fontWeight: 600, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>Splunk HEC</div>
<div style={{fontSize: '1rem'}}>↓</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>Fast Searches</div>
<div style={{fontSize: '0.7rem', color: '#16a34a'}}>pre-parsed fields</div>
</div>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', flex: 1}}>
<div style={{fontSize: '1rem'}}>↓ archive</div>
<div style={{padding: '0.5rem 0.75rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, textAlign: 'center', width: '100%', fontSize: '0.85rem'}}>S3 / Archive</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-font-color-secondary)'}}>full fidelity backup</div>
</div>
</div>
</div>
</div>

</div>

**What changes:**
- **Search performance** — pre-extracted fields, no more search-time `rex` commands
- **Data quality** — normalized timestamps, deduplicated events, enriched metadata
- **Simpler ops** — one pipeline YAML replaces configs spread across every forwarder
- **Multi-destination** — same data to Splunk + S3 + metrics systems, parsed once

## If You Know Splunk, You Already Know Expanso

Expanso uses familiar Splunk concepts — but simpler to manage:

| **Splunk Concept** | **Expanso Equivalent** | **What's Better** |
|---|---|---|
| `inputs.conf` | Pipeline `input` section | Real-time parsing, multiformat support |
| `props.conf` / `transforms.conf` | Pipeline `processors` + Bloblang | One file, not three. Side-by-side SPL translations |
| `outputs.conf` | Pipeline `output` section | Multi-destination routing built in |
| Heavy Forwarder fleet | Expanso Edge nodes | Cloud-managed, no config drift |
| SPL field extraction | Bloblang mapping | Runs at ingest, not search time |
| Deployment Server | Expanso Cloud Console | GitOps-driven, instant rollouts |

## What You'll Build

In this tutorial, you'll create a complete Splunk integration that:

1. **Collects logs like inputs.conf** — file monitoring, multiline parsing
2. **Parses data like props.conf** — field extraction, normalization at ingest time
3. **Filters noise before indexing** — so your indexes only contain data people actually query
4. **Routes to Splunk HEC** — proper index/sourcetype tagging, pre-parsed fields
5. **Advanced patterns** — multi-destination, compliance masking, metrics extraction

## Prerequisites

- Expanso Edge installed ([installation guide](https://docs.expanso.io/edge/install))
- Splunk instance with HEC token configured
- Basic familiarity with Splunk configuration files

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See each Splunk integration technique with side-by-side transformations

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [Collect Like inputs.conf](./step-1-collect-like-inputs-conf)
2. [Parse Like props.conf](./step-2-parse-like-props-conf)
3. [Filter Before Indexing](./step-3-filter-before-indexing)
4. [Route to Splunk HEC](./step-4-route-to-splunk-hec)
5. [Advanced Splunk Patterns](./step-5-advanced-splunk-patterns)

### [Complete Pipeline](./complete-splunk-integration)
Download the production-ready solution

---

*Expanso makes your Splunk investment go further — by bringing it into places it's never been, and making everything it already does faster and cleaner.*
