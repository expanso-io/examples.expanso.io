# O-RAN Edge Telemetry: Multi-Destination Data Pipeline

Streamline O-RAN network observability with a single edge pipeline that collects telemetry from DU/RU/CU nodes and routes data simultaneously to multiple destinations: real-time dashboards, analytics platforms, and long-term storage.

## The Problem

Telco operators managing O-RAN networks face a complex observability challenge:

- **Thousands of distributed edge nodes** generate continuous telemetry (DU, RU, CU units)
- **Multiple consumption patterns** require the same data:
  - Real-time dashboards (Grafana) for NOC operations
  - Long-term storage (Parquet) for capacity planning
  - Analytics platforms (Cloudera) for ML/AI insights
  - Compliance reporting for PTP timing requirements
- **The standard stack is heavy**: NiFi for ingestion, Kafka for buffering, Flink/Spark for processing â€” three distributed systems before data even reaches storage

The result: 3-5x network overhead, operational complexity across multiple systems, and teams spending more time managing the pipeline than analyzing the data.

## The Solution

**Single collection, multiple destinations**: Expanso Edge pipelines run on OpenShift Single Node OpenShift (SNO) directly alongside RAN workloads, collecting O-RAN telemetry once and routing to all destinations simultaneously.

<div style={{margin: '2rem 0', padding: '1.5rem', borderRadius: '12px', border: '2px solid var(--ifm-color-primary)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.75rem'}}>

<div style={{padding: '0.6rem 2rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, fontSize: '0.95rem'}}>DU Telemetry (PTP, CPU, PRB, RSRP)</div>

<div style={{fontSize: '1.2rem'}}>â†“</div>

<div style={{padding: '0.75rem 2rem', borderRadius: '8px', background: 'var(--ifm-color-primary)', color: 'white', fontWeight: 600, fontSize: '1rem', boxShadow: '0 2px 8px rgba(107,70,193,0.3)'}}>Expanso Edge Pipeline</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-color-primary)'}}>parse, normalize, enrich, filter anomalies, fan-out</div>

<div style={{display: 'flex', gap: '0.75rem', flexWrap: 'wrap', justifyContent: 'center', marginTop: '0.5rem'}}>
{[
  {label: 'Grafana / Prometheus', color: '#7c3aed', icon: 'ðŸ“Š'},
  {label: 'Parquet Storage', color: '#16a34a', icon: 'ðŸ“¦'},
  {label: 'Cloudera CDP', color: '#ea580c', icon: 'â˜ï¸'},
  {label: 'Local Buffer', color: '#64748b', icon: 'ðŸ’¾'},
].map((dest, i) => (
  <div key={i} style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.25rem'}}>
    <div style={{fontSize: '1rem'}}>â†“</div>
    <div style={{padding: '0.5rem 1rem', borderRadius: '8px', background: dest.color, color: 'white', fontWeight: 600, fontSize: '0.8rem', textAlign: 'center', minWidth: '120px'}}>
      {dest.icon} {dest.label}
    </div>
  </div>
))}
</div>

</div>
</div>

### What You're Replacing

The standard Cloudera Data Platform telco stack looks like this:

| Layer | Traditional Stack | What It Does |
|-------|------------------|--------------|
| **Ingest** | Apache NiFi | Connects to towers/switches, parses messy telco logs, enriches with geospatial data |
| **Buffer** | Apache Kafka | Handles burst traffic (outages, events), decouples ingestion from processing |
| **Process** | Apache Flink / Spark Streaming | Rolling window aggregations, anomaly detection, routing to multiple stores |
| **Store** | Kudu (real-time) + HDFS/Ozone (long-term) | Dashboards for NOC, Parquet for billing/capacity planning |

That's **four systems** to deploy, configure, monitor, and scale â€” each with its own failure modes, its own team, its own upgrade cycle.

**Expanso replaces the first three layers with a single pipeline YAML.** One config file. One deployment. One thing to monitor. Data arrives at Cloudera (or Grafana, or S3, or all three) already parsed, enriched, filtered, and schema-validated.

```
Traditional:  Tower â†’ NiFi â†’ Kafka â†’ Flink â†’ Kudu/HDFS
Expanso:      Tower â†’ Expanso Edge â†’ Kudu/HDFS/Grafana/S3 (all at once)
```

### Key Benefits

- **3 systems â†’ 1**: Replace NiFi + Kafka + Flink with a single Expanso Edge pipeline
- **99% bandwidth reduction**: Transform and filter at the edge before transmission
- **Zero data loss**: Local buffering handles burst traffic (no Kafka needed)
- **Unified data model**: Consistent schemas across all destinations
- **Edge resilience**: Continues operating during network partitions
- **OpenShift native**: Runs as certified operator on existing SNO infrastructure

## What You'll Build

This guide walks through creating a production-ready O-RAN telemetry pipeline that:

1. **Collects** PTP timing, CPU, PRB utilization, and RF metrics from DU nodes
2. **Transforms** raw telemetry with Bloblang processing (compliance classification, enrichment)
3. **Routes** to multiple destinations using fan-out broker pattern
4. **Monitors** pipeline health with built-in observability

### Key Metrics Processed

| Metric | Source | Purpose | Compliance Threshold |
|--------|--------|---------|---------------------|
| PTP4L Offset | DU Timing | 5G sync compliance | less than Â±100ns (compliant), Â±1000ns (critical) |
| PRB DL/UL % | DU Scheduler | Resource utilization | greater than 90% (congested) |
| CPU % | DU System | Performance monitoring | greater than 80% (alert) |
| RSRP/SINR | UE Reports | RF quality | RSRP less than -120dBm (poor coverage) |

## Prerequisites

- Expanso Edge running on OpenShift SNO nodes
- Access to DU telemetry endpoints or files
- Grafana + OTEL Collector + Prometheus stack
- Parquet writer capability
- Cloudera Data Platform (CDP) or Kafka endpoint

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See each O-RAN telemetry processing technique with side-by-side transformations

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [Collect O-RAN Metrics](./step-1-collect-oran-metrics)
2. [Transform and Enrich](./step-2-transform-and-enrich)
3. [Multi-Destination Routing](./step-3-multi-destination-routing)
4. [Grafana Dashboards](./step-4-grafana-dashboards)
5. [Parquet and Cloudera](./step-5-parquet-and-cloudera)

### [Complete Pipeline](./complete-oran-pipeline)
Download the production-ready solution
