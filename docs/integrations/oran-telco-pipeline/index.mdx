# O-RAN Edge Telemetry: Multi-Destination Data Pipeline

Streamline O-RAN network observability with a single edge pipeline that collects telemetry from DU/RU/CU nodes and routes data simultaneously to multiple destinations: real-time dashboards, analytics platforms, and long-term storage.

## The Problem

Telco operators managing O-RAN networks face a complex observability challenge:

- **Thousands of distributed edge nodes** generate continuous telemetry (DU, RU, CU units)
- **Multiple consumption patterns** require the same data:
  - Real-time dashboards (Grafana) for NOC operations
  - Long-term storage (Parquet) for capacity planning
  - Analytics platforms (Cloudera) for ML/AI insights
  - Compliance reporting for PTP timing requirements
- **The edge gap**: Data needs to be collected, shaped, and enriched before it reaches your Cloudera/Kafka/Grafana backends â€” but there's no lightweight, Red Hat-integrated way to do it at the edge

The result: 3-5x network overhead from shipping raw data, inconsistent schemas across destinations, and no edge-native processing before data hits your backends.

## The Solution

**Single collection, multiple destinations**: Expanso Edge pipelines run on OpenShift Single Node OpenShift (SNO) directly alongside RAN workloads, collecting O-RAN telemetry once and routing to all destinations simultaneously.

<div style={{margin: '2rem 0', padding: '1.5rem', borderRadius: '12px', border: '2px solid var(--ifm-color-primary)', background: 'var(--ifm-background-surface-color)'}}>
<div style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.75rem'}}>

<div style={{padding: '0.6rem 2rem', borderRadius: '8px', background: 'var(--ifm-color-emphasis-200)', fontWeight: 500, fontSize: '0.95rem'}}>DU Telemetry (PTP, CPU, PRB, RSRP)</div>

<div style={{fontSize: '1.2rem'}}>â†“</div>

<div style={{padding: '0.75rem 2rem', borderRadius: '8px', background: 'var(--ifm-color-primary)', color: 'white', fontWeight: 600, fontSize: '1rem', boxShadow: '0 2px 8px rgba(107,70,193,0.3)'}}>Expanso Edge Pipeline</div>
<div style={{fontSize: '0.7rem', color: 'var(--ifm-color-primary)'}}>parse, normalize, enrich, filter anomalies, fan-out</div>

<div style={{display: 'flex', gap: '0.75rem', flexWrap: 'wrap', justifyContent: 'center', marginTop: '0.5rem'}}>
{[
  {label: 'Grafana / Prometheus', color: '#7c3aed', icon: 'ðŸ“Š'},
  {label: 'Parquet Storage', color: '#16a34a', icon: 'ðŸ“¦'},
  {label: 'Cloudera CDP', color: '#ea580c', icon: 'â˜ï¸'},
  {label: 'Local Buffer', color: '#64748b', icon: 'ðŸ’¾'},
].map((dest, i) => (
  <div key={i} style={{display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '0.25rem'}}>
    <div style={{fontSize: '1rem'}}>â†“</div>
    <div style={{padding: '0.5rem 1rem', borderRadius: '8px', background: dest.color, color: 'white', fontWeight: 600, fontSize: '0.8rem', textAlign: 'center', minWidth: '120px'}}>
      {dest.icon} {dest.label}
    </div>
  </div>
))}
</div>

</div>
</div>

### Where Expanso Fits In Your Stack

Your backend stays exactly as-is â€” Cloudera CDP, Kafka, Grafana, HDFS/Ozone. Expanso Edge handles what happens **before** data reaches those systems: collect, shape, augment, and deliver to multiple destinations simultaneously.

| Layer | What | How Expanso Helps |
|-------|------|-------------------|
| **Collect** | MQTT, OPC-UA, syslog, file tailing from DU/RU/CU nodes | Single lightweight agent on OpenShift SNO â€” no NiFi deployment at the edge |
| **Shape** | Parse messy telco logs, normalize schemas, filter noise | Bloblang processors run at the edge â€” only clean data leaves the site |
| **Augment** | Enrich with cell site metadata, geo coordinates, compliance zones | Lookups and enrichment happen before transmission, not after |
| **Deliver** | Fan-out to Kafka, Grafana, Parquet, Cloudera â€” all at once | One pipeline, multiple destinations. Your backends receive ready-to-use data |

```
Tower â†’ Expanso Edge (collect, shape, augment) â†’ Kafka / Cloudera / Grafana / S3
        â”œâ”€â”€ runs on OpenShift SNO                  (your existing backends, unchanged)
        â”œâ”€â”€ buffers locally during outages
        â””â”€â”€ managed via Red Hat-integrated operator
```

### Key Benefits

- **Edge-native processing**: Collect and transform at the source, not in the datacenter
- **99% bandwidth reduction**: Only shaped, filtered data leaves the edge site
- **Zero data loss**: Local buffering handles burst traffic and connectivity drops
- **Unified data model**: Every destination receives consistent, enriched schemas
- **Multi-destination fan-out**: Same data to Kafka, Grafana, Parquet, and Cloudera simultaneously
- **Red Hat integrated**: Runs as certified OpenShift operator on existing SNO infrastructure

## What You'll Build

This guide walks through creating a production-ready O-RAN telemetry pipeline that:

1. **Collects** PTP timing, CPU, PRB utilization, and RF metrics from DU nodes
2. **Transforms** raw telemetry with Bloblang processing (compliance classification, enrichment)
3. **Routes** to multiple destinations using fan-out broker pattern
4. **Monitors** pipeline health with built-in observability

### Key Metrics Processed

| Metric | Source | Purpose | Compliance Threshold |
|--------|--------|---------|---------------------|
| PTP4L Offset | DU Timing | 5G sync compliance | less than Â±100ns (compliant), Â±1000ns (critical) |
| PRB DL/UL % | DU Scheduler | Resource utilization | greater than 90% (congested) |
| CPU % | DU System | Performance monitoring | greater than 80% (alert) |
| RSRP/SINR | UE Reports | RF quality | RSRP less than -120dBm (poor coverage) |

## Prerequisites

- Expanso Edge running on OpenShift SNO nodes
- Access to DU telemetry endpoints or files
- Grafana + OTEL Collector + Prometheus stack
- Parquet writer capability
- Cloudera Data Platform (CDP) or Kafka endpoint

## Get Started

Choose your path:

### [Interactive Explorer](./explorer)
See each O-RAN telemetry processing technique with side-by-side transformations

### [Step-by-Step Tutorial](./setup)
Build the pipeline incrementally:
1. [Collect O-RAN Metrics](./step-1-collect-oran-metrics)
2. [Transform and Enrich](./step-2-transform-and-enrich)
3. [Multi-Destination Routing](./step-3-multi-destination-routing)
4. [Grafana Dashboards](./step-4-grafana-dashboards)
5. [Parquet and Cloudera](./step-5-parquet-and-cloudera)

### [Complete Pipeline](./complete-oran-pipeline)
Download the production-ready solution
